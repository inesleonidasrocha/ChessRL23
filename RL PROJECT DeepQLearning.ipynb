{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning Final Project \n",
    "\n",
    "Welcome to your Reinforcement Learning project focused on developing an RL agent capable of playing chess at a strategic level. Chess has long been considered a benchmark for measuring AI capabilities, and this project aims to leverage the power of RL to create an intelligent agent that can make optimal decisions in complex chess positions. By combining the principles of reinforcement learning with the rich strategic domain of chess, you will explore new approaches to create the most effective chess player.\n",
    "\n",
    "## Project Objectives:\n",
    "\n",
    "* Train an RL agent to play chess: The primary objective of this project is to develop an RL agent that can play chess at a high level of proficiency. The agent should be capable of evaluating chess positions and making strategic decisions.\n",
    "\n",
    "* Optimize decision-making using RL algorithms: Explore different RL algorithms, as seen in class, to train the agent. Compare and analise their effectiveness in learning and decision-making capabilities in the context of chess.\n",
    "\n",
    "* Use a challenging chess environment: Use a comprehensive environment for the agent to interact with, representing the rules and dynamics of chess. This environment will provide a realistic and challenging setting for the agent's training and evaluation.\n",
    "\n",
    "* Evaluate and benchmark performance: Assess the performance of the RL agent against different benchmarks from existing chess engines. You will compare your agent's performance to established chess engines to measure progress and identify areas for improvement.\n",
    "\n",
    "\n",
    "### Extra Objectives:\n",
    "\n",
    "* Investigate transfer learning and generalization: Explore techniques for transfer learning to leverage knowledge acquired in related domains or from pre-training on large chess datasets. Investigate the agent's ability to generalize its knowledge.\n",
    "\n",
    "* Enhance interpretability and analysis: Develop methods to analise the agent's decision-making process and provide insights into its strategic thinking. Investigate techniques to visualize the agent's evaluation of chess positions and understand its reasoning behind specific moves."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Play Chess! \n",
    "\n",
    "As you know [Chess](https://en.wikipedia.org/wiki/Chess) is a board game for two players, called White and Black, each controlling an army of chess pieces in their color, with the objective to checkmate the opponent's king.\n",
    "\n",
    "Chess is an abstract strategy game that involves no hidden information and no use of dice or cards. It is played on a chessboard with 64 squares arranged in an eight-by-eight grid. At the start, each player controls sixteen pieces: one king, one queen, two rooks, two bishops, two knights, and eight pawns. White moves first, followed by Black. Checkmating the opponent's king involves putting the king under immediate attack (in \"check\") whereby there is no way for it to escape.\n",
    "\n",
    "\n",
    "![](Images/CHESS_MOVES.PNG)\n",
    "\n",
    "* The king moves one square in any direction. There is also a special move called castling that involves moving the king and a rook. The king is the most valuable piece â€” attacks on the king must be immediately countered, and if this is impossible, the game is immediately lost.\n",
    "* A rook can move any number of squares along a rank or file, but cannot leap over other pieces. Along with the king, a rook is involved during the king's castling move.\n",
    "* A bishop can move any number of squares diagonally, but cannot leap over other pieces.\n",
    "* A queen combines the power of a rook and bishop and can move any number of squares along a rank, file, or diagonal, but cannot leap over other pieces.\n",
    "* A knight moves to any of the closest squares that are not on the same rank, file, or diagonal. (Thus the move forms an \"L\"-shape: two squares vertically and one square horizontally, or two squares horizontally and one square vertically.) The knight is the only piece that can leap over other pieces.\n",
    "* A pawn can move forward to the unoccupied square immediately in front of it on the same file, or on its first move it can advance two squares along the same file, provided both squares are unoccupied (black dots in the diagram). A pawn can capture an opponent's piece on a square diagonally in front of it by moving to that square (black crosses). It cannot capture a piece while advancing along the same file. A pawn has two special moves: the en passant capture and promotion."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The [Environment](https://github.com/iamlucaswolf/gym-chess)\n",
    "\n",
    "The environment gym-chess provides OpenAI Gym environments for the game of Chess. It comes with an implementation of the board and move encoding used in AlphaZero. \n",
    "\n",
    "Please install it using the command: \n",
    "\n",
    "`pip install gym-chess`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install gym-chess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import gym\n",
    "import gym_chess\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "#import gymnasium as gym\n",
    "#import numpy as np\n",
    "from collections import deque\n",
    "#import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import cv2\n",
    "\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for NumPy\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set the seed for TensorFlow\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "#set seed for random\n",
    "random.seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Two player's game\n",
    "\n",
    "As you know chess is played by two players, as such the gym-chess environment gives you access to both players actions in a sequential matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WHITE_PLAYER_POLICY(env, state):\n",
    "    legal_actions = env.legal_actions\n",
    "    action = np.random.choice(legal_actions)\n",
    "\n",
    "    return action\n",
    "\n",
    "\n",
    "def BLACK_PLAYER_POLICY(env, state):\n",
    "    legal_actions = env.legal_actions\n",
    "    action = np.random.choice(legal_actions)\n",
    "\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\n",
    "    \"ChessAlphaZero-v0\"\n",
    ")  # We will use Alpha Zero's numenclature for the actions encodings\n",
    "\n",
    "state = env.reset()\n",
    "done = False\n",
    "counter = 0  # Since each step represents a play in a chess game we are going to store the number of steps associated to the episode/game\n",
    "\n",
    "while not done:\n",
    "    if (\n",
    "        counter % 2 == 0\n",
    "    ):  # If the step number is even, this means that it is the WHITE player's turn\n",
    "        action = WHITE_PLAYER_POLICY(env, state)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "\n",
    "    else:  # If the step number is not even, aka odd, this means that it is the BLACK player's turn\n",
    "        action = BLACK_PLAYER_POLICY(env, state)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "\n",
    "    counter += 1\n",
    "\n",
    "print(reward)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The agent receives a reward of +1 when the white player makes a winning move, and a reward of -1 when the black player makes a winning move. \n",
    "\n",
    "All other rewards are zero."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluationg your agent with [Stockfish](https://github.com/zhelyabuzhsky/stockfish)\n",
    "\n",
    "In order to have a good enough idea that our agent is actually playing well we need a benchmarkable opponent.\n",
    "\n",
    "As such we need to install stockfish a free and open-source chess engine. Stockfish has consistently ranked first or near the top of most chess-engine rating lists and, as of April 2023, is the strongest CPU chess engine in the world.\n",
    "\n",
    "`pip install stockfish`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stockfish in c:\\users\\isabe\\anaconda3\\envs\\week5\\lib\\site-packages (3.28.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install stockfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: numpy\n",
      "Version: 1.23.4\n",
      "Summary: NumPy is the fundamental package for array computing with Python.\n",
      "Home-page: https://www.numpy.org\n",
      "Author: Travis E. Oliphant et al.\n",
      "Author-email: \n",
      "License: BSD\n",
      "Location: c:\\users\\isabe\\anaconda3\\envs\\week5\\lib\\site-packages\n",
      "Requires: \n",
      "Required-by: ale-py, contourpy, gym, gymnasium, h5py, imageio, jax, jax-jumpy, Keras-Applications, Keras-Preprocessing, matplotlib, ml-dtypes, moviepy, mujoco, mujoco-py, opencv-python, opt-einsum, pandas, scikit-learn, scipy, seaborn, tensorboard, tensorflow-intel, torchtext\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stockfish import Stockfish"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StockFish has a python api as seen above, nevertheless the engine still needs to be downloaded [here](https://stockfishchess.org/download/) and used in the path.\n",
    "\n",
    "NOTE: You were given an engine already in moodle, nevertheless different computer systems (Windows, Mac, Ubuntu) might require other Stockfish engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stockfish_path = \"C:/Users/isabe/Desktop/RL/Project/stockfish_15.1_win_x64_avx2/stockfish-windows-2022-x86-64-avx2\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions bellow generate episodes/games for a WHITE or BLACK Pieces Scenario respectively. We store the outcome of the episode (win/draw/loss) and the number of steps taken.\n",
    "\n",
    "#### Notice how the AGENT_POLICY function is used it recieves as inputs the env and the current state.\n",
    "`action = AGENT_POLICY(env, state)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_WHITE_scenario(Stockfish_path, AGENT_POLICY):\n",
    "    env = gym.make(\n",
    "        \"ChessAlphaZero-v0\"\n",
    "    )  # We will use Alpha Zero's numenclature for the actions encodings\n",
    "    stockfish = Stockfish(Stockfish_path)\n",
    "    stockfish.set_elo_rating(\n",
    "        100\n",
    "    )  # Default \"skill\" level is 1350, higher will increase the skill of stockfish \"player\". See more at https://en.wikipedia.org/wiki/Elo_rating_system\n",
    "\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    counter = 0  # Since each step represents a play in a chess game we are going to store the number of steps associated to the episode/game\n",
    "\n",
    "    while not done:\n",
    "        if (\n",
    "            counter % 2 == 0\n",
    "        ):  # If the step number is pair, this means that it is the WHITE player's turn\n",
    "            action = AGENT_POLICY(env, state)\n",
    "            decoded_action = str(env.decode(action))\n",
    "            stockfish.make_moves_from_current_position([decoded_action])\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "\n",
    "        else:  # If the step number is not pair, aka odd, this means that it is the BLACK player's turn\n",
    "            decoded_action = stockfish.get_best_move()\n",
    "            action = env.encode(chess.Move.from_uci(decoded_action))\n",
    "            stockfish.make_moves_from_current_position([decoded_action])\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    return reward, np.ceil(counter / 2)\n",
    "\n",
    "\n",
    "def generate_BLACK_scenario(Stockfish_path, AGENT_POLICY):\n",
    "    env = gym.make(\n",
    "        \"ChessAlphaZero-v0\"\n",
    "    )  # We will use Alpha Zero's numenclature for the actions encodings\n",
    "    stockfish = Stockfish(Stockfish_path)\n",
    "    stockfish.set_elo_rating(\n",
    "        100\n",
    "    )  # Default \"skill\" level is 1350, higher will increase the skill of stockfish \"player\". See more at https://en.wikipedia.org/wiki/Elo_rating_system\n",
    "\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    counter = 0  # Since each step represents a play in a chess game we are going to store the number of steps associated to the episode/game\n",
    "\n",
    "    while not done:\n",
    "        if (\n",
    "            counter % 2 == 1\n",
    "        ):  # If the step number is not even, aka odd, this means that it is the BLACK player's turn\n",
    "            action = AGENT_POLICY(env, state)\n",
    "            decoded_action = str(env.decode(action))\n",
    "            stockfish.make_moves_from_current_position([decoded_action])\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "\n",
    "        else:  # If the step number is even, this means that it is the WHITE player's turn\n",
    "            decoded_action = stockfish.get_best_move()\n",
    "            action = env.encode(chess.Move.from_uci(decoded_action))\n",
    "            stockfish.make_moves_from_current_position([decoded_action])\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    return reward, np.ceil(counter / 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the function bellow a visualization is produced from the bechmarks made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AGENT_EVALUATION(Stockfish_path, WHITE_PLAYER_POLICY, BLACK_PLAYER_POLICY, n_evaluations=100): #changed\n",
    "    results_list = []\n",
    "\n",
    "    for evaluation_number in tqdm(range(n_evaluations)):\n",
    "        generate_episode = generate_WHITE_scenario\n",
    "\n",
    "        reward, n_steps = generate_episode(Stockfish_path, WHITE_PLAYER_POLICY) #changed\n",
    "\n",
    "        if reward == 1:\n",
    "            result = \"VICTORY\"\n",
    "        elif reward == 0:\n",
    "            result = \"DRAW\"\n",
    "        else:\n",
    "            result = \"LOSS\"\n",
    "\n",
    "        results_list.append([\"WHITE\", result, n_steps])\n",
    "\n",
    "        generate_episode = generate_BLACK_scenario\n",
    "\n",
    "        reward, n_steps = generate_episode(Stockfish_path, BLACK_PLAYER_POLICY) #changed\n",
    "\n",
    "        if reward == -1:\n",
    "            result = \"VICTORY\"\n",
    "        elif reward == 0:\n",
    "            result = \"DRAW\"\n",
    "        else:\n",
    "            result = \"LOSS\"\n",
    "\n",
    "        results_list.append([\"BLACK\", result, n_steps])\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        results_list, columns=[\"AGENT COLOR\", \"OUTCOME\", \"N STEPS\"]\n",
    "    ).astype(\"int\", errors=\"ignore\")\n",
    "\n",
    "    plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "    results_group = (\n",
    "        df.groupby([\"AGENT COLOR\", \"OUTCOME\"])\n",
    "        .count()\n",
    "        .rename(columns={\"N STEPS\": \"GAMES\"})\n",
    "    )\n",
    "\n",
    "    n_games = results_group.sum()[0]\n",
    "\n",
    "    results_group = (2 * 100 * results_group / (n_games)).astype(\"int\")\n",
    "\n",
    "    viz_df = (\n",
    "        results_group.reset_index()\n",
    "        .pivot_table(index=\"AGENT COLOR\", columns=\"OUTCOME\", values=\"GAMES\")\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    viz_df.plot(kind=\"barh\", stacked=True)\n",
    "\n",
    "    plt.xlabel(\"Percentage\")\n",
    "    plt.title(f\"EVALUATION RESULTS FOR {n_games} GAMES\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "093d6334d32a470485c6b8d0e545baf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = AGENT_EVALUATION(Stockfish_path, WHITE_PLAYER_POLICY, BLACK_PLAYER_POLICY, n_evaluations=5) #changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGENT COLOR</th>\n",
       "      <th>OUTCOME</th>\n",
       "      <th>N STEPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHITE</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLACK</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHITE</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BLACK</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WHITE</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  AGENT COLOR OUTCOME  N STEPS\n",
       "0       WHITE    LOSS       28\n",
       "1       BLACK    LOSS        7\n",
       "2       WHITE    LOSS       11\n",
       "3       BLACK    LOSS       27\n",
       "4       WHITE    LOSS       19"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ready to Play Chess?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_state(state):\n",
    "    state_boards= np.c_[state[:,:,:14], state[:,:,-7:]] #the state we want just has the current board and the last matrices with information\n",
    "    return np.array([state_boards.reshape(8,8,21)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for NumPy\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set the seed for TensorFlow\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "#set seed for random\n",
    "random.seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Deep Q-Network (DQN) model architecture using a neural network framework like TensorFlow. The model takes the state as input and outputs Q-values for each action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN:\n",
    "    def __init__(self, state_size, env):\n",
    "        #define environment\n",
    "        self.env= env\n",
    "\n",
    "        #define the state size\n",
    "        self.state_size = state_size\n",
    "        \n",
    "        #define the action size\n",
    "        self.action_size = len(env.legal_actions)\n",
    "        \n",
    "        #define the replay buffer\n",
    "        self.replay_buffer = deque(maxlen=1000)\n",
    "        \n",
    "        #define the discount factor\n",
    "        self.gamma = 0.9\n",
    "        \n",
    "        #define the epsilon value\n",
    "        self.epsilon = 0.99\n",
    "        \n",
    "        #define the update rate at which we want to update the target network\n",
    "        self.update_rate = 5\n",
    "        \n",
    "        #define the main network\n",
    "        self.main_network = self.build_network()\n",
    "        \n",
    "        #define the target network\n",
    "        self.target_network = self.build_network()\n",
    "        \n",
    "        #copy the weights of the main network to the target network\n",
    "        self.target_network.set_weights(self.main_network.get_weights())\n",
    "\n",
    "        #learning rate\n",
    "        self.learning_rate = .0001\n",
    "        \n",
    "\n",
    "    #Let's define a function called build_network which is essentially our DQN. \n",
    "\n",
    "    def build_network(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(filters=6, kernel_size=(7, 7), strides=1, activation='relu', padding='same', input_shape=self.state_size))\n",
    "        model.add(Conv2D(filters=6, kernel_size=(3, 3), strides=2, activation='relu', padding='same'))\n",
    "        model.add(Conv2D(filters=12, kernel_size=(3, 3), strides=1, activation='relu', padding='same'))\n",
    "        model.add(Conv2D(filters=12, kernel_size=(3, 3), strides=2, activation='relu', padding='same'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(216, activation='relu'))\n",
    "        model.add(Dense(self.env.action_space.n, activation=None))\n",
    "\n",
    "        model.compile(loss='mse', optimizer=Adam(learning_rate=.0001, epsilon=1e-7))\n",
    "\n",
    "\n",
    "        return model\n",
    "\n",
    "    #We learned that we train DQN by randomly sampling a minibatch of transitions from the\n",
    "    #replay buffer. So, we define a function called store_transition which stores the transition information\n",
    "    #into the replay buffer\n",
    "\n",
    "    def store_transition(self, state, action, reward, next_state, done):\n",
    "        self.replay_buffer.append((state, action, reward, next_state, done))\n",
    "        \n",
    "\n",
    "    #We learned that in DQN, to take care of exploration-exploitation trade off, we select action\n",
    "    #using the epsilon-greedy policy. So, now we define the function called epsilon_greedy\n",
    "    #for selecting action using the epsilon-greedy policy.\n",
    "    def epsilon_greedy(self, state):\n",
    "        if random.uniform(0,1) < self.epsilon:\n",
    "            legal_actions = self.env.legal_actions\n",
    "            action = np.random.choice(legal_actions)\n",
    "            return action\n",
    "        else:    \n",
    "            Q_values = self.main_network.predict(state, verbose=0)[0]\n",
    "            legal_q_values= Q_values[self.env.legal_actions]\n",
    "            action= self.env.legal_actions[np.argmax(legal_q_values)]\n",
    "            return action\n",
    "    \n",
    "    #train the network\n",
    "    def train(self, batch_size):\n",
    "        \n",
    "        minibatch = np.array(random.sample(self.replay_buffer, batch_size), dtype=object)\n",
    "\n",
    "        state_list = np.array(minibatch[:,0], dtype=object)\n",
    "        state_list = np.hstack(state_list).reshape(batch_size, 8, 8, 21)\n",
    "\n",
    "        next_state_list = np.array(minibatch[:,3])\n",
    "        next_state_list = np.hstack(next_state_list).reshape(batch_size, 8, 8, 21)\n",
    "\n",
    "        current_Q_values_list = self.main_network.predict(state_list, verbose=0)\n",
    "\n",
    "        max_q = np.amax(self.target_network.predict(next_state_list, verbose=0), axis=1)\n",
    "\n",
    "        for i, zip_ in enumerate(minibatch):\n",
    "\n",
    "            state, action, reward, next_state, done = zip_\n",
    "\n",
    "            if not done:\n",
    "                target  = reward + self.gamma * max_q[i]\n",
    "            else:\n",
    "                target = reward\n",
    "\n",
    "            updated_Q_value = target # (1 - self.learning_rate)*current_Q_values_list[i][action] + self.learning_rate*(target) # - current_Q_values_list[i][action]) # This is a different form of Q-learning (Min Q-Learning)\n",
    "\n",
    "            current_Q_values_list[i][action] = updated_Q_value\n",
    "        #train the main network\n",
    "        self.main_network.fit(state_list, current_Q_values_list, epochs=1, verbose=0)\n",
    "            \n",
    "    #update the target network weights by copying from the main network\n",
    "    def update_target_network(self):\n",
    "        self.target_network.set_weights(self.main_network.get_weights())\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_WHITE_scenario(Stockfish_path, dqn_white, evaluation_number):\n",
    "    env = gym.make(\"ChessAlphaZero-v0\") # We will use Alpha Zero's numenclature for the actions encodings\n",
    "    stockfish = Stockfish(Stockfish_path)\n",
    "    stockfish.set_elo_rating(\n",
    "        100\n",
    "    )  # Default \"skill\" level is 1350, higher will increase the skill of stockfish \"player\". See more at https://en.wikipedia.org/wiki/Elo_rating_system\n",
    "    \n",
    "    #pre-process state\n",
    "    dqn_white.state = env.reset()\n",
    "    dqn_white.env= env\n",
    "    dqn_white.state = preprocess_state(dqn_white.state)\n",
    "    done = False\n",
    "    counter = 0  # Since each step represents a play in a chess game we are going to store the number of steps associated to the episode/game\n",
    "    # set return to 0\n",
    "    Return = 0 \n",
    "    Real_Return = 0\n",
    "\n",
    "    while not done:\n",
    "        if (\n",
    "            counter % 2 == 0\n",
    "        ):  # If the step number is even, this means that it is the WHITE player's turn\n",
    "            #Update target model if the correct nÂº episodes has passed\n",
    "            if evaluation_number % dqn_white.update_rate == 0:\n",
    "                dqn_white.update_target_network()\n",
    "\n",
    "            # Select action to perform   \n",
    "            action = dqn_white.epsilon_greedy(dqn_white.state)\n",
    "            #print(action)\n",
    "            decoded_action = str(env.decode(action))\n",
    "            stockfish.make_moves_from_current_position([decoded_action])\n",
    "\n",
    "            # Perform selected action\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            real_reward= reward\n",
    "            #pre-process next state\n",
    "            next_state = preprocess_state(next_state)\n",
    "\n",
    "            #if player removed piece from opponent, increase reward\n",
    "            if next_state[:, :,:, :6].sum() < dqn_white.state[:, :,:, :6].sum(): \n",
    "                reward += reward*abs(0.25)\n",
    "            \n",
    "            #update values in dqn class\n",
    "            dqn_white.env= env\n",
    "\n",
    "            #store the transition information\n",
    "            dqn_white.store_transition(dqn_white.state, action, reward, next_state, done)\n",
    "\n",
    "            #update current state to next state\n",
    "            dqn_white.state = next_state\n",
    "\n",
    "            #update the return\n",
    "            Return += reward\n",
    "            Real_Return += real_reward\n",
    "\n",
    "        else:  # If the step number is not even, aka odd, this means that it is the BLACK player's turn\n",
    "            decoded_action = stockfish.get_best_move()\n",
    "            action = env.encode(chess.Move.from_uci(decoded_action))\n",
    "            stockfish.make_moves_from_current_position([decoded_action])\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "\n",
    "            #pre-process next state\n",
    "            next_state = preprocess_state(next_state)\n",
    "\n",
    "            #update values in dqn class\n",
    "            dqn_white.env= env\n",
    "        \n",
    "            #store the transition information\n",
    "            dqn_white.store_transition(dqn_white.state, action, reward, next_state, done)\n",
    "            \n",
    "            #update current state to next state\n",
    "            dqn_white.state = next_state\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "    #if nÂº transitions in replay_buffer>batch_size\n",
    "    if (len(dqn_white.replay_buffer) > batch_size) & (counter % 10 == 0): # Only train each 10 steps that the agent plays\n",
    "        dqn_white.train(batch_size)\n",
    "\n",
    "    env.close()\n",
    "    print('Episode: ',evaluation_number, ', Return:', round(Return), 'Steps:', counter, 'Epsilon:', round(dqn_white.epsilon,2))\n",
    "    return reward, np.ceil(counter / 2), dqn_white.state\n",
    "\n",
    "\n",
    "def generate_BLACK_scenario(Stockfish_path, dqn_black, evaluation_number):\n",
    "    env = gym.make(\"ChessAlphaZero-v0\") # We will use Alpha Zero's numenclature for the actions encodings\n",
    "    stockfish = Stockfish(Stockfish_path)\n",
    "    stockfish.set_elo_rating(\n",
    "        100\n",
    "    )  # Default \"skill\" level is 1350, higher will increase the skill of stockfish \"player\". See more at https://en.wikipedia.org/wiki/Elo_rating_system\n",
    "    \n",
    "    #pre-process state\n",
    "    dqn_black.state = env.reset()\n",
    "    dqn_black.env= env\n",
    "    dqn_black.state = preprocess_state(dqn_black.state)\n",
    "    done = False\n",
    "    counter = 0  # Since each step represents a play in a chess game we are going to store the number of steps associated to the episode/game\n",
    "    # set return to 0\n",
    "    Return = 0 \n",
    "    Real_Return = 0\n",
    "\n",
    "    while not done:\n",
    "        if (\n",
    "            counter % 2 == 1\n",
    "        ):  # If the step number is even, this means that it is the WHITE player's turn\n",
    "            \n",
    "            #Update target model if the correct nÂº episodes has passed\n",
    "            if evaluation_number % dqn_black.update_rate == 0:\n",
    "                dqn_black.update_target_network()\n",
    "\n",
    "            # Select action to perform   \n",
    "            action = dqn_black.epsilon_greedy(dqn_black.state)\n",
    "            decoded_action = str(env.decode(action))\n",
    "            stockfish.make_moves_from_current_position([decoded_action])\n",
    "\n",
    "            # Perform selected action\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            real_reward= reward\n",
    "\n",
    "            #pre-process next state\n",
    "            next_state = preprocess_state(next_state)\n",
    "            \n",
    "            #if player removed piece from opponent, increase reward\n",
    "            if next_state[:, :,:, 6:13].sum() < dqn_black.state[:, :,:, :6].sum(): \n",
    "                reward += reward*abs(0.25)\n",
    "\n",
    "            #update values in dqn class\n",
    "            dqn_black.env= env\n",
    "\n",
    "            #store the transition information\n",
    "            dqn_black.store_transition(dqn_black.state, action, -reward, next_state, done)\n",
    "\n",
    "            #update current state to next state\n",
    "            dqn_black.state = next_state\n",
    "\n",
    "            #update the return\n",
    "            Return += reward\n",
    "            Real_Return += real_reward\n",
    "\n",
    "\n",
    "        else:  # If the step number is not even, aka odd, this means that it is the BLACK player's turn\n",
    "            decoded_action = stockfish.get_best_move()\n",
    "            action = env.encode(chess.Move.from_uci(decoded_action))\n",
    "            stockfish.make_moves_from_current_position([decoded_action])\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "\n",
    "            #pre-process next state\n",
    "            next_state = preprocess_state(next_state)\n",
    "\n",
    "            #update values in dqn class\n",
    "            dqn_black.env= env\n",
    "\n",
    "            #store the transition information\n",
    "            dqn_black.store_transition(dqn_black.state, action, reward, next_state, done)\n",
    "\n",
    "            #update current state to next state\n",
    "            dqn_black.state = next_state\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "    #if nÂº transitions in replay_buffer>batch_size\n",
    "    if (len(dqn_black.replay_buffer) > batch_size) & (counter % 10 == 0): # Only train each 10 steps that the agent plays\n",
    "        dqn_black.train(batch_size)\n",
    "\n",
    "    \n",
    "\n",
    "    env.close()\n",
    "    print('Episode: ',evaluation_number, ', Return:', round(Return), 'Steps:', counter, 'Epsilon:', round(dqn_white.epsilon,2))\n",
    "    return reward, np.ceil(counter / 2), dqn_black.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_pieces={0: \"pawn\", 1: \"horse\", 2: \"knight\", 3: \"rook\", 4: \"queen\", 5: \"king\"} #PARA TODOS\n",
    "black_pieces={6: \"pawn\", 7: \"horse\", 8: \"knight\", 9: \"rook\", 10: \"queen\", 11: \"king\"} #PARA TODOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AGENT_EVALUATION(Stockfish_path, n_evaluations=100): #changed\n",
    "    results_list = []\n",
    "    env= gym.make(\"ChessAlphaZero-v0\")\n",
    "    env.reset()\n",
    "    dqn_white= DQN((8, 8, 21), env)\n",
    "    dqn_black= DQN((8, 8, 21), env)\n",
    "    for evaluation_number in tqdm(range(n_evaluations)):\n",
    "        #print('in white scenario')\n",
    "        generate_episode = generate_WHITE_scenario\n",
    "        reward, n_steps, last_state = generate_episode(Stockfish_path, dqn_white, evaluation_number) #PARA TODOS (last_state)->retornar no generate ep\n",
    "\n",
    "        if reward == 1:\n",
    "            result = \"VICTORY\"\n",
    "        elif reward == 0:\n",
    "            result = \"DRAW\"\n",
    "        else:\n",
    "            result = \"LOSS\"\n",
    "\n",
    "        agent_pieces= last_state[:, :,:, 6:13].sum() #PARA TODOS: podem ter de ajustar para [:, :,:6]\n",
    "        opponent_pieces= last_state[:, :,:, :6].sum() #PARA TODOS: podem ter de ajustar para [:, :,:6]\n",
    "        remaining_pieces=[] #PARA TODOS\n",
    "        for piece in white_pieces: #PARA TODOS\n",
    "            remaining_pieces.append(last_state[:,:,:,piece].sum()) #PARA TODOS: podem ter de ajustar para [:, :,piece]\n",
    "        results_list.append([\"WHITE\", result, n_steps, agent_pieces, opponent_pieces, *remaining_pieces]) #PARA TODOS\n",
    "        \n",
    "        #update the epsilon\n",
    "        dqn_white.epsilon -= .005 # dqn.epsilon/num_episodes\n",
    "        dqn_white.epsilon = max(dqn_white.epsilon, 0.2) \n",
    "\n",
    "        #print('in black scenario')\n",
    "        generate_episode = generate_BLACK_scenario\n",
    "\n",
    "        reward, n_steps, last_state = generate_episode(Stockfish_path, dqn_black, evaluation_number) #PARA TODOS (last_state)->retornar no generate ep\n",
    "\n",
    "        if reward == -1:\n",
    "            result = \"VICTORY\"\n",
    "        elif reward == 0:\n",
    "            result = \"DRAW\"\n",
    "        else:\n",
    "            result = \"LOSS\"\n",
    "\n",
    "        agent_pieces= last_state[:,:,:, :6].sum() #PARA TODOS: podem ter de ajustar para [:, :,:6]\n",
    "        opponent_pieces= last_state[:, :,:, 6:13].sum() #PARA TODOS: podem ter de ajustar para [:, :,:6]\n",
    "        remaining_pieces=[] #PARA TODOS\n",
    "        for piece in black_pieces: #PARA TODOS\n",
    "            remaining_pieces.append(last_state[:,:,:,piece].sum()) #PARA TODOS: podem ter de ajustar para [:, :,piece]\n",
    "        results_list.append([\"BLACK\", result, n_steps, agent_pieces, opponent_pieces, *remaining_pieces]) #PARA TODOS\n",
    "\n",
    "        #update the epsilon\n",
    "        dqn_black.epsilon -= .005 # dqn.epsilon/num_episodes\n",
    "        dqn_black.epsilon = max(dqn_black.epsilon, 0.2) \n",
    "        \n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        results_list, columns=[\"AGENT COLOR\", \"OUTCOME\", \"N STEPS\", \"AGENT PIECES\", \"OPPONENT PIECES\", \"pawn\", \"horse\", \"knight\", \"rook\", \"queen\", \"king\"]\n",
    "    ).astype(\"int\", errors=\"ignore\")\n",
    "\n",
    "    plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "    results_group = (\n",
    "        df.groupby([\"AGENT COLOR\", \"OUTCOME\"])\n",
    "        .count()\n",
    "        .rename(columns={\"N STEPS\": \"GAMES\"})\n",
    "    )\n",
    "\n",
    "    n_games = results_group.sum()[0]\n",
    "\n",
    "    results_group = (2 * 100 * results_group / (n_games)).astype(\"int\")\n",
    "\n",
    "    viz_df = (\n",
    "        results_group.reset_index()\n",
    "        .pivot_table(index=\"AGENT COLOR\", columns=\"OUTCOME\", values=\"GAMES\")\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    viz_df.plot(kind=\"barh\", stacked=True)\n",
    "\n",
    "    plt.xlabel(\"Percentage\")\n",
    "    plt.title(f\"EVALUATION RESULTS FOR {n_games} GAMES\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return df, dqn_black, dqn_white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc95ba8274804a64af8d014a4f46b071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  0 , Return: 0 Steps: 48 Epsilon: 0.99\n",
      "Episode:  0 , Return: 0 Steps: 43 Epsilon: 0.94\n",
      "Episode:  1 , Return: 0 Steps: 28 Epsilon: 0.98\n",
      "Episode:  1 , Return: 0 Steps: 33 Epsilon: 0.94\n",
      "Episode:  2 , Return: 0 Steps: 32 Epsilon: 0.98\n",
      "Episode:  2 , Return: 0 Steps: 19 Epsilon: 0.94\n",
      "Episode:  3 , Return: 0 Steps: 46 Epsilon: 0.97\n",
      "Episode:  3 , Return: 0 Steps: 43 Epsilon: 0.94\n",
      "Episode:  4 , Return: 0 Steps: 8 Epsilon: 0.97\n",
      "Episode:  4 , Return: 0 Steps: 29 Epsilon: 0.94\n",
      "Episode:  5 , Return: 0 Steps: 46 Epsilon: 0.96\n",
      "Episode:  5 , Return: 0 Steps: 35 Epsilon: 0.94\n",
      "Episode:  6 , Return: 0 Steps: 38 Epsilon: 0.96\n",
      "Episode:  6 , Return: 0 Steps: 43 Epsilon: 0.94\n",
      "Episode:  7 , Return: 0 Steps: 8 Epsilon: 0.95\n",
      "Episode:  7 , Return: 0 Steps: 17 Epsilon: 0.94\n",
      "Episode:  8 , Return: 0 Steps: 12 Epsilon: 0.95\n",
      "Episode:  8 , Return: 0 Steps: 43 Epsilon: 0.94\n",
      "Episode:  9 , Return: 0 Steps: 8 Epsilon: 0.94\n",
      "Episode:  9 , Return: 0 Steps: 37 Epsilon: 0.94\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#number of episodes\n",
    "num_episodes = 10 #00\n",
    "\n",
    "# Define the batch size:\n",
    "batch_size = 12#8\n",
    "\n",
    "df, dqn_black, dqn_white = AGENT_EVALUATION(Stockfish_path, n_evaluations=num_episodes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_chess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DQN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39m# Define the batch size:\u001b[39;00m\n\u001b[0;32m      5\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m128\u001b[39m\n\u001b[1;32m----> 7\u001b[0m df, dqn_black, dqn_white \u001b[39m=\u001b[39m AGENT_EVALUATION(Stockfish_path, n_evaluations\u001b[39m=\u001b[39;49mnum_episodes) \n",
      "Cell \u001b[1;32mIn[26], line 5\u001b[0m, in \u001b[0;36mAGENT_EVALUATION\u001b[1;34m(Stockfish_path, n_evaluations)\u001b[0m\n\u001b[0;32m      3\u001b[0m env\u001b[39m=\u001b[39m gym\u001b[39m.\u001b[39mmake(\u001b[39m\"\u001b[39m\u001b[39mChessAlphaZero-v0\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m env\u001b[39m.\u001b[39mreset()\n\u001b[1;32m----> 5\u001b[0m dqn_white\u001b[39m=\u001b[39m DQN((\u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m21\u001b[39m), env)\n\u001b[0;32m      6\u001b[0m dqn_black\u001b[39m=\u001b[39m DQN((\u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m21\u001b[39m), env)\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m evaluation_number \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(n_evaluations)):\n\u001b[0;32m      8\u001b[0m     \u001b[39m#print('in white scenario')\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DQN' is not defined"
     ]
    }
   ],
   "source": [
    "#number of episodes\n",
    "num_episodes = 1000\n",
    "\n",
    "# Define the batch size:\n",
    "batch_size = 128\n",
    "\n",
    "df, dqn_black, dqn_white = AGENT_EVALUATION(Stockfish_path, n_evaluations=num_episodes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGENT COLOR</th>\n",
       "      <th>OUTCOME</th>\n",
       "      <th>N STEPS</th>\n",
       "      <th>AGENT PIECES</th>\n",
       "      <th>OPPONENT PIECES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHITE</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLACK</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHITE</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BLACK</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WHITE</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  AGENT COLOR OUTCOME  N STEPS  AGENT PIECES  OPPONENT PIECES\n",
       "0       WHITE    LOSS       25             8               16\n",
       "1       BLACK    LOSS       19            14                9\n",
       "2       WHITE    LOSS       18            11               14\n",
       "3       BLACK    LOSS       16            15               11\n",
       "4       WHITE    LOSS       23            10               16"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv(\"evaluation_data/deepqlearning_normal.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn_white.target_network.save('MODELS/target_chess_white.keras')\n",
    "dqn_white.main_network.save('MODELS/main_chess_white.keras')\n",
    "dqn_black.target_network.save('MODELS/target_chess_black.keras')\n",
    "dqn_black.main_network.save('MODELS/main_chess_black.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-made games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess.pgn\n",
    "import io\n",
    "\n",
    "pgn = open(\"C:/Users/isabe/Desktop/RL/Project/alphazero_stockfish_all/alphazero_vs_stockfish_all.pgn\")\n",
    "\n",
    "train_df=[]\n",
    "\n",
    "for i in range(110):\n",
    "    game=chess.pgn.read_game(pgn)\n",
    "    # Process the moves, positions in board, rewards and outcome in the game\n",
    "    moves = []\n",
    "    positions = []\n",
    "    rewards = []\n",
    "    outcome = game.headers[\"Result\"]\n",
    "    if game.headers[\"White\"]== \"AlphaZero\":\n",
    "        color= \"white\"\n",
    "    else:\n",
    "        color= \"black\"\n",
    "\n",
    "    board = game.board()\n",
    "    for move in game.mainline_moves():\n",
    "        board.push(move)\n",
    "        moves.append(move)\n",
    "        positions.append(board.fen())  # Save board position\n",
    "        \n",
    "    game_data = {\n",
    "        \"moves\": moves,\n",
    "        \"positions\": positions,\n",
    "        \"player_color\": color,\n",
    "        \"outcome\": outcome\n",
    "    }\n",
    "\n",
    "    train_df.append(game_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>moves</th>\n",
       "      <th>positions</th>\n",
       "      <th>player_color</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[g1f3, g8f6, c2c4, e7e6, b1c3, f8b4, d1c2, e8g...</td>\n",
       "      <td>[rnbqkbnr/pppppppp/8/8/8/5N2/PPPPPPPP/RNBQKB1R...</td>\n",
       "      <td>white</td>\n",
       "      <td>1-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[d2d4, g8f6, c2c4, e7e6, g1f3, b7b6, g2g3, c8b...</td>\n",
       "      <td>[rnbqkbnr/pppppppp/8/8/3P4/8/PPP1PPPP/RNBQKBNR...</td>\n",
       "      <td>white</td>\n",
       "      <td>1-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[d2d4, g8f6, c2c4, e7e6, g1f3, b7b6, g2g3, c8b...</td>\n",
       "      <td>[rnbqkbnr/pppppppp/8/8/3P4/8/PPP1PPPP/RNBQKBNR...</td>\n",
       "      <td>white</td>\n",
       "      <td>1-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[g1f3, e7e6, c2c4, g8f6, b1c3, f8b4, d1c2, e8g...</td>\n",
       "      <td>[rnbqkbnr/pppppppp/8/8/8/5N2/PPPPPPPP/RNBQKB1R...</td>\n",
       "      <td>white</td>\n",
       "      <td>1-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[d2d4, g8f6, g1f3, e7e6, c2c4, b7b6, g2g3, c8b...</td>\n",
       "      <td>[rnbqkbnr/pppppppp/8/8/3P4/8/PPP1PPPP/RNBQKBNR...</td>\n",
       "      <td>white</td>\n",
       "      <td>1-0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               moves  \\\n",
       "0  [g1f3, g8f6, c2c4, e7e6, b1c3, f8b4, d1c2, e8g...   \n",
       "1  [d2d4, g8f6, c2c4, e7e6, g1f3, b7b6, g2g3, c8b...   \n",
       "2  [d2d4, g8f6, c2c4, e7e6, g1f3, b7b6, g2g3, c8b...   \n",
       "3  [g1f3, e7e6, c2c4, g8f6, b1c3, f8b4, d1c2, e8g...   \n",
       "4  [d2d4, g8f6, g1f3, e7e6, c2c4, b7b6, g2g3, c8b...   \n",
       "\n",
       "                                           positions player_color outcome  \n",
       "0  [rnbqkbnr/pppppppp/8/8/8/5N2/PPPPPPPP/RNBQKB1R...        white     1-0  \n",
       "1  [rnbqkbnr/pppppppp/8/8/3P4/8/PPP1PPPP/RNBQKBNR...        white     1-0  \n",
       "2  [rnbqkbnr/pppppppp/8/8/3P4/8/PPP1PPPP/RNBQKBNR...        white     1-0  \n",
       "3  [rnbqkbnr/pppppppp/8/8/8/5N2/PPPPPPPP/RNBQKB1R...        white     1-0  \n",
       "4  [rnbqkbnr/pppppppp/8/8/3P4/8/PPP1PPPP/RNBQKBNR...        white     1-0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(train_df)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_pieces={0: \"pawn\", 1: \"horse\", 2: \"knight\", 3: \"rook\", 4: \"queen\", 5: \"king\"} #PARA TODOS\n",
    "black_pieces={6: \"pawn\", 7: \"horse\", 8: \"knight\", 9: \"rook\", 10: \"queen\", 11: \"king\"} #PARA TODOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WHITE_PLAYER_POLICY(env, state, step, episode):\n",
    "    encoded_move = env.encode(train_df.iloc[episode]['moves'][step])\n",
    "    return encoded_move\n",
    "\n",
    "\n",
    "def BLACK_PLAYER_POLICY(env, state, step, episode):\n",
    "    encoded_move = env.encode(train_df.iloc[episode]['moves'][step])\n",
    "    return encoded_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_state(state):\n",
    "    state_boards= np.c_[state[:,:,:14], state[:,:,-7:]] #the state we want just has the current board and the last matrices with information\n",
    "    return np.array([state_boards.reshape(8,8,21)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN:\n",
    "    def __init__(self, state_size, env):\n",
    "        #define environment\n",
    "        self.env= env\n",
    "\n",
    "        #define the state size\n",
    "        self.state_size = state_size\n",
    "        \n",
    "        #define the action size\n",
    "        self.action_size = len(env.legal_actions)\n",
    "        \n",
    "        #define the replay buffer\n",
    "        self.replay_buffer = deque(maxlen=1000)\n",
    "        \n",
    "        #define the discount factor\n",
    "        self.gamma = 0.9\n",
    "        \n",
    "        #define the epsilon value\n",
    "        self.epsilon = 0.99\n",
    "        \n",
    "        #define the update rate at which we want to update the target network\n",
    "        self.update_rate = 5\n",
    "        \n",
    "        #define the main network\n",
    "        self.main_network = self.build_network()\n",
    "        \n",
    "        #define the target network\n",
    "        self.target_network = self.build_network()\n",
    "        \n",
    "        #copy the weights of the main network to the target network\n",
    "        self.target_network.set_weights(self.main_network.get_weights())\n",
    "\n",
    "        #learning rate\n",
    "        self.learning_rate = .0001\n",
    "        \n",
    "\n",
    "    #Let's define a function called build_network which is essentially our DQN. \n",
    "\n",
    "    def build_network(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(filters=6, kernel_size=(7, 7), strides=1, activation='relu', padding='same', input_shape=self.state_size))\n",
    "        model.add(Conv2D(filters=6, kernel_size=(3, 3), strides=2, activation='relu', padding='same'))\n",
    "        model.add(Conv2D(filters=12, kernel_size=(3, 3), strides=1, activation='relu', padding='same'))\n",
    "        model.add(Conv2D(filters=12, kernel_size=(3, 3), strides=2, activation='relu', padding='same'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(216, activation='relu'))\n",
    "        model.add(Dense(self.env.action_space.n, activation=None))\n",
    "\n",
    "        model.compile(loss='mse', optimizer=Adam(learning_rate=.0001, epsilon=1e-7))\n",
    "\n",
    "\n",
    "        return model\n",
    "\n",
    "    #We learned that we train DQN by randomly sampling a minibatch of transitions from the\n",
    "    #replay buffer. So, we define a function called store_transition which stores the transition information\n",
    "    #into the replay buffer\n",
    "\n",
    "    def store_transition(self, state, action, reward, next_state, done):\n",
    "        self.replay_buffer.append((state, action, reward, next_state, done))\n",
    "        \n",
    "\n",
    "    #We learned that in DQN, to take care of exploration-exploitation trade off, we select action\n",
    "    #using the epsilon-greedy policy. So, now we define the function called epsilon_greedy\n",
    "    #for selecting action using the epsilon-greedy policy.\n",
    "    def epsilon_greedy(self, state):\n",
    "        if random.uniform(0,1) < self.epsilon:\n",
    "            legal_actions = self.env.legal_actions\n",
    "            action = np.random.choice(legal_actions)\n",
    "            return action\n",
    "        else:    \n",
    "            Q_values = self.main_network.predict(state, verbose=0)[0]\n",
    "            legal_q_values= Q_values[self.env.legal_actions]\n",
    "            action= self.env.legal_actions[np.argmax(legal_q_values)]\n",
    "            return action\n",
    "    \n",
    "    #train the network\n",
    "    def train(self, batch_size):\n",
    "        \n",
    "        minibatch = np.array(random.sample(self.replay_buffer, batch_size), dtype=object)\n",
    "\n",
    "        state_list = np.array(minibatch[:,0], dtype=object)\n",
    "        state_list = np.hstack(state_list).reshape(batch_size, 8, 8, 21)\n",
    "\n",
    "        next_state_list = np.array(minibatch[:,3])\n",
    "        next_state_list = np.hstack(next_state_list).reshape(batch_size, 8, 8, 21)\n",
    "\n",
    "        current_Q_values_list = self.main_network.predict(state_list, verbose=0)\n",
    "\n",
    "        max_q = np.amax(self.target_network.predict(next_state_list, verbose=0), axis=1)\n",
    "\n",
    "        for i, zip_ in enumerate(minibatch):\n",
    "\n",
    "            state, action, reward, next_state, done = zip_\n",
    "\n",
    "            if not done:\n",
    "                target  = reward + self.gamma * max_q[i]\n",
    "            else:\n",
    "                target = reward\n",
    "\n",
    "            updated_Q_value = target # (1 - self.learning_rate)*current_Q_values_list[i][action] + self.learning_rate*(target) # - current_Q_values_list[i][action]) # This is a different form of Q-learning (Min Q-Learning)\n",
    "\n",
    "            current_Q_values_list[i][action] = updated_Q_value\n",
    "        #train the main network\n",
    "        self.main_network.fit(state_list, current_Q_values_list, epochs=1, verbose=0)\n",
    "            \n",
    "    #update the target network weights by copying from the main network\n",
    "    def update_target_network(self):\n",
    "        self.target_network.set_weights(self.main_network.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_WHITE_scenario(Stockfish_path, dqn_white, evaluation_number):\n",
    "    env = gym.make(\"ChessAlphaZero-v0\") # We will use Alpha Zero's numenclature for the actions encodings\n",
    "    stockfish = Stockfish(Stockfish_path)\n",
    "    stockfish.set_elo_rating(\n",
    "        100\n",
    "    )  # Default \"skill\" level is 1350, higher will increase the skill of stockfish \"player\". See more at https://en.wikipedia.org/wiki/Elo_rating_system\n",
    "    \n",
    "    #pre-process state\n",
    "    dqn_white.state = env.reset()\n",
    "    dqn_white.env= env\n",
    "    dqn_white.state = preprocess_state(dqn_white.state)\n",
    "    done = False\n",
    "    counter = 0  # Since each step represents a play in a chess game we are going to store the number of steps associated to the episode/game\n",
    "    # set return to 0\n",
    "    Return = 0 \n",
    "    Real_Return = 0\n",
    "\n",
    "    while not done:\n",
    "        if (\n",
    "            counter % 2 == 0\n",
    "        ):  # If the step number is even, this means that it is the WHITE player's turn\n",
    "            #Update target model if the correct nÂº episodes has passed\n",
    "            if evaluation_number % dqn_white.update_rate == 0:\n",
    "                dqn_white.update_target_network()\n",
    "\n",
    "            # Select action to perform   \n",
    "            action = dqn_white.epsilon_greedy(dqn_white.state)\n",
    "            #print(action)\n",
    "            decoded_action = str(env.decode(action))\n",
    "            stockfish.make_moves_from_current_position([decoded_action])\n",
    "\n",
    "            # Perform selected action\n",
    "            next_state, reward, done, info = dqn_white.env.step(action)\n",
    "            real_reward= reward\n",
    "            #pre-process next state\n",
    "            next_state = preprocess_state(next_state)\n",
    "\n",
    "            #if player removed piece from opponent, increase reward (by very small ammount)\n",
    "            if next_state[:, :,:, :6].sum() < dqn_white.state[:, :,:, :6].sum(): \n",
    "                reward += 0.01\n",
    "            \n",
    "            #update values in dqn class\n",
    "            dqn_white.env= env\n",
    "\n",
    "            #store the transition information\n",
    "            dqn_white.store_transition(dqn_white.state, action, reward, next_state, done)\n",
    "\n",
    "            #update current state to next state\n",
    "            dqn_white.state = next_state\n",
    "\n",
    "            #update the return\n",
    "            Return += reward\n",
    "            Real_Return += real_reward\n",
    "\n",
    "\n",
    "        else:  # If the step number is not even, aka odd, this means that it is the BLACK player's turn\n",
    "            decoded_action = stockfish.get_best_move()\n",
    "            action = env.encode(chess.Move.from_uci(decoded_action))\n",
    "            stockfish.make_moves_from_current_position([decoded_action])\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "\n",
    "            #pre-process next state\n",
    "            next_state = preprocess_state(next_state)\n",
    "\n",
    "            #update values in dqn class\n",
    "            dqn_white.env= env\n",
    "\n",
    "            #store the transition information\n",
    "            dqn_white.store_transition(dqn_white.state, action, reward, next_state, done)\n",
    "            \n",
    "            #update current state to next state\n",
    "            dqn_white.state = next_state\n",
    "\n",
    "\n",
    "        #if nÂº transitions in replay_buffer>batch_size\n",
    "            if (len(dqn_white.replay_buffer) > batch_size) & (counter % 10 == 0): # Only train each 10 steps that the agent plays\n",
    "                dqn_white.train(batch_size)\n",
    "\n",
    "        counter += 1\n",
    "        \n",
    "    env.close()\n",
    "    print('Episode: ',evaluation_number, ', Return:', round(reward), 'Steps:', counter, 'Epsilon:', round(dqn_white.epsilon,2))\n",
    "    return reward, np.ceil(counter / 2), dqn_white.state\n",
    "\n",
    "\n",
    "def generate_BLACK_scenario(Stockfish_path, dqn_black, evaluation_number):\n",
    "    env = gym.make(\"ChessAlphaZero-v0\") # We will use Alpha Zero's numenclature for the actions encodings\n",
    "    stockfish = Stockfish(Stockfish_path)\n",
    "    stockfish.set_elo_rating(\n",
    "        100\n",
    "    )  # Default \"skill\" level is 1350, higher will increase the skill of stockfish \"player\". See more at https://en.wikipedia.org/wiki/Elo_rating_system\n",
    "    \n",
    "    #pre-process state\n",
    "    dqn_black.state = env.reset()\n",
    "    dqn_black.env= env\n",
    "    dqn_black.state = preprocess_state(dqn_black.state)\n",
    "    done = False\n",
    "    counter = 0  # Since each step represents a play in a chess game we are going to store the number of steps associated to the episode/game\n",
    "    # set return to 0\n",
    "    Return = 0 \n",
    "    Real_Return = 0\n",
    "\n",
    "    while not done:\n",
    "        if (\n",
    "            counter % 2 == 1\n",
    "        ):  # If the step number is even, this means that it is the WHITE player's turn\n",
    "            \n",
    "            #Update target model if the correct nÂº episodes has passed\n",
    "            if evaluation_number % dqn_black.update_rate == 0:\n",
    "                dqn_black.update_target_network()\n",
    "\n",
    "            # Select action to perform   \n",
    "            action = dqn_black.epsilon_greedy(dqn_black.state)\n",
    "            decoded_action = str(env.decode(action))\n",
    "            stockfish.make_moves_from_current_position([decoded_action])\n",
    "\n",
    "            # Perform selected action\n",
    "            next_state, reward, done, info = dqn_black.env.step(action)\n",
    "            real_reward= reward\n",
    "\n",
    "            #pre-process next state\n",
    "            next_state = preprocess_state(next_state)\n",
    "            \n",
    "            #if player removed piece from opponent, increase reward\n",
    "            if next_state[:, :,:, 6:13].sum() < dqn_black.state[:, :,:, :6].sum(): \n",
    "                reward -= 0.01\n",
    "\n",
    "            #update values in dqn class\n",
    "            dqn_black.env= env\n",
    "\n",
    "            #store the transition information\n",
    "            #reward negative because -1 is black win\n",
    "            dqn_black.store_transition(dqn_black.state, action, -reward, next_state, done)\n",
    "\n",
    "            #update current state to next state\n",
    "            dqn_black.state = next_state\n",
    "\n",
    "            #update the return\n",
    "            Return += reward\n",
    "            Real_Return += real_reward\n",
    "\n",
    "\n",
    "        else:  # If the step number is not even, aka odd, this means that it is the BLACK player's turn\n",
    "            decoded_action = stockfish.get_best_move()\n",
    "            action = env.encode(chess.Move.from_uci(decoded_action))\n",
    "            stockfish.make_moves_from_current_position([decoded_action])\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "\n",
    "            #pre-process next state\n",
    "            next_state = preprocess_state(next_state)\n",
    "\n",
    "            #update values in dqn class\n",
    "            dqn_black.env= env\n",
    "        \n",
    "            #store the transition information\n",
    "            dqn_black.store_transition(dqn_black.state, action, -reward, next_state, done)\n",
    "            \n",
    "            #update current state to next state\n",
    "            dqn_black.state = next_state\n",
    "            \n",
    "\n",
    "        #if nÂº transitions in replay_buffer>batch_size\n",
    "        if (len(dqn_black.replay_buffer) > batch_size) & (counter % 10 == 0): # Only train each 10 steps that the agent plays\n",
    "            dqn_black.train(batch_size)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "    env.close()\n",
    "    print('Episode: ',evaluation_number, ', Return:', round(reward), 'Steps:', counter, 'Epsilon:', round(dqn_black.epsilon,2))\n",
    "    return reward, np.ceil(counter / 2), dqn_black.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AGENT_EVALUATION(Stockfish_path, n_evaluations=100): #changed\n",
    "    results_list = []\n",
    "    env= gym.make(\"ChessAlphaZero-v0\")\n",
    "    env.reset()\n",
    "    dqn_white= DQN((8, 8, 21), env)\n",
    "    dqn_black= DQN((8, 8, 21), env)\n",
    "    for game in range(len(train_df)):\n",
    "        env = gym.make(\n",
    "            \"ChessAlphaZero-v0\"\n",
    "        )  # We will use Alpha Zero's numenclature for the actions encodings\n",
    "        dqn_white.state = env.reset()\n",
    "        dqn_white.env= env\n",
    "        dqn_white.state = preprocess_state(dqn_white.state)\n",
    "\n",
    "        dqn_black.state = env.reset()\n",
    "        dqn_black.env= env\n",
    "        dqn_black.state = preprocess_state(dqn_black.state)\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        counter = 0  # Since each step represents a play in a chess game we are going to store the number of steps associated to the episode/game\n",
    "        while not done:\n",
    "            if (\n",
    "                counter % 2 == 0\n",
    "            ):  # If the step number is even, this means that it is the WHITE player's turn\n",
    "                \n",
    "                action = WHITE_PLAYER_POLICY(env, state, counter, game)\n",
    "\n",
    "                #perform action\n",
    "                next_state, reward, done, info = dqn_white.env.step(action)\n",
    "\n",
    "                if counter == len(train_df.iloc[game]['moves'])-1: #last move of the game\n",
    "                    done= True\n",
    "                    if train_df.iloc[game]['outcome']== \"1-0\":\n",
    "                        reward= 1\n",
    "                    elif train_df.iloc[game]['outcome']== \"1/2-1/2\":\n",
    "                        reward= 0\n",
    "                    else:\n",
    "                        reward= -1\n",
    "                \n",
    "                #save state in the right format\n",
    "                next_state = preprocess_state(next_state)\n",
    "\n",
    "                #store the transition information\n",
    "                dqn_white.store_transition(dqn_white.state, action, reward, next_state, done)\n",
    "\n",
    "                #update current state to next state\n",
    "                dqn_white.state = next_state\n",
    "\n",
    "            else:  # If the step number is not even, aka odd, this means that it is the BLACK player's turn\n",
    "                action = BLACK_PLAYER_POLICY(env, state, counter, game)\n",
    "\n",
    "                #perform action\n",
    "                next_state, reward, done, info = dqn_black.env.step(action)\n",
    "\n",
    "                if counter == len(train_df.iloc[game]['moves'])-1: #last move of the game\n",
    "                    done= True\n",
    "                    if train_df.iloc[game]['outcome']== \"0-1\":\n",
    "                        reward= 1\n",
    "                    elif train_df.iloc[game]['outcome']== \"1/2-1/2\":\n",
    "                        reward= 0\n",
    "                    else:\n",
    "                        reward = -1\n",
    "                \n",
    "                #save state in the right format\n",
    "                next_state = preprocess_state(next_state)\n",
    "\n",
    "                #store the transition information\n",
    "                dqn_black.store_transition(dqn_black.state, action, -reward, next_state, done)\n",
    "\n",
    "                #update current state to next state\n",
    "                dqn_black.state = next_state\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "        dqn_white.env.close()   \n",
    "        dqn_black.env.close()          \n",
    "\n",
    "\n",
    "    for evaluation_number in tqdm(range(n_evaluations)): #PARA TODOS\n",
    "        #print('in white scenario')\n",
    "        generate_episode = generate_WHITE_scenario\n",
    "        reward, n_steps, last_state = generate_episode(Stockfish_path, dqn_white, evaluation_number) #PARA TODOS (last_state)->retornar no generate ep\n",
    "\n",
    "        if reward == 1:\n",
    "            result = \"VICTORY\"\n",
    "        elif reward == 0:\n",
    "            result = \"DRAW\"\n",
    "        else:\n",
    "            result = \"LOSS\"\n",
    "\n",
    "        agent_pieces= last_state[:, :,:, 6:13].sum() #PARA TODOS: podem ter de ajustar para [:, :,:6]\n",
    "        opponent_pieces= last_state[:, :,:, :6].sum() #PARA TODOS: podem ter de ajustar para [:, :,:6]\n",
    "        remaining_pieces=[] #PARA TODOS\n",
    "        for piece in white_pieces: #PARA TODOS\n",
    "            remaining_pieces.append(last_state[:,:,:,piece].sum()) #PARA TODOS: podem ter de ajustar para [:, :,piece]\n",
    "        results_list.append([\"WHITE\", result, n_steps, agent_pieces, opponent_pieces, evaluation_number, *remaining_pieces]) #PARA TODOS\n",
    "        \n",
    "        #update the epsilon\n",
    "        dqn_white.epsilon -= .005 # dqn.epsilon/num_episodes\n",
    "        dqn_white.epsilon = max(dqn_white.epsilon, 0.2) \n",
    "\n",
    "        #print('in black scenario')\n",
    "        generate_episode = generate_BLACK_scenario\n",
    "\n",
    "        reward, n_steps, last_state = generate_episode(Stockfish_path, dqn_black, evaluation_number) #PARA TODOS (last_state)->retornar no generate ep\n",
    "\n",
    "        if reward == -1:\n",
    "            result = \"VICTORY\"\n",
    "        elif reward == 0:\n",
    "            result = \"DRAW\"\n",
    "        else:\n",
    "            result = \"LOSS\"\n",
    "\n",
    "        agent_pieces= last_state[:,:,:, :6].sum() #PARA TODOS: podem ter de ajustar para [:, :,:6]\n",
    "        opponent_pieces= last_state[:, :,:, 6:13].sum() #PARA TODOS: podem ter de ajustar para [:, :,:6]\n",
    "        remaining_pieces=[] #PARA TODOS\n",
    "        for piece in black_pieces: #PARA TODOS\n",
    "            remaining_pieces.append(last_state[:,:,:,piece].sum()) #PARA TODOS: podem ter de ajustar para [:, :,piece]\n",
    "        results_list.append([\"BLACK\", result, n_steps, agent_pieces, opponent_pieces, evaluation_number, *remaining_pieces]) #PARA TODOS\n",
    "\n",
    "        #update the epsilon\n",
    "        dqn_black.epsilon -= .005 # dqn.epsilon/num_episodes\n",
    "        dqn_black.epsilon = max(dqn_black.epsilon, 0.2) \n",
    "        \n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        results_list, columns=[\"AGENT COLOR\", \"OUTCOME\", \"N STEPS\", \"AGENT PIECES\", \"OPPONENT PIECES\", \"EPISODE\", \"pawn\", \"horse\", \"knight\", \"rook\", \"queen\", \"king\"]  #PARA TODOS\n",
    "    ).astype(\"int\", errors=\"ignore\")\n",
    "\n",
    "    plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "    results_group = (\n",
    "        df.groupby([\"AGENT COLOR\", \"OUTCOME\"])\n",
    "        .count()\n",
    "        .rename(columns={\"N STEPS\": \"GAMES\"})\n",
    "    )\n",
    "\n",
    "    n_games = results_group.sum()[0]\n",
    "\n",
    "    results_group = (2 * 100 * results_group / (n_games)).astype(\"int\")\n",
    "\n",
    "    viz_df = (\n",
    "        results_group.reset_index()\n",
    "        .pivot_table(index=\"AGENT COLOR\", columns=\"OUTCOME\", values=\"GAMES\")\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    viz_df.plot(kind=\"barh\", stacked=True)\n",
    "\n",
    "    plt.xlabel(\"Percentage\")\n",
    "    plt.title(f\"EVALUATION RESULTS FOR {n_games} GAMES\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return df, dqn_black, dqn_white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db6b739159a4fa6992063fbfdb47015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  0 , Return: -1 Steps: 26 Epsilon: 0.99\n",
      "Episode:  0 , Return: 1 Steps: 45 Epsilon: 0.99\n",
      "Episode:  1 , Return: -1 Steps: 42 Epsilon: 0.98\n",
      "Episode:  1 , Return: 1 Steps: 59 Epsilon: 0.98\n",
      "Episode:  2 , Return: -1 Steps: 36 Epsilon: 0.98\n",
      "Episode:  2 , Return: 1 Steps: 57 Epsilon: 0.98\n",
      "Episode:  3 , Return: -1 Steps: 50 Epsilon: 0.97\n",
      "Episode:  3 , Return: 1 Steps: 43 Epsilon: 0.97\n",
      "Episode:  4 , Return: -1 Steps: 32 Epsilon: 0.97\n",
      "Episode:  4 , Return: 1 Steps: 61 Epsilon: 0.97\n",
      "Episode:  5 , Return: -1 Steps: 30 Epsilon: 0.96\n",
      "Episode:  5 , Return: 1 Steps: 31 Epsilon: 0.96\n",
      "Episode:  6 , Return: -1 Steps: 40 Epsilon: 0.96\n",
      "Episode:  6 , Return: 1 Steps: 55 Epsilon: 0.96\n",
      "Episode:  7 , Return: -1 Steps: 26 Epsilon: 0.95\n",
      "Episode:  7 , Return: 1 Steps: 33 Epsilon: 0.95\n",
      "Episode:  8 , Return: -1 Steps: 56 Epsilon: 0.95\n",
      "Episode:  8 , Return: 1 Steps: 29 Epsilon: 0.95\n",
      "Episode:  9 , Return: -1 Steps: 38 Epsilon: 0.94\n",
      "Episode:  9 , Return: 1 Steps: 25 Epsilon: 0.94\n",
      "Episode:  10 , Return: -1 Steps: 32 Epsilon: 0.94\n",
      "Episode:  10 , Return: 1 Steps: 25 Epsilon: 0.94\n",
      "Episode:  11 , Return: -1 Steps: 34 Epsilon: 0.93\n",
      "Episode:  11 , Return: 1 Steps: 31 Epsilon: 0.93\n",
      "Episode:  12 , Return: -1 Steps: 40 Epsilon: 0.93\n",
      "Episode:  12 , Return: 1 Steps: 63 Epsilon: 0.93\n",
      "Episode:  13 , Return: -1 Steps: 40 Epsilon: 0.92\n",
      "Episode:  13 , Return: 1 Steps: 33 Epsilon: 0.92\n",
      "Episode:  14 , Return: -1 Steps: 56 Epsilon: 0.92\n",
      "Episode:  14 , Return: 1 Steps: 37 Epsilon: 0.92\n",
      "Episode:  15 , Return: -1 Steps: 26 Epsilon: 0.91\n",
      "Episode:  15 , Return: 1 Steps: 33 Epsilon: 0.91\n",
      "Episode:  16 , Return: -1 Steps: 44 Epsilon: 0.91\n",
      "Episode:  16 , Return: 1 Steps: 31 Epsilon: 0.91\n",
      "Episode:  17 , Return: -1 Steps: 36 Epsilon: 0.9\n",
      "Episode:  17 , Return: 1 Steps: 45 Epsilon: 0.9\n",
      "Episode:  18 , Return: -1 Steps: 38 Epsilon: 0.9\n",
      "Episode:  18 , Return: 1 Steps: 43 Epsilon: 0.9\n",
      "Episode:  19 , Return: -1 Steps: 22 Epsilon: 0.89\n",
      "Episode:  19 , Return: 1 Steps: 39 Epsilon: 0.89\n",
      "Episode:  20 , Return: -1 Steps: 38 Epsilon: 0.89\n",
      "Episode:  20 , Return: 1 Steps: 47 Epsilon: 0.89\n",
      "Episode:  21 , Return: -1 Steps: 46 Epsilon: 0.88\n",
      "Episode:  21 , Return: 1 Steps: 43 Epsilon: 0.88\n",
      "Episode:  22 , Return: -1 Steps: 20 Epsilon: 0.88\n",
      "Episode:  22 , Return: 1 Steps: 27 Epsilon: 0.88\n",
      "Episode:  23 , Return: -1 Steps: 32 Epsilon: 0.87\n",
      "Episode:  23 , Return: 1 Steps: 21 Epsilon: 0.87\n",
      "Episode:  24 , Return: -1 Steps: 44 Epsilon: 0.87\n",
      "Episode:  24 , Return: 1 Steps: 61 Epsilon: 0.87\n",
      "Episode:  25 , Return: -1 Steps: 46 Epsilon: 0.86\n",
      "Episode:  25 , Return: 1 Steps: 61 Epsilon: 0.86\n",
      "Episode:  26 , Return: -1 Steps: 30 Epsilon: 0.86\n",
      "Episode:  26 , Return: 1 Steps: 43 Epsilon: 0.86\n",
      "Episode:  27 , Return: -1 Steps: 40 Epsilon: 0.85\n",
      "Episode:  27 , Return: 1 Steps: 29 Epsilon: 0.85\n",
      "Episode:  28 , Return: -1 Steps: 30 Epsilon: 0.85\n",
      "Episode:  28 , Return: 1 Steps: 35 Epsilon: 0.85\n",
      "Episode:  29 , Return: -1 Steps: 32 Epsilon: 0.84\n",
      "Episode:  29 , Return: 1 Steps: 31 Epsilon: 0.84\n",
      "Episode:  30 , Return: -1 Steps: 40 Epsilon: 0.84\n",
      "Episode:  30 , Return: 1 Steps: 41 Epsilon: 0.84\n",
      "Episode:  31 , Return: -1 Steps: 38 Epsilon: 0.83\n",
      "Episode:  31 , Return: 1 Steps: 35 Epsilon: 0.83\n",
      "Episode:  32 , Return: -1 Steps: 42 Epsilon: 0.83\n",
      "Episode:  32 , Return: 1 Steps: 41 Epsilon: 0.83\n",
      "Episode:  33 , Return: -1 Steps: 28 Epsilon: 0.82\n",
      "Episode:  33 , Return: 1 Steps: 51 Epsilon: 0.82\n",
      "Episode:  34 , Return: -1 Steps: 42 Epsilon: 0.82\n",
      "Episode:  34 , Return: 1 Steps: 49 Epsilon: 0.82\n",
      "Episode:  35 , Return: -1 Steps: 50 Epsilon: 0.81\n",
      "Episode:  35 , Return: 1 Steps: 15 Epsilon: 0.81\n",
      "Episode:  36 , Return: -1 Steps: 24 Epsilon: 0.81\n",
      "Episode:  36 , Return: 1 Steps: 21 Epsilon: 0.81\n",
      "Episode:  37 , Return: -1 Steps: 26 Epsilon: 0.8\n",
      "Episode:  37 , Return: 1 Steps: 31 Epsilon: 0.8\n",
      "Episode:  38 , Return: -1 Steps: 36 Epsilon: 0.8\n",
      "Episode:  38 , Return: 1 Steps: 47 Epsilon: 0.8\n",
      "Episode:  39 , Return: -1 Steps: 28 Epsilon: 0.79\n",
      "Episode:  39 , Return: 1 Steps: 47 Epsilon: 0.79\n",
      "Episode:  40 , Return: -1 Steps: 32 Epsilon: 0.79\n",
      "Episode:  40 , Return: 1 Steps: 55 Epsilon: 0.79\n",
      "Episode:  41 , Return: -1 Steps: 32 Epsilon: 0.78\n",
      "Episode:  41 , Return: 1 Steps: 35 Epsilon: 0.78\n",
      "Episode:  42 , Return: -1 Steps: 30 Epsilon: 0.78\n",
      "Episode:  42 , Return: 1 Steps: 41 Epsilon: 0.78\n",
      "Episode:  43 , Return: -1 Steps: 50 Epsilon: 0.77\n",
      "Episode:  43 , Return: 1 Steps: 57 Epsilon: 0.77\n",
      "Episode:  44 , Return: -1 Steps: 30 Epsilon: 0.77\n",
      "Episode:  44 , Return: 1 Steps: 39 Epsilon: 0.77\n",
      "Episode:  45 , Return: -1 Steps: 36 Epsilon: 0.76\n",
      "Episode:  45 , Return: 1 Steps: 33 Epsilon: 0.76\n",
      "Episode:  46 , Return: -1 Steps: 44 Epsilon: 0.76\n",
      "Episode:  46 , Return: 1 Steps: 49 Epsilon: 0.76\n",
      "Episode:  47 , Return: -1 Steps: 28 Epsilon: 0.75\n",
      "Episode:  47 , Return: 1 Steps: 35 Epsilon: 0.75\n",
      "Episode:  48 , Return: -1 Steps: 48 Epsilon: 0.75\n",
      "Episode:  48 , Return: 1 Steps: 21 Epsilon: 0.75\n",
      "Episode:  49 , Return: -1 Steps: 44 Epsilon: 0.74\n",
      "Episode:  49 , Return: 1 Steps: 27 Epsilon: 0.74\n",
      "Episode:  50 , Return: -1 Steps: 20 Epsilon: 0.74\n",
      "Episode:  50 , Return: 1 Steps: 27 Epsilon: 0.74\n",
      "Episode:  51 , Return: -1 Steps: 44 Epsilon: 0.73\n",
      "Episode:  51 , Return: 1 Steps: 17 Epsilon: 0.73\n",
      "Episode:  52 , Return: -1 Steps: 42 Epsilon: 0.73\n",
      "Episode:  52 , Return: 1 Steps: 33 Epsilon: 0.73\n",
      "Episode:  53 , Return: -1 Steps: 18 Epsilon: 0.72\n",
      "Episode:  53 , Return: 1 Steps: 23 Epsilon: 0.72\n",
      "Episode:  54 , Return: -1 Steps: 34 Epsilon: 0.72\n",
      "Episode:  54 , Return: 1 Steps: 43 Epsilon: 0.72\n",
      "Episode:  55 , Return: -1 Steps: 34 Epsilon: 0.71\n",
      "Episode:  55 , Return: 1 Steps: 31 Epsilon: 0.71\n",
      "Episode:  56 , Return: -1 Steps: 62 Epsilon: 0.71\n",
      "Episode:  56 , Return: 1 Steps: 37 Epsilon: 0.71\n",
      "Episode:  57 , Return: -1 Steps: 24 Epsilon: 0.7\n",
      "Episode:  57 , Return: 1 Steps: 9 Epsilon: 0.7\n",
      "Episode:  58 , Return: -1 Steps: 28 Epsilon: 0.7\n",
      "Episode:  58 , Return: 1 Steps: 11 Epsilon: 0.7\n",
      "Episode:  59 , Return: -1 Steps: 46 Epsilon: 0.69\n",
      "Episode:  59 , Return: 1 Steps: 43 Epsilon: 0.69\n",
      "Episode:  60 , Return: -1 Steps: 26 Epsilon: 0.69\n",
      "Episode:  60 , Return: 1 Steps: 43 Epsilon: 0.69\n",
      "Episode:  61 , Return: -1 Steps: 52 Epsilon: 0.68\n",
      "Episode:  61 , Return: 1 Steps: 45 Epsilon: 0.68\n",
      "Episode:  62 , Return: -1 Steps: 56 Epsilon: 0.68\n",
      "Episode:  62 , Return: 1 Steps: 39 Epsilon: 0.68\n",
      "Episode:  63 , Return: -1 Steps: 22 Epsilon: 0.67\n",
      "Episode:  63 , Return: 1 Steps: 35 Epsilon: 0.67\n",
      "Episode:  64 , Return: -1 Steps: 30 Epsilon: 0.67\n",
      "Episode:  64 , Return: 1 Steps: 31 Epsilon: 0.67\n",
      "Episode:  65 , Return: -1 Steps: 38 Epsilon: 0.66\n",
      "Episode:  65 , Return: 1 Steps: 47 Epsilon: 0.66\n",
      "Episode:  66 , Return: -1 Steps: 42 Epsilon: 0.66\n",
      "Episode:  66 , Return: 1 Steps: 33 Epsilon: 0.66\n",
      "Episode:  67 , Return: -1 Steps: 26 Epsilon: 0.65\n",
      "Episode:  67 , Return: 1 Steps: 43 Epsilon: 0.65\n",
      "Episode:  68 , Return: -1 Steps: 48 Epsilon: 0.65\n",
      "Episode:  68 , Return: 1 Steps: 37 Epsilon: 0.65\n",
      "Episode:  69 , Return: -1 Steps: 50 Epsilon: 0.64\n",
      "Episode:  69 , Return: 1 Steps: 15 Epsilon: 0.64\n",
      "Episode:  70 , Return: -1 Steps: 8 Epsilon: 0.64\n",
      "Episode:  70 , Return: 1 Steps: 47 Epsilon: 0.64\n",
      "Episode:  71 , Return: -1 Steps: 46 Epsilon: 0.63\n",
      "Episode:  71 , Return: 1 Steps: 47 Epsilon: 0.63\n",
      "Episode:  72 , Return: -1 Steps: 34 Epsilon: 0.63\n",
      "Episode:  72 , Return: 1 Steps: 65 Epsilon: 0.63\n",
      "Episode:  73 , Return: -1 Steps: 38 Epsilon: 0.62\n",
      "Episode:  73 , Return: 1 Steps: 31 Epsilon: 0.62\n",
      "Episode:  74 , Return: -1 Steps: 40 Epsilon: 0.62\n",
      "Episode:  74 , Return: 1 Steps: 49 Epsilon: 0.62\n",
      "Episode:  75 , Return: -1 Steps: 24 Epsilon: 0.61\n",
      "Episode:  75 , Return: 1 Steps: 27 Epsilon: 0.61\n",
      "Episode:  76 , Return: -1 Steps: 20 Epsilon: 0.61\n",
      "Episode:  76 , Return: 1 Steps: 39 Epsilon: 0.61\n",
      "Episode:  77 , Return: -1 Steps: 34 Epsilon: 0.6\n",
      "Episode:  77 , Return: 1 Steps: 25 Epsilon: 0.6\n",
      "Episode:  78 , Return: -1 Steps: 50 Epsilon: 0.6\n",
      "Episode:  78 , Return: 1 Steps: 21 Epsilon: 0.6\n",
      "Episode:  79 , Return: -1 Steps: 28 Epsilon: 0.59\n",
      "Episode:  79 , Return: 1 Steps: 23 Epsilon: 0.59\n",
      "Episode:  80 , Return: -1 Steps: 36 Epsilon: 0.59\n",
      "Episode:  80 , Return: 1 Steps: 25 Epsilon: 0.59\n",
      "Episode:  81 , Return: -1 Steps: 50 Epsilon: 0.58\n",
      "Episode:  81 , Return: 1 Steps: 29 Epsilon: 0.58\n",
      "Episode:  82 , Return: -1 Steps: 48 Epsilon: 0.58\n",
      "Episode:  82 , Return: 1 Steps: 27 Epsilon: 0.58\n",
      "Episode:  83 , Return: -1 Steps: 34 Epsilon: 0.57\n",
      "Episode:  83 , Return: 1 Steps: 37 Epsilon: 0.57\n",
      "Episode:  84 , Return: -1 Steps: 24 Epsilon: 0.57\n",
      "Episode:  84 , Return: 1 Steps: 23 Epsilon: 0.57\n",
      "Episode:  85 , Return: -1 Steps: 36 Epsilon: 0.56\n",
      "Episode:  85 , Return: 1 Steps: 37 Epsilon: 0.56\n",
      "Episode:  86 , Return: -1 Steps: 54 Epsilon: 0.56\n",
      "Episode:  86 , Return: 1 Steps: 21 Epsilon: 0.56\n",
      "Episode:  87 , Return: -1 Steps: 38 Epsilon: 0.55\n",
      "Episode:  87 , Return: 1 Steps: 85 Epsilon: 0.55\n",
      "Episode:  88 , Return: -1 Steps: 78 Epsilon: 0.55\n",
      "Episode:  88 , Return: 1 Steps: 57 Epsilon: 0.55\n",
      "Episode:  89 , Return: -1 Steps: 58 Epsilon: 0.54\n",
      "Episode:  89 , Return: 1 Steps: 35 Epsilon: 0.54\n",
      "Episode:  90 , Return: -1 Steps: 32 Epsilon: 0.54\n",
      "Episode:  90 , Return: 1 Steps: 35 Epsilon: 0.54\n",
      "Episode:  91 , Return: -1 Steps: 16 Epsilon: 0.53\n",
      "Episode:  91 , Return: 1 Steps: 23 Epsilon: 0.53\n",
      "Episode:  92 , Return: -1 Steps: 48 Epsilon: 0.53\n",
      "Episode:  92 , Return: 1 Steps: 25 Epsilon: 0.53\n",
      "Episode:  93 , Return: -1 Steps: 16 Epsilon: 0.52\n",
      "Episode:  93 , Return: 1 Steps: 33 Epsilon: 0.52\n",
      "Episode:  94 , Return: -1 Steps: 24 Epsilon: 0.52\n",
      "Episode:  94 , Return: 1 Steps: 25 Epsilon: 0.52\n",
      "Episode:  95 , Return: -1 Steps: 50 Epsilon: 0.51\n",
      "Episode:  95 , Return: 1 Steps: 11 Epsilon: 0.51\n",
      "Episode:  96 , Return: -1 Steps: 44 Epsilon: 0.51\n",
      "Episode:  96 , Return: 1 Steps: 45 Epsilon: 0.51\n",
      "Episode:  97 , Return: -1 Steps: 30 Epsilon: 0.5\n",
      "Episode:  97 , Return: 1 Steps: 39 Epsilon: 0.5\n",
      "Episode:  98 , Return: -1 Steps: 24 Epsilon: 0.5\n",
      "Episode:  98 , Return: 1 Steps: 33 Epsilon: 0.5\n",
      "Episode:  99 , Return: -1 Steps: 34 Epsilon: 0.49\n",
      "Episode:  99 , Return: 1 Steps: 67 Epsilon: 0.49\n",
      "Episode:  100 , Return: -1 Steps: 38 Epsilon: 0.49\n",
      "Episode:  100 , Return: 1 Steps: 31 Epsilon: 0.49\n",
      "Episode:  101 , Return: -1 Steps: 46 Epsilon: 0.48\n",
      "Episode:  101 , Return: 1 Steps: 61 Epsilon: 0.48\n",
      "Episode:  102 , Return: -1 Steps: 42 Epsilon: 0.48\n",
      "Episode:  102 , Return: 1 Steps: 25 Epsilon: 0.48\n",
      "Episode:  103 , Return: -1 Steps: 26 Epsilon: 0.47\n",
      "Episode:  103 , Return: 1 Steps: 17 Epsilon: 0.47\n",
      "Episode:  104 , Return: -1 Steps: 36 Epsilon: 0.47\n",
      "Episode:  104 , Return: 1 Steps: 29 Epsilon: 0.47\n",
      "Episode:  105 , Return: -1 Steps: 30 Epsilon: 0.46\n",
      "Episode:  105 , Return: 1 Steps: 63 Epsilon: 0.46\n",
      "Episode:  106 , Return: -1 Steps: 46 Epsilon: 0.46\n",
      "Episode:  106 , Return: 1 Steps: 19 Epsilon: 0.46\n",
      "Episode:  107 , Return: -1 Steps: 32 Epsilon: 0.45\n",
      "Episode:  107 , Return: 1 Steps: 51 Epsilon: 0.45\n",
      "Episode:  108 , Return: -1 Steps: 38 Epsilon: 0.45\n",
      "Episode:  108 , Return: 1 Steps: 21 Epsilon: 0.45\n",
      "Episode:  109 , Return: -1 Steps: 42 Epsilon: 0.44\n",
      "Episode:  109 , Return: 1 Steps: 21 Epsilon: 0.44\n",
      "Episode:  110 , Return: -1 Steps: 38 Epsilon: 0.44\n",
      "Episode:  110 , Return: 1 Steps: 27 Epsilon: 0.44\n",
      "Episode:  111 , Return: -1 Steps: 38 Epsilon: 0.43\n",
      "Episode:  111 , Return: 1 Steps: 31 Epsilon: 0.43\n",
      "Episode:  112 , Return: -1 Steps: 34 Epsilon: 0.43\n",
      "Episode:  112 , Return: 1 Steps: 55 Epsilon: 0.43\n",
      "Episode:  113 , Return: -1 Steps: 28 Epsilon: 0.42\n",
      "Episode:  113 , Return: 1 Steps: 23 Epsilon: 0.42\n",
      "Episode:  114 , Return: -1 Steps: 50 Epsilon: 0.42\n",
      "Episode:  114 , Return: 1 Steps: 15 Epsilon: 0.42\n",
      "Episode:  115 , Return: -1 Steps: 44 Epsilon: 0.41\n",
      "Episode:  115 , Return: 1 Steps: 43 Epsilon: 0.41\n",
      "Episode:  116 , Return: -1 Steps: 40 Epsilon: 0.41\n",
      "Episode:  116 , Return: 1 Steps: 31 Epsilon: 0.41\n",
      "Episode:  117 , Return: -1 Steps: 24 Epsilon: 0.4\n",
      "Episode:  117 , Return: 1 Steps: 39 Epsilon: 0.4\n",
      "Episode:  118 , Return: -1 Steps: 24 Epsilon: 0.4\n",
      "Episode:  118 , Return: 1 Steps: 59 Epsilon: 0.4\n",
      "Episode:  119 , Return: -1 Steps: 18 Epsilon: 0.39\n",
      "Episode:  119 , Return: 1 Steps: 19 Epsilon: 0.39\n",
      "Episode:  120 , Return: -1 Steps: 38 Epsilon: 0.39\n",
      "Episode:  120 , Return: 1 Steps: 47 Epsilon: 0.39\n",
      "Episode:  121 , Return: -1 Steps: 26 Epsilon: 0.38\n",
      "Episode:  121 , Return: 1 Steps: 15 Epsilon: 0.38\n",
      "Episode:  122 , Return: -1 Steps: 42 Epsilon: 0.38\n",
      "Episode:  122 , Return: 1 Steps: 55 Epsilon: 0.38\n",
      "Episode:  123 , Return: -1 Steps: 32 Epsilon: 0.37\n",
      "Episode:  123 , Return: 1 Steps: 45 Epsilon: 0.37\n",
      "Episode:  124 , Return: -1 Steps: 16 Epsilon: 0.37\n",
      "Episode:  124 , Return: 1 Steps: 51 Epsilon: 0.37\n",
      "Episode:  125 , Return: -1 Steps: 56 Epsilon: 0.36\n",
      "Episode:  125 , Return: 1 Steps: 53 Epsilon: 0.36\n",
      "Episode:  126 , Return: -1 Steps: 42 Epsilon: 0.36\n",
      "Episode:  126 , Return: 1 Steps: 37 Epsilon: 0.36\n",
      "Episode:  127 , Return: -1 Steps: 24 Epsilon: 0.35\n",
      "Episode:  127 , Return: 1 Steps: 23 Epsilon: 0.35\n",
      "Episode:  128 , Return: -1 Steps: 48 Epsilon: 0.35\n",
      "Episode:  128 , Return: 1 Steps: 37 Epsilon: 0.35\n",
      "Episode:  129 , Return: -1 Steps: 26 Epsilon: 0.34\n",
      "Episode:  129 , Return: 1 Steps: 23 Epsilon: 0.34\n",
      "Episode:  130 , Return: -1 Steps: 30 Epsilon: 0.34\n",
      "Episode:  130 , Return: 1 Steps: 55 Epsilon: 0.34\n",
      "Episode:  131 , Return: -1 Steps: 54 Epsilon: 0.33\n",
      "Episode:  131 , Return: 1 Steps: 39 Epsilon: 0.33\n",
      "Episode:  132 , Return: -1 Steps: 32 Epsilon: 0.33\n",
      "Episode:  132 , Return: 1 Steps: 35 Epsilon: 0.33\n",
      "Episode:  133 , Return: -1 Steps: 64 Epsilon: 0.32\n",
      "Episode:  133 , Return: 1 Steps: 39 Epsilon: 0.32\n",
      "Episode:  134 , Return: -1 Steps: 38 Epsilon: 0.32\n",
      "Episode:  134 , Return: 1 Steps: 39 Epsilon: 0.32\n",
      "Episode:  135 , Return: -1 Steps: 36 Epsilon: 0.31\n",
      "Episode:  135 , Return: 1 Steps: 43 Epsilon: 0.31\n",
      "Episode:  136 , Return: -1 Steps: 38 Epsilon: 0.31\n",
      "Episode:  136 , Return: 1 Steps: 49 Epsilon: 0.31\n",
      "Episode:  137 , Return: -1 Steps: 22 Epsilon: 0.3\n",
      "Episode:  137 , Return: 1 Steps: 57 Epsilon: 0.3\n",
      "Episode:  138 , Return: -1 Steps: 24 Epsilon: 0.3\n",
      "Episode:  138 , Return: 1 Steps: 55 Epsilon: 0.3\n",
      "Episode:  139 , Return: -1 Steps: 38 Epsilon: 0.29\n",
      "Episode:  139 , Return: 1 Steps: 33 Epsilon: 0.29\n",
      "Episode:  140 , Return: -1 Steps: 32 Epsilon: 0.29\n",
      "Episode:  140 , Return: 1 Steps: 13 Epsilon: 0.29\n",
      "Episode:  141 , Return: -1 Steps: 52 Epsilon: 0.28\n",
      "Episode:  141 , Return: 1 Steps: 43 Epsilon: 0.28\n",
      "Episode:  142 , Return: -1 Steps: 46 Epsilon: 0.28\n",
      "Episode:  142 , Return: 1 Steps: 25 Epsilon: 0.28\n",
      "Episode:  143 , Return: -1 Steps: 34 Epsilon: 0.27\n",
      "Episode:  143 , Return: 1 Steps: 43 Epsilon: 0.27\n",
      "Episode:  144 , Return: -1 Steps: 46 Epsilon: 0.27\n",
      "Episode:  144 , Return: 1 Steps: 55 Epsilon: 0.27\n",
      "Episode:  145 , Return: -1 Steps: 22 Epsilon: 0.26\n",
      "Episode:  145 , Return: 1 Steps: 51 Epsilon: 0.26\n",
      "Episode:  146 , Return: -1 Steps: 34 Epsilon: 0.26\n",
      "Episode:  146 , Return: 1 Steps: 21 Epsilon: 0.26\n",
      "Episode:  147 , Return: -1 Steps: 26 Epsilon: 0.25\n",
      "Episode:  147 , Return: 1 Steps: 27 Epsilon: 0.25\n",
      "Episode:  148 , Return: -1 Steps: 28 Epsilon: 0.25\n",
      "Episode:  148 , Return: 1 Steps: 51 Epsilon: 0.25\n",
      "Episode:  149 , Return: -1 Steps: 30 Epsilon: 0.24\n",
      "Episode:  149 , Return: 1 Steps: 29 Epsilon: 0.24\n",
      "Episode:  150 , Return: -1 Steps: 34 Epsilon: 0.24\n",
      "Episode:  150 , Return: 1 Steps: 33 Epsilon: 0.24\n",
      "Episode:  151 , Return: -1 Steps: 34 Epsilon: 0.23\n",
      "Episode:  151 , Return: 1 Steps: 29 Epsilon: 0.23\n",
      "Episode:  152 , Return: -1 Steps: 28 Epsilon: 0.23\n",
      "Episode:  152 , Return: 1 Steps: 41 Epsilon: 0.23\n",
      "Episode:  153 , Return: -1 Steps: 54 Epsilon: 0.22\n",
      "Episode:  153 , Return: 1 Steps: 45 Epsilon: 0.22\n",
      "Episode:  154 , Return: -1 Steps: 36 Epsilon: 0.22\n",
      "Episode:  154 , Return: 1 Steps: 27 Epsilon: 0.22\n",
      "Episode:  155 , Return: -1 Steps: 30 Epsilon: 0.21\n",
      "Episode:  155 , Return: 1 Steps: 39 Epsilon: 0.21\n",
      "Episode:  156 , Return: -1 Steps: 50 Epsilon: 0.21\n",
      "Episode:  156 , Return: 1 Steps: 29 Epsilon: 0.21\n",
      "Episode:  157 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  157 , Return: 1 Steps: 51 Epsilon: 0.2\n",
      "Episode:  158 , Return: -1 Steps: 50 Epsilon: 0.2\n",
      "Episode:  158 , Return: 1 Steps: 27 Epsilon: 0.2\n",
      "Episode:  159 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  159 , Return: 1 Steps: 29 Epsilon: 0.2\n",
      "Episode:  160 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  160 , Return: 1 Steps: 33 Epsilon: 0.2\n",
      "Episode:  161 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  161 , Return: 1 Steps: 61 Epsilon: 0.2\n",
      "Episode:  162 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  162 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  163 , Return: -1 Steps: 50 Epsilon: 0.2\n",
      "Episode:  163 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  164 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  164 , Return: 1 Steps: 17 Epsilon: 0.2\n",
      "Episode:  165 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  165 , Return: 1 Steps: 53 Epsilon: 0.2\n",
      "Episode:  166 , Return: -1 Steps: 44 Epsilon: 0.2\n",
      "Episode:  166 , Return: 1 Steps: 17 Epsilon: 0.2\n",
      "Episode:  167 , Return: -1 Steps: 62 Epsilon: 0.2\n",
      "Episode:  167 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  168 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  168 , Return: 1 Steps: 55 Epsilon: 0.2\n",
      "Episode:  169 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  169 , Return: 1 Steps: 45 Epsilon: 0.2\n",
      "Episode:  170 , Return: -1 Steps: 48 Epsilon: 0.2\n",
      "Episode:  170 , Return: 1 Steps: 27 Epsilon: 0.2\n",
      "Episode:  171 , Return: -1 Steps: 22 Epsilon: 0.2\n",
      "Episode:  171 , Return: 1 Steps: 21 Epsilon: 0.2\n",
      "Episode:  172 , Return: -1 Steps: 42 Epsilon: 0.2\n",
      "Episode:  172 , Return: 1 Steps: 47 Epsilon: 0.2\n",
      "Episode:  173 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  173 , Return: 1 Steps: 27 Epsilon: 0.2\n",
      "Episode:  174 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  174 , Return: 1 Steps: 51 Epsilon: 0.2\n",
      "Episode:  175 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  175 , Return: 1 Steps: 41 Epsilon: 0.2\n",
      "Episode:  176 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  176 , Return: 1 Steps: 59 Epsilon: 0.2\n",
      "Episode:  177 , Return: -1 Steps: 44 Epsilon: 0.2\n",
      "Episode:  177 , Return: 1 Steps: 29 Epsilon: 0.2\n",
      "Episode:  178 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  178 , Return: 1 Steps: 31 Epsilon: 0.2\n",
      "Episode:  179 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  179 , Return: 1 Steps: 19 Epsilon: 0.2\n",
      "Episode:  180 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  180 , Return: 1 Steps: 21 Epsilon: 0.2\n",
      "Episode:  181 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  181 , Return: 1 Steps: 35 Epsilon: 0.2\n",
      "Episode:  182 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  182 , Return: 1 Steps: 27 Epsilon: 0.2\n",
      "Episode:  183 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  183 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  184 , Return: -1 Steps: 20 Epsilon: 0.2\n",
      "Episode:  184 , Return: 1 Steps: 15 Epsilon: 0.2\n",
      "Episode:  185 , Return: -1 Steps: 48 Epsilon: 0.2\n",
      "Episode:  185 , Return: 1 Steps: 29 Epsilon: 0.2\n",
      "Episode:  186 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  186 , Return: 1 Steps: 53 Epsilon: 0.2\n",
      "Episode:  187 , Return: -1 Steps: 46 Epsilon: 0.2\n",
      "Episode:  187 , Return: 1 Steps: 25 Epsilon: 0.2\n",
      "Episode:  188 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  188 , Return: 1 Steps: 57 Epsilon: 0.2\n",
      "Episode:  189 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  189 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  190 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  190 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  191 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  191 , Return: 1 Steps: 23 Epsilon: 0.2\n",
      "Episode:  192 , Return: -1 Steps: 42 Epsilon: 0.2\n",
      "Episode:  192 , Return: 1 Steps: 15 Epsilon: 0.2\n",
      "Episode:  193 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  193 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  194 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  194 , Return: 1 Steps: 21 Epsilon: 0.2\n",
      "Episode:  195 , Return: -1 Steps: 58 Epsilon: 0.2\n",
      "Episode:  195 , Return: 1 Steps: 23 Epsilon: 0.2\n",
      "Episode:  196 , Return: -1 Steps: 64 Epsilon: 0.2\n",
      "Episode:  196 , Return: 1 Steps: 9 Epsilon: 0.2\n",
      "Episode:  197 , Return: -1 Steps: 56 Epsilon: 0.2\n",
      "Episode:  197 , Return: 1 Steps: 35 Epsilon: 0.2\n",
      "Episode:  198 , Return: -1 Steps: 62 Epsilon: 0.2\n",
      "Episode:  198 , Return: 1 Steps: 23 Epsilon: 0.2\n",
      "Episode:  199 , Return: -1 Steps: 46 Epsilon: 0.2\n",
      "Episode:  199 , Return: 1 Steps: 41 Epsilon: 0.2\n",
      "Episode:  200 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  200 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  201 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  201 , Return: 1 Steps: 23 Epsilon: 0.2\n",
      "Episode:  202 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  202 , Return: 1 Steps: 29 Epsilon: 0.2\n",
      "Episode:  203 , Return: -1 Steps: 50 Epsilon: 0.2\n",
      "Episode:  203 , Return: 1 Steps: 55 Epsilon: 0.2\n",
      "Episode:  204 , Return: -1 Steps: 22 Epsilon: 0.2\n",
      "Episode:  204 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  205 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  205 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  206 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  206 , Return: 1 Steps: 53 Epsilon: 0.2\n",
      "Episode:  207 , Return: -1 Steps: 22 Epsilon: 0.2\n",
      "Episode:  207 , Return: 1 Steps: 29 Epsilon: 0.2\n",
      "Episode:  208 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  208 , Return: 1 Steps: 25 Epsilon: 0.2\n",
      "Episode:  209 , Return: -1 Steps: 58 Epsilon: 0.2\n",
      "Episode:  209 , Return: 1 Steps: 29 Epsilon: 0.2\n",
      "Episode:  210 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  210 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  211 , Return: -1 Steps: 42 Epsilon: 0.2\n",
      "Episode:  211 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  212 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  212 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  213 , Return: -1 Steps: 48 Epsilon: 0.2\n",
      "Episode:  213 , Return: 1 Steps: 67 Epsilon: 0.2\n",
      "Episode:  214 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  214 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  215 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  215 , Return: 1 Steps: 51 Epsilon: 0.2\n",
      "Episode:  216 , Return: -1 Steps: 56 Epsilon: 0.2\n",
      "Episode:  216 , Return: 1 Steps: 27 Epsilon: 0.2\n",
      "Episode:  217 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  217 , Return: 1 Steps: 41 Epsilon: 0.2\n",
      "Episode:  218 , Return: -1 Steps: 62 Epsilon: 0.2\n",
      "Episode:  218 , Return: 1 Steps: 31 Epsilon: 0.2\n",
      "Episode:  219 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  219 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  220 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  220 , Return: 1 Steps: 35 Epsilon: 0.2\n",
      "Episode:  221 , Return: -1 Steps: 42 Epsilon: 0.2\n",
      "Episode:  221 , Return: 1 Steps: 41 Epsilon: 0.2\n",
      "Episode:  222 , Return: -1 Steps: 46 Epsilon: 0.2\n",
      "Episode:  222 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  223 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  223 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  224 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  224 , Return: 1 Steps: 53 Epsilon: 0.2\n",
      "Episode:  225 , Return: -1 Steps: 18 Epsilon: 0.2\n",
      "Episode:  225 , Return: 1 Steps: 9 Epsilon: 0.2\n",
      "Episode:  226 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  226 , Return: 1 Steps: 33 Epsilon: 0.2\n",
      "Episode:  227 , Return: -1 Steps: 22 Epsilon: 0.2\n",
      "Episode:  227 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  228 , Return: -1 Steps: 20 Epsilon: 0.2\n",
      "Episode:  228 , Return: 1 Steps: 31 Epsilon: 0.2\n",
      "Episode:  229 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  229 , Return: 1 Steps: 15 Epsilon: 0.2\n",
      "Episode:  230 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  230 , Return: 1 Steps: 9 Epsilon: 0.2\n",
      "Episode:  231 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  231 , Return: 1 Steps: 51 Epsilon: 0.2\n",
      "Episode:  232 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  232 , Return: 1 Steps: 27 Epsilon: 0.2\n",
      "Episode:  233 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  233 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  234 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  234 , Return: 1 Steps: 35 Epsilon: 0.2\n",
      "Episode:  235 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  235 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  236 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  236 , Return: 1 Steps: 11 Epsilon: 0.2\n",
      "Episode:  237 , Return: -1 Steps: 44 Epsilon: 0.2\n",
      "Episode:  237 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  238 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  238 , Return: 1 Steps: 31 Epsilon: 0.2\n",
      "Episode:  239 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  239 , Return: 1 Steps: 51 Epsilon: 0.2\n",
      "Episode:  240 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  240 , Return: 1 Steps: 23 Epsilon: 0.2\n",
      "Episode:  241 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  241 , Return: 1 Steps: 55 Epsilon: 0.2\n",
      "Episode:  242 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  242 , Return: 1 Steps: 35 Epsilon: 0.2\n",
      "Episode:  243 , Return: -1 Steps: 14 Epsilon: 0.2\n",
      "Episode:  243 , Return: 1 Steps: 59 Epsilon: 0.2\n",
      "Episode:  244 , Return: -1 Steps: 44 Epsilon: 0.2\n",
      "Episode:  244 , Return: 1 Steps: 73 Epsilon: 0.2\n",
      "Episode:  245 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  245 , Return: 1 Steps: 17 Epsilon: 0.2\n",
      "Episode:  246 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  246 , Return: 1 Steps: 47 Epsilon: 0.2\n",
      "Episode:  247 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  247 , Return: 1 Steps: 31 Epsilon: 0.2\n",
      "Episode:  248 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  248 , Return: 1 Steps: 27 Epsilon: 0.2\n",
      "Episode:  249 , Return: -1 Steps: 48 Epsilon: 0.2\n",
      "Episode:  249 , Return: 1 Steps: 31 Epsilon: 0.2\n",
      "Episode:  250 , Return: -1 Steps: 48 Epsilon: 0.2\n",
      "Episode:  250 , Return: 1 Steps: 45 Epsilon: 0.2\n",
      "Episode:  251 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  251 , Return: 1 Steps: 15 Epsilon: 0.2\n",
      "Episode:  252 , Return: -1 Steps: 48 Epsilon: 0.2\n",
      "Episode:  252 , Return: 1 Steps: 41 Epsilon: 0.2\n",
      "Episode:  253 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  253 , Return: 1 Steps: 25 Epsilon: 0.2\n",
      "Episode:  254 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  254 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  255 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  255 , Return: 1 Steps: 51 Epsilon: 0.2\n",
      "Episode:  256 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  256 , Return: 1 Steps: 59 Epsilon: 0.2\n",
      "Episode:  257 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  257 , Return: 1 Steps: 41 Epsilon: 0.2\n",
      "Episode:  258 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  258 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  259 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  259 , Return: 1 Steps: 57 Epsilon: 0.2\n",
      "Episode:  260 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  260 , Return: 1 Steps: 35 Epsilon: 0.2\n",
      "Episode:  261 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  261 , Return: 1 Steps: 19 Epsilon: 0.2\n",
      "Episode:  262 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  262 , Return: 1 Steps: 27 Epsilon: 0.2\n",
      "Episode:  263 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  263 , Return: 1 Steps: 47 Epsilon: 0.2\n",
      "Episode:  264 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  264 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  265 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  265 , Return: 1 Steps: 21 Epsilon: 0.2\n",
      "Episode:  266 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  266 , Return: 1 Steps: 51 Epsilon: 0.2\n",
      "Episode:  267 , Return: -1 Steps: 10 Epsilon: 0.2\n",
      "Episode:  267 , Return: 1 Steps: 19 Epsilon: 0.2\n",
      "Episode:  268 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  268 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  269 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  269 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  270 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  270 , Return: 1 Steps: 61 Epsilon: 0.2\n",
      "Episode:  271 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  271 , Return: 1 Steps: 57 Epsilon: 0.2\n",
      "Episode:  272 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  272 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  273 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  273 , Return: 1 Steps: 57 Epsilon: 0.2\n",
      "Episode:  274 , Return: -1 Steps: 46 Epsilon: 0.2\n",
      "Episode:  274 , Return: 1 Steps: 9 Epsilon: 0.2\n",
      "Episode:  275 , Return: -1 Steps: 20 Epsilon: 0.2\n",
      "Episode:  275 , Return: 1 Steps: 27 Epsilon: 0.2\n",
      "Episode:  276 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  276 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  277 , Return: -1 Steps: 44 Epsilon: 0.2\n",
      "Episode:  277 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  278 , Return: -1 Steps: 42 Epsilon: 0.2\n",
      "Episode:  278 , Return: 1 Steps: 17 Epsilon: 0.2\n",
      "Episode:  279 , Return: -1 Steps: 42 Epsilon: 0.2\n",
      "Episode:  279 , Return: 1 Steps: 9 Epsilon: 0.2\n",
      "Episode:  280 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  280 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  281 , Return: -1 Steps: 68 Epsilon: 0.2\n",
      "Episode:  281 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  282 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  282 , Return: 1 Steps: 53 Epsilon: 0.2\n",
      "Episode:  283 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  283 , Return: 1 Steps: 55 Epsilon: 0.2\n",
      "Episode:  284 , Return: -1 Steps: 18 Epsilon: 0.2\n",
      "Episode:  284 , Return: 1 Steps: 53 Epsilon: 0.2\n",
      "Episode:  285 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  285 , Return: 1 Steps: 63 Epsilon: 0.2\n",
      "Episode:  286 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  286 , Return: 1 Steps: 53 Epsilon: 0.2\n",
      "Episode:  287 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  287 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  288 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  288 , Return: 1 Steps: 47 Epsilon: 0.2\n",
      "Episode:  289 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  289 , Return: 1 Steps: 53 Epsilon: 0.2\n",
      "Episode:  290 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  290 , Return: 1 Steps: 45 Epsilon: 0.2\n",
      "Episode:  291 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  291 , Return: 1 Steps: 25 Epsilon: 0.2\n",
      "Episode:  292 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  292 , Return: 1 Steps: 35 Epsilon: 0.2\n",
      "Episode:  293 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  293 , Return: 1 Steps: 33 Epsilon: 0.2\n",
      "Episode:  294 , Return: -1 Steps: 42 Epsilon: 0.2\n",
      "Episode:  294 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  295 , Return: -1 Steps: 46 Epsilon: 0.2\n",
      "Episode:  295 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  296 , Return: -1 Steps: 20 Epsilon: 0.2\n",
      "Episode:  296 , Return: 1 Steps: 61 Epsilon: 0.2\n",
      "Episode:  297 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  297 , Return: 1 Steps: 33 Epsilon: 0.2\n",
      "Episode:  298 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  298 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  299 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  299 , Return: 1 Steps: 65 Epsilon: 0.2\n",
      "Episode:  300 , Return: -1 Steps: 52 Epsilon: 0.2\n",
      "Episode:  300 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  301 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  301 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  302 , Return: -1 Steps: 42 Epsilon: 0.2\n",
      "Episode:  302 , Return: 1 Steps: 59 Epsilon: 0.2\n",
      "Episode:  303 , Return: -1 Steps: 48 Epsilon: 0.2\n",
      "Episode:  303 , Return: 1 Steps: 15 Epsilon: 0.2\n",
      "Episode:  304 , Return: -1 Steps: 52 Epsilon: 0.2\n",
      "Episode:  304 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  305 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  305 , Return: 1 Steps: 29 Epsilon: 0.2\n",
      "Episode:  306 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  306 , Return: 1 Steps: 53 Epsilon: 0.2\n",
      "Episode:  307 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  307 , Return: 1 Steps: 71 Epsilon: 0.2\n",
      "Episode:  308 , Return: -1 Steps: 20 Epsilon: 0.2\n",
      "Episode:  308 , Return: 1 Steps: 55 Epsilon: 0.2\n",
      "Episode:  309 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  309 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  310 , Return: -1 Steps: 46 Epsilon: 0.2\n",
      "Episode:  310 , Return: 1 Steps: 57 Epsilon: 0.2\n",
      "Episode:  311 , Return: -1 Steps: 42 Epsilon: 0.2\n",
      "Episode:  311 , Return: 1 Steps: 29 Epsilon: 0.2\n",
      "Episode:  312 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  312 , Return: 1 Steps: 31 Epsilon: 0.2\n",
      "Episode:  313 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  313 , Return: 1 Steps: 71 Epsilon: 0.2\n",
      "Episode:  314 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  314 , Return: 1 Steps: 35 Epsilon: 0.2\n",
      "Episode:  315 , Return: -1 Steps: 48 Epsilon: 0.2\n",
      "Episode:  315 , Return: 1 Steps: 29 Epsilon: 0.2\n",
      "Episode:  316 , Return: -1 Steps: 22 Epsilon: 0.2\n",
      "Episode:  316 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  317 , Return: -1 Steps: 46 Epsilon: 0.2\n",
      "Episode:  317 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  318 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  318 , Return: 1 Steps: 53 Epsilon: 0.2\n",
      "Episode:  319 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  319 , Return: 1 Steps: 55 Epsilon: 0.2\n",
      "Episode:  320 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  320 , Return: 1 Steps: 15 Epsilon: 0.2\n",
      "Episode:  321 , Return: -1 Steps: 56 Epsilon: 0.2\n",
      "Episode:  321 , Return: 1 Steps: 59 Epsilon: 0.2\n",
      "Episode:  322 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  322 , Return: 1 Steps: 31 Epsilon: 0.2\n",
      "Episode:  323 , Return: -1 Steps: 44 Epsilon: 0.2\n",
      "Episode:  323 , Return: 1 Steps: 29 Epsilon: 0.2\n",
      "Episode:  324 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  324 , Return: 1 Steps: 27 Epsilon: 0.2\n",
      "Episode:  325 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  325 , Return: 1 Steps: 35 Epsilon: 0.2\n",
      "Episode:  326 , Return: -1 Steps: 48 Epsilon: 0.2\n",
      "Episode:  326 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  327 , Return: -1 Steps: 44 Epsilon: 0.2\n",
      "Episode:  327 , Return: 1 Steps: 19 Epsilon: 0.2\n",
      "Episode:  328 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  328 , Return: 1 Steps: 27 Epsilon: 0.2\n",
      "Episode:  329 , Return: -1 Steps: 22 Epsilon: 0.2\n",
      "Episode:  329 , Return: 1 Steps: 71 Epsilon: 0.2\n",
      "Episode:  330 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  330 , Return: 1 Steps: 55 Epsilon: 0.2\n",
      "Episode:  331 , Return: -1 Steps: 46 Epsilon: 0.2\n",
      "Episode:  331 , Return: 1 Steps: 27 Epsilon: 0.2\n",
      "Episode:  332 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  332 , Return: 1 Steps: 31 Epsilon: 0.2\n",
      "Episode:  333 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  333 , Return: 1 Steps: 35 Epsilon: 0.2\n",
      "Episode:  334 , Return: -1 Steps: 70 Epsilon: 0.2\n",
      "Episode:  334 , Return: 1 Steps: 33 Epsilon: 0.2\n",
      "Episode:  335 , Return: -1 Steps: 22 Epsilon: 0.2\n",
      "Episode:  335 , Return: 1 Steps: 57 Epsilon: 0.2\n",
      "Episode:  336 , Return: -1 Steps: 56 Epsilon: 0.2\n",
      "Episode:  336 , Return: 1 Steps: 63 Epsilon: 0.2\n",
      "Episode:  337 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  337 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  338 , Return: -1 Steps: 68 Epsilon: 0.2\n",
      "Episode:  338 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  339 , Return: -1 Steps: 46 Epsilon: 0.2\n",
      "Episode:  339 , Return: 1 Steps: 23 Epsilon: 0.2\n",
      "Episode:  340 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  340 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  341 , Return: -1 Steps: 54 Epsilon: 0.2\n",
      "Episode:  341 , Return: 1 Steps: 45 Epsilon: 0.2\n",
      "Episode:  342 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  342 , Return: 1 Steps: 25 Epsilon: 0.2\n",
      "Episode:  343 , Return: -1 Steps: 64 Epsilon: 0.2\n",
      "Episode:  343 , Return: 1 Steps: 65 Epsilon: 0.2\n",
      "Episode:  344 , Return: -1 Steps: 14 Epsilon: 0.2\n",
      "Episode:  344 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  345 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  345 , Return: 1 Steps: 29 Epsilon: 0.2\n",
      "Episode:  346 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  346 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  347 , Return: -1 Steps: 20 Epsilon: 0.2\n",
      "Episode:  347 , Return: 1 Steps: 59 Epsilon: 0.2\n",
      "Episode:  348 , Return: -1 Steps: 54 Epsilon: 0.2\n",
      "Episode:  348 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  349 , Return: -1 Steps: 16 Epsilon: 0.2\n",
      "Episode:  349 , Return: 1 Steps: 45 Epsilon: 0.2\n",
      "Episode:  350 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  350 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  351 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  351 , Return: 1 Steps: 55 Epsilon: 0.2\n",
      "Episode:  352 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  352 , Return: 1 Steps: 45 Epsilon: 0.2\n",
      "Episode:  353 , Return: -1 Steps: 48 Epsilon: 0.2\n",
      "Episode:  353 , Return: 1 Steps: 25 Epsilon: 0.2\n",
      "Episode:  354 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  354 , Return: 1 Steps: 27 Epsilon: 0.2\n",
      "Episode:  355 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  355 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  356 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  356 , Return: 1 Steps: 35 Epsilon: 0.2\n",
      "Episode:  357 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  357 , Return: 1 Steps: 41 Epsilon: 0.2\n",
      "Episode:  358 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  358 , Return: 1 Steps: 23 Epsilon: 0.2\n",
      "Episode:  359 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  359 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  360 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  360 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  361 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  361 , Return: 1 Steps: 55 Epsilon: 0.2\n",
      "Episode:  362 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  362 , Return: 1 Steps: 61 Epsilon: 0.2\n",
      "Episode:  363 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  363 , Return: 1 Steps: 51 Epsilon: 0.2\n",
      "Episode:  364 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  364 , Return: 1 Steps: 63 Epsilon: 0.2\n",
      "Episode:  365 , Return: -1 Steps: 48 Epsilon: 0.2\n",
      "Episode:  365 , Return: 1 Steps: 53 Epsilon: 0.2\n",
      "Episode:  366 , Return: -1 Steps: 14 Epsilon: 0.2\n",
      "Episode:  366 , Return: 1 Steps: 33 Epsilon: 0.2\n",
      "Episode:  367 , Return: -1 Steps: 52 Epsilon: 0.2\n",
      "Episode:  367 , Return: 1 Steps: 67 Epsilon: 0.2\n",
      "Episode:  368 , Return: -1 Steps: 42 Epsilon: 0.2\n",
      "Episode:  368 , Return: 1 Steps: 35 Epsilon: 0.2\n",
      "Episode:  369 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  369 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  370 , Return: -1 Steps: 20 Epsilon: 0.2\n",
      "Episode:  370 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  371 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  371 , Return: 1 Steps: 27 Epsilon: 0.2\n",
      "Episode:  372 , Return: -1 Steps: 46 Epsilon: 0.2\n",
      "Episode:  372 , Return: 1 Steps: 41 Epsilon: 0.2\n",
      "Episode:  373 , Return: -1 Steps: 48 Epsilon: 0.2\n",
      "Episode:  373 , Return: 1 Steps: 31 Epsilon: 0.2\n",
      "Episode:  374 , Return: -1 Steps: 46 Epsilon: 0.2\n",
      "Episode:  374 , Return: 1 Steps: 69 Epsilon: 0.2\n",
      "Episode:  375 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  375 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  376 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  376 , Return: 1 Steps: 57 Epsilon: 0.2\n",
      "Episode:  377 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  377 , Return: 1 Steps: 31 Epsilon: 0.2\n",
      "Episode:  378 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  378 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  379 , Return: -1 Steps: 44 Epsilon: 0.2\n",
      "Episode:  379 , Return: 1 Steps: 67 Epsilon: 0.2\n",
      "Episode:  380 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  380 , Return: 1 Steps: 51 Epsilon: 0.2\n",
      "Episode:  381 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  381 , Return: 1 Steps: 33 Epsilon: 0.2\n",
      "Episode:  382 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  382 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  383 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  383 , Return: 1 Steps: 27 Epsilon: 0.2\n",
      "Episode:  384 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  384 , Return: 1 Steps: 23 Epsilon: 0.2\n",
      "Episode:  385 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  385 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  386 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  386 , Return: 1 Steps: 51 Epsilon: 0.2\n",
      "Episode:  387 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  387 , Return: 1 Steps: 25 Epsilon: 0.2\n",
      "Episode:  388 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  388 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  389 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  389 , Return: 1 Steps: 45 Epsilon: 0.2\n",
      "Episode:  390 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  390 , Return: 1 Steps: 61 Epsilon: 0.2\n",
      "Episode:  391 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  391 , Return: 1 Steps: 41 Epsilon: 0.2\n",
      "Episode:  392 , Return: -1 Steps: 22 Epsilon: 0.2\n",
      "Episode:  392 , Return: 1 Steps: 79 Epsilon: 0.2\n",
      "Episode:  393 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  393 , Return: 1 Steps: 41 Epsilon: 0.2\n",
      "Episode:  394 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  394 , Return: 1 Steps: 93 Epsilon: 0.2\n",
      "Episode:  395 , Return: -1 Steps: 46 Epsilon: 0.2\n",
      "Episode:  395 , Return: 1 Steps: 47 Epsilon: 0.2\n",
      "Episode:  396 , Return: -1 Steps: 18 Epsilon: 0.2\n",
      "Episode:  396 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  397 , Return: -1 Steps: 18 Epsilon: 0.2\n",
      "Episode:  397 , Return: 1 Steps: 23 Epsilon: 0.2\n",
      "Episode:  398 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  398 , Return: 1 Steps: 33 Epsilon: 0.2\n",
      "Episode:  399 , Return: -1 Steps: 42 Epsilon: 0.2\n",
      "Episode:  399 , Return: 1 Steps: 45 Epsilon: 0.2\n",
      "Episode:  400 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  400 , Return: 1 Steps: 57 Epsilon: 0.2\n",
      "Episode:  401 , Return: -1 Steps: 42 Epsilon: 0.2\n",
      "Episode:  401 , Return: 1 Steps: 33 Epsilon: 0.2\n",
      "Episode:  402 , Return: -1 Steps: 22 Epsilon: 0.2\n",
      "Episode:  402 , Return: 1 Steps: 31 Epsilon: 0.2\n",
      "Episode:  403 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  403 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  404 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  404 , Return: 1 Steps: 47 Epsilon: 0.2\n",
      "Episode:  405 , Return: -1 Steps: 46 Epsilon: 0.2\n",
      "Episode:  405 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  406 , Return: -1 Steps: 50 Epsilon: 0.2\n",
      "Episode:  406 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  407 , Return: -1 Steps: 44 Epsilon: 0.2\n",
      "Episode:  407 , Return: 1 Steps: 51 Epsilon: 0.2\n",
      "Episode:  408 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  408 , Return: 1 Steps: 41 Epsilon: 0.2\n",
      "Episode:  409 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  409 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  410 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  410 , Return: 1 Steps: 53 Epsilon: 0.2\n",
      "Episode:  411 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  411 , Return: 1 Steps: 45 Epsilon: 0.2\n",
      "Episode:  412 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  412 , Return: 1 Steps: 27 Epsilon: 0.2\n",
      "Episode:  413 , Return: -1 Steps: 50 Epsilon: 0.2\n",
      "Episode:  413 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  414 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  414 , Return: 1 Steps: 69 Epsilon: 0.2\n",
      "Episode:  415 , Return: -1 Steps: 48 Epsilon: 0.2\n",
      "Episode:  415 , Return: 1 Steps: 33 Epsilon: 0.2\n",
      "Episode:  416 , Return: -1 Steps: 22 Epsilon: 0.2\n",
      "Episode:  416 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  417 , Return: -1 Steps: 42 Epsilon: 0.2\n",
      "Episode:  417 , Return: 1 Steps: 55 Epsilon: 0.2\n",
      "Episode:  418 , Return: -1 Steps: 42 Epsilon: 0.2\n",
      "Episode:  418 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  419 , Return: -1 Steps: 16 Epsilon: 0.2\n",
      "Episode:  419 , Return: 1 Steps: 55 Epsilon: 0.2\n",
      "Episode:  420 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  420 , Return: 1 Steps: 45 Epsilon: 0.2\n",
      "Episode:  421 , Return: -1 Steps: 48 Epsilon: 0.2\n",
      "Episode:  421 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  422 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  422 , Return: 1 Steps: 45 Epsilon: 0.2\n",
      "Episode:  423 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  423 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  424 , Return: -1 Steps: 44 Epsilon: 0.2\n",
      "Episode:  424 , Return: 1 Steps: 25 Epsilon: 0.2\n",
      "Episode:  425 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  425 , Return: 1 Steps: 27 Epsilon: 0.2\n",
      "Episode:  426 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  426 , Return: 1 Steps: 57 Epsilon: 0.2\n",
      "Episode:  427 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  427 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  428 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  428 , Return: 1 Steps: 71 Epsilon: 0.2\n",
      "Episode:  429 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  429 , Return: 1 Steps: 45 Epsilon: 0.2\n",
      "Episode:  430 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  430 , Return: 1 Steps: 41 Epsilon: 0.2\n",
      "Episode:  431 , Return: -1 Steps: 42 Epsilon: 0.2\n",
      "Episode:  431 , Return: 1 Steps: 35 Epsilon: 0.2\n",
      "Episode:  432 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  432 , Return: 1 Steps: 53 Epsilon: 0.2\n",
      "Episode:  433 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  433 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  434 , Return: -1 Steps: 44 Epsilon: 0.2\n",
      "Episode:  434 , Return: 1 Steps: 29 Epsilon: 0.2\n",
      "Episode:  435 , Return: -1 Steps: 50 Epsilon: 0.2\n",
      "Episode:  435 , Return: 1 Steps: 33 Epsilon: 0.2\n",
      "Episode:  436 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  436 , Return: 1 Steps: 45 Epsilon: 0.2\n",
      "Episode:  437 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  437 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  438 , Return: -1 Steps: 18 Epsilon: 0.2\n",
      "Episode:  438 , Return: 1 Steps: 35 Epsilon: 0.2\n",
      "Episode:  439 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  439 , Return: 1 Steps: 53 Epsilon: 0.2\n",
      "Episode:  440 , Return: -1 Steps: 46 Epsilon: 0.2\n",
      "Episode:  440 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  441 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  441 , Return: 1 Steps: 53 Epsilon: 0.2\n",
      "Episode:  442 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  442 , Return: 1 Steps: 61 Epsilon: 0.2\n",
      "Episode:  443 , Return: -1 Steps: 50 Epsilon: 0.2\n",
      "Episode:  443 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  444 , Return: -1 Steps: 22 Epsilon: 0.2\n",
      "Episode:  444 , Return: 1 Steps: 51 Epsilon: 0.2\n",
      "Episode:  445 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  445 , Return: 1 Steps: 33 Epsilon: 0.2\n",
      "Episode:  446 , Return: -1 Steps: 50 Epsilon: 0.2\n",
      "Episode:  446 , Return: 1 Steps: 47 Epsilon: 0.2\n",
      "Episode:  447 , Return: -1 Steps: 20 Epsilon: 0.2\n",
      "Episode:  447 , Return: 1 Steps: 23 Epsilon: 0.2\n",
      "Episode:  448 , Return: -1 Steps: 22 Epsilon: 0.2\n",
      "Episode:  448 , Return: 1 Steps: 47 Epsilon: 0.2\n",
      "Episode:  449 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  449 , Return: 1 Steps: 27 Epsilon: 0.2\n",
      "Episode:  450 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  450 , Return: 1 Steps: 53 Epsilon: 0.2\n",
      "Episode:  451 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  451 , Return: 1 Steps: 33 Epsilon: 0.2\n",
      "Episode:  452 , Return: -1 Steps: 50 Epsilon: 0.2\n",
      "Episode:  452 , Return: 1 Steps: 69 Epsilon: 0.2\n",
      "Episode:  453 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  453 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  454 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  454 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  455 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  455 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  456 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  456 , Return: 1 Steps: 41 Epsilon: 0.2\n",
      "Episode:  457 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  457 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  458 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  458 , Return: 1 Steps: 89 Epsilon: 0.2\n",
      "Episode:  459 , Return: -1 Steps: 46 Epsilon: 0.2\n",
      "Episode:  459 , Return: 1 Steps: 17 Epsilon: 0.2\n",
      "Episode:  460 , Return: -1 Steps: 46 Epsilon: 0.2\n",
      "Episode:  460 , Return: 1 Steps: 47 Epsilon: 0.2\n",
      "Episode:  461 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  461 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  462 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  462 , Return: 1 Steps: 47 Epsilon: 0.2\n",
      "Episode:  463 , Return: -1 Steps: 44 Epsilon: 0.2\n",
      "Episode:  463 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  464 , Return: -1 Steps: 62 Epsilon: 0.2\n",
      "Episode:  464 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  465 , Return: -1 Steps: 22 Epsilon: 0.2\n",
      "Episode:  465 , Return: 1 Steps: 35 Epsilon: 0.2\n",
      "Episode:  466 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  466 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  467 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  467 , Return: 1 Steps: 57 Epsilon: 0.2\n",
      "Episode:  468 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  468 , Return: 1 Steps: 67 Epsilon: 0.2\n",
      "Episode:  469 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  469 , Return: 1 Steps: 47 Epsilon: 0.2\n",
      "Episode:  470 , Return: -1 Steps: 64 Epsilon: 0.2\n",
      "Episode:  470 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  471 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  471 , Return: 1 Steps: 45 Epsilon: 0.2\n",
      "Episode:  472 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  472 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  473 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  473 , Return: 1 Steps: 53 Epsilon: 0.2\n",
      "Episode:  474 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  474 , Return: 1 Steps: 29 Epsilon: 0.2\n",
      "Episode:  475 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  475 , Return: 1 Steps: 53 Epsilon: 0.2\n",
      "Episode:  476 , Return: -1 Steps: 56 Epsilon: 0.2\n",
      "Episode:  476 , Return: 1 Steps: 69 Epsilon: 0.2\n",
      "Episode:  477 , Return: -1 Steps: 56 Epsilon: 0.2\n",
      "Episode:  477 , Return: 1 Steps: 53 Epsilon: 0.2\n",
      "Episode:  478 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  478 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  479 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  479 , Return: 1 Steps: 47 Epsilon: 0.2\n",
      "Episode:  480 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  480 , Return: 1 Steps: 73 Epsilon: 0.2\n",
      "Episode:  481 , Return: -1 Steps: 42 Epsilon: 0.2\n",
      "Episode:  481 , Return: 1 Steps: 33 Epsilon: 0.2\n",
      "Episode:  482 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  482 , Return: 1 Steps: 33 Epsilon: 0.2\n",
      "Episode:  483 , Return: -1 Steps: 10 Epsilon: 0.2\n",
      "Episode:  483 , Return: 1 Steps: 29 Epsilon: 0.2\n",
      "Episode:  484 , Return: -1 Steps: 42 Epsilon: 0.2\n",
      "Episode:  484 , Return: 1 Steps: 61 Epsilon: 0.2\n",
      "Episode:  485 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  485 , Return: 1 Steps: 53 Epsilon: 0.2\n",
      "Episode:  486 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  486 , Return: 1 Steps: 61 Epsilon: 0.2\n",
      "Episode:  487 , Return: -1 Steps: 82 Epsilon: 0.2\n",
      "Episode:  487 , Return: 1 Steps: 33 Epsilon: 0.2\n",
      "Episode:  488 , Return: -1 Steps: 54 Epsilon: 0.2\n",
      "Episode:  488 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  489 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  489 , Return: 1 Steps: 23 Epsilon: 0.2\n",
      "Episode:  490 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  490 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  491 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  491 , Return: 1 Steps: 67 Epsilon: 0.2\n",
      "Episode:  492 , Return: -1 Steps: 58 Epsilon: 0.2\n",
      "Episode:  492 , Return: 1 Steps: 33 Epsilon: 0.2\n",
      "Episode:  493 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  493 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  494 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  494 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  495 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  495 , Return: 1 Steps: 45 Epsilon: 0.2\n",
      "Episode:  496 , Return: -1 Steps: 42 Epsilon: 0.2\n",
      "Episode:  496 , Return: 1 Steps: 71 Epsilon: 0.2\n",
      "Episode:  497 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  497 , Return: 1 Steps: 35 Epsilon: 0.2\n",
      "Episode:  498 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  498 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  499 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  499 , Return: 1 Steps: 29 Epsilon: 0.2\n",
      "Episode:  500 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  500 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  501 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  501 , Return: 1 Steps: 27 Epsilon: 0.2\n",
      "Episode:  502 , Return: -1 Steps: 58 Epsilon: 0.2\n",
      "Episode:  502 , Return: 1 Steps: 51 Epsilon: 0.2\n",
      "Episode:  503 , Return: -1 Steps: 22 Epsilon: 0.2\n",
      "Episode:  503 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  504 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  504 , Return: 1 Steps: 35 Epsilon: 0.2\n",
      "Episode:  505 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  505 , Return: 1 Steps: 29 Epsilon: 0.2\n",
      "Episode:  506 , Return: -1 Steps: 44 Epsilon: 0.2\n",
      "Episode:  506 , Return: 1 Steps: 51 Epsilon: 0.2\n",
      "Episode:  507 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  507 , Return: 1 Steps: 13 Epsilon: 0.2\n",
      "Episode:  508 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  508 , Return: 1 Steps: 35 Epsilon: 0.2\n",
      "Episode:  509 , Return: -1 Steps: 22 Epsilon: 0.2\n",
      "Episode:  509 , Return: 1 Steps: 47 Epsilon: 0.2\n",
      "Episode:  510 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  510 , Return: 1 Steps: 81 Epsilon: 0.2\n",
      "Episode:  511 , Return: -1 Steps: 46 Epsilon: 0.2\n",
      "Episode:  511 , Return: 1 Steps: 57 Epsilon: 0.2\n",
      "Episode:  512 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  512 , Return: 1 Steps: 23 Epsilon: 0.2\n",
      "Episode:  513 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  513 , Return: 1 Steps: 35 Epsilon: 0.2\n",
      "Episode:  514 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  514 , Return: 1 Steps: 59 Epsilon: 0.2\n",
      "Episode:  515 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  515 , Return: 1 Steps: 57 Epsilon: 0.2\n",
      "Episode:  516 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  516 , Return: 1 Steps: 47 Epsilon: 0.2\n",
      "Episode:  517 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  517 , Return: 1 Steps: 47 Epsilon: 0.2\n",
      "Episode:  518 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  518 , Return: 1 Steps: 45 Epsilon: 0.2\n",
      "Episode:  519 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  519 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  520 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  520 , Return: 1 Steps: 31 Epsilon: 0.2\n",
      "Episode:  521 , Return: -1 Steps: 76 Epsilon: 0.2\n",
      "Episode:  521 , Return: 1 Steps: 85 Epsilon: 0.2\n",
      "Episode:  522 , Return: -1 Steps: 52 Epsilon: 0.2\n",
      "Episode:  522 , Return: 1 Steps: 53 Epsilon: 0.2\n",
      "Episode:  523 , Return: -1 Steps: 44 Epsilon: 0.2\n",
      "Episode:  523 , Return: 1 Steps: 35 Epsilon: 0.2\n",
      "Episode:  524 , Return: -1 Steps: 64 Epsilon: 0.2\n",
      "Episode:  524 , Return: 1 Steps: 47 Epsilon: 0.2\n",
      "Episode:  525 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  525 , Return: 1 Steps: 47 Epsilon: 0.2\n",
      "Episode:  526 , Return: -1 Steps: 54 Epsilon: 0.2\n",
      "Episode:  526 , Return: 1 Steps: 31 Epsilon: 0.2\n",
      "Episode:  527 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  527 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  528 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  528 , Return: 1 Steps: 41 Epsilon: 0.2\n",
      "Episode:  529 , Return: -1 Steps: 42 Epsilon: 0.2\n",
      "Episode:  529 , Return: 1 Steps: 33 Epsilon: 0.2\n",
      "Episode:  530 , Return: -1 Steps: 20 Epsilon: 0.2\n",
      "Episode:  530 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  531 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  531 , Return: 1 Steps: 63 Epsilon: 0.2\n",
      "Episode:  532 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  532 , Return: 1 Steps: 65 Epsilon: 0.2\n",
      "Episode:  533 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  533 , Return: 1 Steps: 35 Epsilon: 0.2\n",
      "Episode:  534 , Return: -1 Steps: 48 Epsilon: 0.2\n",
      "Episode:  534 , Return: 1 Steps: 55 Epsilon: 0.2\n",
      "Episode:  535 , Return: -1 Steps: 48 Epsilon: 0.2\n",
      "Episode:  535 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  536 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  536 , Return: 1 Steps: 51 Epsilon: 0.2\n",
      "Episode:  537 , Return: -1 Steps: 46 Epsilon: 0.2\n",
      "Episode:  537 , Return: 1 Steps: 85 Epsilon: 0.2\n",
      "Episode:  538 , Return: -1 Steps: 78 Epsilon: 0.2\n",
      "Episode:  538 , Return: 1 Steps: 53 Epsilon: 0.2\n",
      "Episode:  539 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  539 , Return: 1 Steps: 63 Epsilon: 0.2\n",
      "Episode:  540 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  540 , Return: 1 Steps: 75 Epsilon: 0.2\n",
      "Episode:  541 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  541 , Return: 1 Steps: 57 Epsilon: 0.2\n",
      "Episode:  542 , Return: -1 Steps: 18 Epsilon: 0.2\n",
      "Episode:  542 , Return: 1 Steps: 55 Epsilon: 0.2\n",
      "Episode:  543 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  543 , Return: 1 Steps: 25 Epsilon: 0.2\n",
      "Episode:  544 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  544 , Return: 1 Steps: 27 Epsilon: 0.2\n",
      "Episode:  545 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  545 , Return: 1 Steps: 51 Epsilon: 0.2\n",
      "Episode:  546 , Return: -1 Steps: 22 Epsilon: 0.2\n",
      "Episode:  546 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  547 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  547 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  548 , Return: -1 Steps: 18 Epsilon: 0.2\n",
      "Episode:  548 , Return: 1 Steps: 29 Epsilon: 0.2\n",
      "Episode:  549 , Return: -1 Steps: 44 Epsilon: 0.2\n",
      "Episode:  549 , Return: 1 Steps: 61 Epsilon: 0.2\n",
      "Episode:  550 , Return: -1 Steps: 50 Epsilon: 0.2\n",
      "Episode:  550 , Return: 1 Steps: 61 Epsilon: 0.2\n",
      "Episode:  551 , Return: -1 Steps: 20 Epsilon: 0.2\n",
      "Episode:  551 , Return: 1 Steps: 65 Epsilon: 0.2\n",
      "Episode:  552 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  552 , Return: 1 Steps: 51 Epsilon: 0.2\n",
      "Episode:  553 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  553 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  554 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  554 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  555 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  555 , Return: 1 Steps: 67 Epsilon: 0.2\n",
      "Episode:  556 , Return: -1 Steps: 48 Epsilon: 0.2\n",
      "Episode:  556 , Return: 1 Steps: 29 Epsilon: 0.2\n",
      "Episode:  557 , Return: -1 Steps: 42 Epsilon: 0.2\n",
      "Episode:  557 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  558 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  558 , Return: 1 Steps: 25 Epsilon: 0.2\n",
      "Episode:  559 , Return: -1 Steps: 50 Epsilon: 0.2\n",
      "Episode:  559 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  560 , Return: -1 Steps: 80 Epsilon: 0.2\n",
      "Episode:  560 , Return: 1 Steps: 57 Epsilon: 0.2\n",
      "Episode:  561 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  561 , Return: 1 Steps: 29 Epsilon: 0.2\n",
      "Episode:  562 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  562 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  563 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  563 , Return: 1 Steps: 53 Epsilon: 0.2\n",
      "Episode:  564 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  564 , Return: 1 Steps: 61 Epsilon: 0.2\n",
      "Episode:  565 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  565 , Return: 1 Steps: 31 Epsilon: 0.2\n",
      "Episode:  566 , Return: -1 Steps: 50 Epsilon: 0.2\n",
      "Episode:  566 , Return: 1 Steps: 31 Epsilon: 0.2\n",
      "Episode:  567 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  567 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  568 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  568 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  569 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  569 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  570 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  570 , Return: 1 Steps: 69 Epsilon: 0.2\n",
      "Episode:  571 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  571 , Return: 1 Steps: 45 Epsilon: 0.2\n",
      "Episode:  572 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  572 , Return: 1 Steps: 51 Epsilon: 0.2\n",
      "Episode:  573 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  573 , Return: 1 Steps: 47 Epsilon: 0.2\n",
      "Episode:  574 , Return: -1 Steps: 20 Epsilon: 0.2\n",
      "Episode:  574 , Return: 1 Steps: 29 Epsilon: 0.2\n",
      "Episode:  575 , Return: -1 Steps: 44 Epsilon: 0.2\n",
      "Episode:  575 , Return: 1 Steps: 67 Epsilon: 0.2\n",
      "Episode:  576 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  576 , Return: 1 Steps: 75 Epsilon: 0.2\n",
      "Episode:  577 , Return: -1 Steps: 60 Epsilon: 0.2\n",
      "Episode:  577 , Return: 1 Steps: 45 Epsilon: 0.2\n",
      "Episode:  578 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  578 , Return: 1 Steps: 41 Epsilon: 0.2\n",
      "Episode:  579 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  579 , Return: 1 Steps: 53 Epsilon: 0.2\n",
      "Episode:  580 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  580 , Return: 1 Steps: 29 Epsilon: 0.2\n",
      "Episode:  581 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  581 , Return: 1 Steps: 41 Epsilon: 0.2\n",
      "Episode:  582 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  582 , Return: 1 Steps: 51 Epsilon: 0.2\n",
      "Episode:  583 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  583 , Return: 1 Steps: 31 Epsilon: 0.2\n",
      "Episode:  584 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  584 , Return: 1 Steps: 47 Epsilon: 0.2\n",
      "Episode:  585 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  585 , Return: 1 Steps: 71 Epsilon: 0.2\n",
      "Episode:  586 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  586 , Return: 1 Steps: 33 Epsilon: 0.2\n",
      "Episode:  587 , Return: -1 Steps: 72 Epsilon: 0.2\n",
      "Episode:  587 , Return: 1 Steps: 63 Epsilon: 0.2\n",
      "Episode:  588 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  588 , Return: 1 Steps: 53 Epsilon: 0.2\n",
      "Episode:  589 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  589 , Return: 1 Steps: 27 Epsilon: 0.2\n",
      "Episode:  590 , Return: -1 Steps: 62 Epsilon: 0.2\n",
      "Episode:  590 , Return: 1 Steps: 45 Epsilon: 0.2\n",
      "Episode:  591 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  591 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  592 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  592 , Return: 1 Steps: 57 Epsilon: 0.2\n",
      "Episode:  593 , Return: -1 Steps: 42 Epsilon: 0.2\n",
      "Episode:  593 , Return: 1 Steps: 29 Epsilon: 0.2\n",
      "Episode:  594 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  594 , Return: 1 Steps: 31 Epsilon: 0.2\n",
      "Episode:  595 , Return: -1 Steps: 44 Epsilon: 0.2\n",
      "Episode:  595 , Return: 1 Steps: 47 Epsilon: 0.2\n",
      "Episode:  596 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  596 , Return: 1 Steps: 47 Epsilon: 0.2\n",
      "Episode:  597 , Return: -1 Steps: 46 Epsilon: 0.2\n",
      "Episode:  597 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  598 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  598 , Return: 1 Steps: 47 Epsilon: 0.2\n",
      "Episode:  599 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  599 , Return: 1 Steps: 63 Epsilon: 0.2\n",
      "Episode:  600 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  600 , Return: 1 Steps: 11 Epsilon: 0.2\n",
      "Episode:  601 , Return: -1 Steps: 52 Epsilon: 0.2\n",
      "Episode:  601 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  602 , Return: -1 Steps: 52 Epsilon: 0.2\n",
      "Episode:  602 , Return: 1 Steps: 35 Epsilon: 0.2\n",
      "Episode:  603 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  603 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  604 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  604 , Return: 1 Steps: 29 Epsilon: 0.2\n",
      "Episode:  605 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  605 , Return: 1 Steps: 19 Epsilon: 0.2\n",
      "Episode:  606 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  606 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  607 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  607 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  608 , Return: -1 Steps: 46 Epsilon: 0.2\n",
      "Episode:  608 , Return: 1 Steps: 41 Epsilon: 0.2\n",
      "Episode:  609 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  609 , Return: 1 Steps: 23 Epsilon: 0.2\n",
      "Episode:  610 , Return: -1 Steps: 8 Epsilon: 0.2\n",
      "Episode:  610 , Return: 1 Steps: 55 Epsilon: 0.2\n",
      "Episode:  611 , Return: -1 Steps: 16 Epsilon: 0.2\n",
      "Episode:  611 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  612 , Return: -1 Steps: 44 Epsilon: 0.2\n",
      "Episode:  612 , Return: 1 Steps: 45 Epsilon: 0.2\n",
      "Episode:  613 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  613 , Return: 1 Steps: 87 Epsilon: 0.2\n",
      "Episode:  614 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  614 , Return: 1 Steps: 45 Epsilon: 0.2\n",
      "Episode:  615 , Return: -1 Steps: 56 Epsilon: 0.2\n",
      "Episode:  615 , Return: 1 Steps: 61 Epsilon: 0.2\n",
      "Episode:  616 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  616 , Return: 1 Steps: 67 Epsilon: 0.2\n",
      "Episode:  617 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  617 , Return: 1 Steps: 61 Epsilon: 0.2\n",
      "Episode:  618 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  618 , Return: 1 Steps: 41 Epsilon: 0.2\n",
      "Episode:  619 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  619 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  620 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  620 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  621 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  621 , Return: 1 Steps: 55 Epsilon: 0.2\n",
      "Episode:  622 , Return: -1 Steps: 56 Epsilon: 0.2\n",
      "Episode:  622 , Return: 1 Steps: 81 Epsilon: 0.2\n",
      "Episode:  623 , Return: -1 Steps: 42 Epsilon: 0.2\n",
      "Episode:  623 , Return: 1 Steps: 41 Epsilon: 0.2\n",
      "Episode:  624 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  624 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  625 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  625 , Return: 1 Steps: 29 Epsilon: 0.2\n",
      "Episode:  626 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  626 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  627 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  627 , Return: 1 Steps: 59 Epsilon: 0.2\n",
      "Episode:  628 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  628 , Return: 1 Steps: 51 Epsilon: 0.2\n",
      "Episode:  629 , Return: -1 Steps: 62 Epsilon: 0.2\n",
      "Episode:  629 , Return: 1 Steps: 47 Epsilon: 0.2\n",
      "Episode:  630 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  630 , Return: 1 Steps: 53 Epsilon: 0.2\n",
      "Episode:  631 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  631 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  632 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  632 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  633 , Return: -1 Steps: 18 Epsilon: 0.2\n",
      "Episode:  633 , Return: 1 Steps: 33 Epsilon: 0.2\n",
      "Episode:  634 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  634 , Return: 1 Steps: 25 Epsilon: 0.2\n",
      "Episode:  635 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  635 , Return: 1 Steps: 47 Epsilon: 0.2\n",
      "Episode:  636 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  636 , Return: 1 Steps: 53 Epsilon: 0.2\n",
      "Episode:  637 , Return: -1 Steps: 44 Epsilon: 0.2\n",
      "Episode:  637 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  638 , Return: -1 Steps: 56 Epsilon: 0.2\n",
      "Episode:  638 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  639 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  639 , Return: 1 Steps: 31 Epsilon: 0.2\n",
      "Episode:  640 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  640 , Return: 1 Steps: 35 Epsilon: 0.2\n",
      "Episode:  641 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  641 , Return: 1 Steps: 21 Epsilon: 0.2\n",
      "Episode:  642 , Return: -1 Steps: 48 Epsilon: 0.2\n",
      "Episode:  642 , Return: 1 Steps: 57 Epsilon: 0.2\n",
      "Episode:  643 , Return: -1 Steps: 52 Epsilon: 0.2\n",
      "Episode:  643 , Return: 1 Steps: 45 Epsilon: 0.2\n",
      "Episode:  644 , Return: -1 Steps: 10 Epsilon: 0.2\n",
      "Episode:  644 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  645 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  645 , Return: 1 Steps: 65 Epsilon: 0.2\n",
      "Episode:  646 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  646 , Return: 1 Steps: 55 Epsilon: 0.2\n",
      "Episode:  647 , Return: -1 Steps: 70 Epsilon: 0.2\n",
      "Episode:  647 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  648 , Return: -1 Steps: 42 Epsilon: 0.2\n",
      "Episode:  648 , Return: 1 Steps: 21 Epsilon: 0.2\n",
      "Episode:  649 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  649 , Return: 1 Steps: 27 Epsilon: 0.2\n",
      "Episode:  650 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  650 , Return: 1 Steps: 41 Epsilon: 0.2\n",
      "Episode:  651 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  651 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  652 , Return: -1 Steps: 50 Epsilon: 0.2\n",
      "Episode:  652 , Return: 1 Steps: 41 Epsilon: 0.2\n",
      "Episode:  653 , Return: -1 Steps: 22 Epsilon: 0.2\n",
      "Episode:  653 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  654 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  654 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  655 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  655 , Return: 1 Steps: 67 Epsilon: 0.2\n",
      "Episode:  656 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  656 , Return: 1 Steps: 27 Epsilon: 0.2\n",
      "Episode:  657 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  657 , Return: 1 Steps: 53 Epsilon: 0.2\n",
      "Episode:  658 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  658 , Return: 1 Steps: 33 Epsilon: 0.2\n",
      "Episode:  659 , Return: -1 Steps: 16 Epsilon: 0.2\n",
      "Episode:  659 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  660 , Return: -1 Steps: 44 Epsilon: 0.2\n",
      "Episode:  660 , Return: 1 Steps: 47 Epsilon: 0.2\n",
      "Episode:  661 , Return: -1 Steps: 46 Epsilon: 0.2\n",
      "Episode:  661 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  662 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  662 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  663 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  663 , Return: 1 Steps: 33 Epsilon: 0.2\n",
      "Episode:  664 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  664 , Return: 1 Steps: 47 Epsilon: 0.2\n",
      "Episode:  665 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  665 , Return: 1 Steps: 45 Epsilon: 0.2\n",
      "Episode:  666 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  666 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  667 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  667 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  668 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  668 , Return: 1 Steps: 55 Epsilon: 0.2\n",
      "Episode:  669 , Return: -1 Steps: 44 Epsilon: 0.2\n",
      "Episode:  669 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  670 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  670 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  671 , Return: -1 Steps: 52 Epsilon: 0.2\n",
      "Episode:  671 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  672 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  672 , Return: 1 Steps: 53 Epsilon: 0.2\n",
      "Episode:  673 , Return: -1 Steps: 50 Epsilon: 0.2\n",
      "Episode:  673 , Return: 1 Steps: 35 Epsilon: 0.2\n",
      "Episode:  674 , Return: -1 Steps: 46 Epsilon: 0.2\n",
      "Episode:  674 , Return: 1 Steps: 57 Epsilon: 0.2\n",
      "Episode:  675 , Return: -1 Steps: 18 Epsilon: 0.2\n",
      "Episode:  675 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  676 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  676 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  677 , Return: -1 Steps: 72 Epsilon: 0.2\n",
      "Episode:  677 , Return: 1 Steps: 27 Epsilon: 0.2\n",
      "Episode:  678 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  678 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  679 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  679 , Return: 1 Steps: 35 Epsilon: 0.2\n",
      "Episode:  680 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  680 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  681 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  681 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  682 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  682 , Return: 1 Steps: 29 Epsilon: 0.2\n",
      "Episode:  683 , Return: -1 Steps: 48 Epsilon: 0.2\n",
      "Episode:  683 , Return: 1 Steps: 21 Epsilon: 0.2\n",
      "Episode:  684 , Return: -1 Steps: 52 Epsilon: 0.2\n",
      "Episode:  684 , Return: 1 Steps: 51 Epsilon: 0.2\n",
      "Episode:  685 , Return: -1 Steps: 18 Epsilon: 0.2\n",
      "Episode:  685 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  686 , Return: -1 Steps: 52 Epsilon: 0.2\n",
      "Episode:  686 , Return: 1 Steps: 41 Epsilon: 0.2\n",
      "Episode:  687 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  687 , Return: 1 Steps: 19 Epsilon: 0.2\n",
      "Episode:  688 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  688 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  689 , Return: -1 Steps: 26 Epsilon: 0.2\n",
      "Episode:  689 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  690 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  690 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  691 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  691 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  692 , Return: -1 Steps: 56 Epsilon: 0.2\n",
      "Episode:  692 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  693 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  693 , Return: 1 Steps: 55 Epsilon: 0.2\n",
      "Episode:  694 , Return: -1 Steps: 44 Epsilon: 0.2\n",
      "Episode:  694 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  695 , Return: -1 Steps: 46 Epsilon: 0.2\n",
      "Episode:  695 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  696 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  696 , Return: 1 Steps: 67 Epsilon: 0.2\n",
      "Episode:  697 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  697 , Return: 1 Steps: 45 Epsilon: 0.2\n",
      "Episode:  698 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  698 , Return: 1 Steps: 57 Epsilon: 0.2\n",
      "Episode:  699 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  699 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  700 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  700 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  701 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  701 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  702 , Return: -1 Steps: 64 Epsilon: 0.2\n",
      "Episode:  702 , Return: 1 Steps: 47 Epsilon: 0.2\n",
      "Episode:  703 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  703 , Return: 1 Steps: 67 Epsilon: 0.2\n",
      "Episode:  704 , Return: -1 Steps: 44 Epsilon: 0.2\n",
      "Episode:  704 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  705 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  705 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  706 , Return: -1 Steps: 54 Epsilon: 0.2\n",
      "Episode:  706 , Return: 1 Steps: 41 Epsilon: 0.2\n",
      "Episode:  707 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  707 , Return: 1 Steps: 27 Epsilon: 0.2\n",
      "Episode:  708 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  708 , Return: 1 Steps: 17 Epsilon: 0.2\n",
      "Episode:  709 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  709 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  710 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  710 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  711 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  711 , Return: 1 Steps: 35 Epsilon: 0.2\n",
      "Episode:  712 , Return: -1 Steps: 22 Epsilon: 0.2\n",
      "Episode:  712 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  713 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  713 , Return: 1 Steps: 59 Epsilon: 0.2\n",
      "Episode:  714 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  714 , Return: 1 Steps: 63 Epsilon: 0.2\n",
      "Episode:  715 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  715 , Return: 1 Steps: 73 Epsilon: 0.2\n",
      "Episode:  716 , Return: -1 Steps: 30 Epsilon: 0.2\n",
      "Episode:  716 , Return: 1 Steps: 63 Epsilon: 0.2\n",
      "Episode:  717 , Return: -1 Steps: 54 Epsilon: 0.2\n",
      "Episode:  717 , Return: 1 Steps: 35 Epsilon: 0.2\n",
      "Episode:  718 , Return: -1 Steps: 42 Epsilon: 0.2\n",
      "Episode:  718 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  719 , Return: -1 Steps: 20 Epsilon: 0.2\n",
      "Episode:  719 , Return: 1 Steps: 47 Epsilon: 0.2\n",
      "Episode:  720 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  720 , Return: 1 Steps: 65 Epsilon: 0.2\n",
      "Episode:  721 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  721 , Return: 1 Steps: 97 Epsilon: 0.2\n",
      "Episode:  722 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  722 , Return: 1 Steps: 67 Epsilon: 0.2\n",
      "Episode:  723 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  723 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  724 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  724 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  725 , Return: -1 Steps: 50 Epsilon: 0.2\n",
      "Episode:  725 , Return: 1 Steps: 51 Epsilon: 0.2\n",
      "Episode:  726 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  726 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  727 , Return: -1 Steps: 66 Epsilon: 0.2\n",
      "Episode:  727 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  728 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  728 , Return: 1 Steps: 57 Epsilon: 0.2\n",
      "Episode:  729 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  729 , Return: 1 Steps: 33 Epsilon: 0.2\n",
      "Episode:  730 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  730 , Return: 1 Steps: 51 Epsilon: 0.2\n",
      "Episode:  731 , Return: -1 Steps: 46 Epsilon: 0.2\n",
      "Episode:  731 , Return: 1 Steps: 39 Epsilon: 0.2\n",
      "Episode:  732 , Return: -1 Steps: 28 Epsilon: 0.2\n",
      "Episode:  732 , Return: 1 Steps: 17 Epsilon: 0.2\n",
      "Episode:  733 , Return: -1 Steps: 34 Epsilon: 0.2\n",
      "Episode:  733 , Return: 1 Steps: 47 Epsilon: 0.2\n",
      "Episode:  734 , Return: -1 Steps: 42 Epsilon: 0.2\n",
      "Episode:  734 , Return: 1 Steps: 37 Epsilon: 0.2\n",
      "Episode:  735 , Return: -1 Steps: 38 Epsilon: 0.2\n",
      "Episode:  735 , Return: 1 Steps: 23 Epsilon: 0.2\n",
      "Episode:  736 , Return: -1 Steps: 24 Epsilon: 0.2\n",
      "Episode:  736 , Return: 1 Steps: 43 Epsilon: 0.2\n",
      "Episode:  737 , Return: -1 Steps: 32 Epsilon: 0.2\n",
      "Episode:  737 , Return: 1 Steps: 55 Epsilon: 0.2\n",
      "Episode:  738 , Return: -1 Steps: 40 Epsilon: 0.2\n",
      "Episode:  738 , Return: 1 Steps: 47 Epsilon: 0.2\n",
      "Episode:  739 , Return: -1 Steps: 36 Epsilon: 0.2\n",
      "Episode:  739 , Return: 1 Steps: 49 Epsilon: 0.2\n",
      "Episode:  740 , Return: -1 Steps: 18 Epsilon: 0.2\n",
      "Episode:  740 , Return: 1 Steps: 25 Epsilon: 0.2\n",
      "Episode:  741 , Return: -1 Steps: 42 Epsilon: 0.2\n"
     ]
    }
   ],
   "source": [
    "#number of episodes\n",
    "num_episodes = 800\n",
    "\n",
    "# Define the batch size:\n",
    "batch_size = 128\n",
    "\n",
    "df, dqn_black, dqn_white = AGENT_EVALUATION(Stockfish_path, n_evaluations=num_episodes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGENT COLOR</th>\n",
       "      <th>OUTCOME</th>\n",
       "      <th>N STEPS</th>\n",
       "      <th>AGENT PIECES</th>\n",
       "      <th>OPPONENT PIECES</th>\n",
       "      <th>N OF EPISODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHITE</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLACK</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHITE</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BLACK</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WHITE</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  AGENT COLOR OUTCOME  N STEPS  AGENT PIECES  OPPONENT PIECES  N OF EPISODE\n",
       "0       WHITE    LOSS       18            12               15             0\n",
       "1       BLACK    LOSS       21            15                9             0\n",
       "2       WHITE    LOSS       14            10               16             1\n",
       "3       BLACK    LOSS        7            16               13             1\n",
       "4       WHITE    LOSS       28             5               13             2"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv(\"evaluation_data/deepqlearning_imitation.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn_white.target_network.save('MODELS/target_chess_white_pretrained.keras')\n",
    "dqn_white.main_network.save('MODELS/main_chess_white_pretrained.keras')\n",
    "dqn_black.target_network.save('MODELS/target_chess_black_pretrained.keras')\n",
    "dqn_black.main_network.save('MODELS/main_chess_black_pretrained.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
