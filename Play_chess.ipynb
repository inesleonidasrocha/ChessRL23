{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning Final Project \n",
    "\n",
    "Group members:\n",
    "1. `InÃªs Rocha: 20220052`\n",
    "2. `Isabel Dias: 20191215`\n",
    "3. `Joana Sousa: 20191205`\n",
    "4. `Rafael Dinis: 20221643`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import gym\n",
    "import gym_chess\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import copy\n",
    "from typing import Optional\n",
    "import random\n",
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "import time\n",
    "import chess.pgn\n",
    "import io\n",
    "\n",
    "from IPython.display import clear_output, display\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this model, we only considered the first board and the last information matrices. The state was also reshaped in order to be fed to the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_state(state):\n",
    "    state_boards= np.c_[state[:,:,:14], state[:,:,-7:]] #the state we want just has the current board and the last matrices with information\n",
    "    return np.array([state_boards.reshape(8,8,21)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "white_model = load_model('./models/main_chess_white_pretrained.keras')\n",
    "black_model = load_model('./models/main_chess_black_pretrained.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WHITE_PLAYER_POLICY(env, state):\n",
    "    Q_values = white_model.predict(state, verbose=0)[0]\n",
    "    legal_q_values = Q_values[env.legal_actions]\n",
    "    action = env.legal_actions[np.argmax(legal_q_values)]\n",
    "    return action\n",
    "\n",
    "\n",
    "def BLACK_PLAYER_POLICY(env, state):\n",
    "    Q_values = black_model.predict(state, verbose=0)[0]\n",
    "    legal_q_values = Q_values[env.legal_actions]\n",
    "    action = env.legal_actions[np.argmax(legal_q_values)]\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_WHITE_scenario(AGENT_POLICY):\n",
    "    env = gym.make(\n",
    "        \"ChessAlphaZero-v0\"\n",
    "    )  # We will use Alpha Zero's numenclature for the actions encodings\n",
    "\n",
    "    state = env.reset()\n",
    "    state = preprocess_state(state)\n",
    "    done = False\n",
    "    counter = 0  # Since each step represents a play in a chess game we are going to store the number of steps associated to the episode/game\n",
    "    while not done:\n",
    "        if (\n",
    "            counter % 2 == 0\n",
    "        ):  # If the step number is pair, this means that it is the WHITE player's turn\n",
    "            print(\"White's turn to play!\\n\", env.render(mode='unicode'))\n",
    "            action = AGENT_POLICY(env, state)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "\n",
    "            #pre-process next state\n",
    "            next_state = preprocess_state(next_state)\n",
    "\n",
    "        else:  # If the step number is not pair, aka odd, this means that it is the BLACK player's turn\n",
    "            illegal_action = True\n",
    "            print(\"Your turn to play!\\n\", env.render(mode='unicode'))\n",
    "            while illegal_action:\n",
    "                decoded_action = input(\"Enter your move in format a1b1 please: \")\n",
    "                try:\n",
    "                    action = env.encode(chess.Move.from_uci(decoded_action))\n",
    "                    next_state, reward, done, info = env.step(action)\n",
    "                    illegal_action = False\n",
    "                except (ValueError, AttributeError):\n",
    "                    print(\"Invalid move, try again with format 'a1b1'.\")\n",
    "                    continue\n",
    "\n",
    "\n",
    "            #pre-process next state\n",
    "            next_state = preprocess_state(next_state)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    return reward, np.ceil(counter / 2)\n",
    "\n",
    "\n",
    "def generate_BLACK_scenario(AGENT_POLICY):\n",
    "    env = gym.make(\n",
    "        \"ChessAlphaZero-v0\"\n",
    "    )  # We will use Alpha Zero's numenclature for the actions encodings\n",
    "\n",
    "    state = env.reset()\n",
    "    state = preprocess_state(state)\n",
    "    done = False\n",
    "    counter = 0  # Since each step represents a play in a chess game we are going to store the number of steps associated to the episode/game\n",
    "\n",
    "    while not done:\n",
    "        if (\n",
    "            counter % 2 == 1\n",
    "        ):  # If the step number is not pair, aka odd, this means that it is the BLACK player's turn\n",
    "            print(\"Black's turn to play!\\n\", env.render(mode='unicode'))\n",
    "            action = AGENT_POLICY(env, state)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "\n",
    "            #pre-process next state\n",
    "            next_state = preprocess_state(next_state)\n",
    "\n",
    "        else:  # If the step number is pair, this means that it is the WHITE player's turn\n",
    "            illegal_action = True\n",
    "            print(\"Your turn to play!\\n\", env.render(mode='unicode'))\n",
    "            while illegal_action:\n",
    "                decoded_action = input(\"Enter your move in format a1b1 please: \")\n",
    "                try:\n",
    "                    action = env.encode(chess.Move.from_uci(decoded_action))\n",
    "                    next_state, reward, done, info = env.step(action)\n",
    "                    illegal_action = False\n",
    "                except (ValueError, AttributeError):\n",
    "                    print(\"Invalid move, try again with format 'a1b1'.\")\n",
    "                    continue\n",
    "\n",
    "\n",
    "            #pre-process next state\n",
    "            next_state = preprocess_state(next_state)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    return reward, np.ceil(counter / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CHESS_GAME( AGENT_POLICY_WHITE, AGENT_POLICY_BLACK):\n",
    "    results_list = []\n",
    "    print(\"Hello! Welcome to my attempt of a chess player algorithm :)\\n\"\n",
    "      \"Here are the rules:\\n\"\n",
    "      \"- You will play 1 game where you'll randomly be assigned as white or black player\\n\"\n",
    "      \"- The white pieces to not have background, and the black pieces have filled/opaque background\\n\"\n",
    "      \"- When it is your turn, a pop-up window will appear on the top where you write your moves\\n\"\n",
    "      \"- To insert your move, you need to write in format a1b1, where first two digits is initial position and last two are position you want to move to\\n\"\n",
    "      \"- The columns are a-h (from left to right), and the rows are 1-8 (1 is bottom, 8 is top)\\n\"\n",
    "      \"Hope you have fun!\")\n",
    "    \n",
    "    player_black = random.choice([True, False]) #choose if player is white or black\n",
    "    if player_black:\n",
    "        generate_episode = generate_WHITE_scenario #generate white scenario, because algorithm plays white when player is black\n",
    "\n",
    "        reward, n_steps = generate_episode(AGENT_POLICY_WHITE)\n",
    "\n",
    "        if reward == 1:\n",
    "            result = \"VICTORY\"\n",
    "            print('YOU LOST! Try again next time :/')\n",
    "        elif reward == 0:\n",
    "            result = \"DRAW\"\n",
    "            print('DRAW! Guess you are as smart as a machine ;)')\n",
    "        else:\n",
    "            result = \"LOSS\"\n",
    "            print('YOU WON! CONGRATS!')\n",
    "\n",
    "        results_list.append([\"WHITE\", result, n_steps])\n",
    "\n",
    "    else:\n",
    "        generate_episode = generate_BLACK_scenario\n",
    "\n",
    "        reward, n_steps = generate_episode(AGENT_POLICY_BLACK)\n",
    "\n",
    "        if reward == -1:\n",
    "            result = \"VICTORY\"\n",
    "            print('YOU LOST! Try again next time :/')\n",
    "        elif reward == 0:\n",
    "            result = \"DRAW\"\n",
    "            print('DRAW! Guess you are as smart as a machine ;)')\n",
    "        else:\n",
    "            result = \"LOSS\"\n",
    "            print('YOU WON! CONGRATS!')\n",
    "\n",
    "        results_list.append([\"BLACK\", result, n_steps])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Welcome to my attempt of a chess player algorithm :)\n",
      "Here are the rules:\n",
      "- You will play 1 game where you'll randomly be assigned as white or black player\n",
      "- The white pieces to not have background, and the black pieces have filled/opaque background\n",
      "- To insert your move, you need to write in format a1b1, where first two digits is initial position and last two are position you want to move to\n",
      "- The columns are a-h (from left to right), and the rows are 1-8 (1 is bottom, 8 is top)\n",
      "Hope you have fun!\n",
      "Your turn to play!\n",
      " â â â â â â â â\n",
      "â â â â â â â â\n",
      "â­ â­ â­ â­ â­ â­ â­ â­\n",
      "â­ â­ â­ â­ â­ â­ â­ â­\n",
      "â­ â­ â­ â­ â­ â­ â­ â­\n",
      "â­ â­ â­ â­ â­ â­ â­ â­\n",
      "â â â â â â â â\n",
      "â â â â â â â â\n",
      "Invalid move, try again with format 'a1b1'.\n",
      "Invalid move, try again with format 'a1b1'.\n",
      "Black's turn to play!\n",
      " â â â â â â â â\n",
      "â â â â â â â â\n",
      "â­ â­ â­ â­ â­ â­ â­ â­\n",
      "â­ â­ â­ â­ â­ â­ â­ â­\n",
      "â­ â­ â­ â â­ â­ â­ â­\n",
      "â­ â­ â­ â­ â­ â­ â­ â­\n",
      "â â â â­ â â â â\n",
      "â â â â â â â â\n",
      "Your turn to play!\n",
      " â â â â â â â­ â\n",
      "â â â â â â â â\n",
      "â­ â­ â­ â­ â­ â â­ â­\n",
      "â­ â­ â­ â­ â­ â­ â­ â­\n",
      "â­ â­ â­ â â­ â­ â­ â­\n",
      "â­ â­ â­ â­ â­ â­ â­ â­\n",
      "â â â â­ â â â â\n",
      "â â â â â â â â\n",
      "Black's turn to play!\n",
      " â â â â â â â­ â\n",
      "â â â â â â â â\n",
      "â­ â­ â­ â­ â­ â â­ â­\n",
      "â­ â­ â­ â­ â­ â­ â­ â­\n",
      "â­ â­ â­ â â­ â­ â­ â­\n",
      "â­ â­ â­ â­ â­ â â­ â­\n",
      "â â â â­ â â â â\n",
      "â â â â â â â­ â\n",
      "Your turn to play!\n",
      " â â â â â â â­ â\n",
      "â â â â­ â â â â\n",
      "â­ â­ â­ â â­ â â­ â­\n",
      "â­ â­ â­ â­ â­ â­ â­ â­\n",
      "â­ â­ â­ â â­ â­ â­ â­\n",
      "â­ â­ â­ â­ â­ â â­ â­\n",
      "â â â â­ â â â â\n",
      "â â â â â â â­ â\n",
      "Black's turn to play!\n",
      " â â â â â â â­ â\n",
      "â â â â­ â â â â\n",
      "â­ â­ â­ â â­ â â­ â­\n",
      "â­ â­ â­ â­ â­ â­ â­ â­\n",
      "â­ â­ â­ â â­ â­ â­ â­\n",
      "â­ â­ â­ â­ â â â­ â­\n",
      "â â â â­ â­ â â â\n",
      "â â â â â â â­ â\n",
      "Your turn to play!\n",
      " â â â­ â â â â­ â\n",
      "â â â â â â â â\n",
      "â­ â­ â­ â â­ â â­ â­\n",
      "â­ â­ â­ â­ â­ â­ â­ â­\n",
      "â­ â­ â­ â â­ â­ â­ â­\n",
      "â­ â­ â­ â­ â â â­ â­\n",
      "â â â â­ â­ â â â\n",
      "â â â â â â â­ â\n",
      "Black's turn to play!\n",
      " â â â­ â â â â­ â\n",
      "â â â â â â â â\n",
      "â­ â­ â­ â â­ â â­ â­\n",
      "â­ â­ â­ â­ â­ â­ â­ â­\n",
      "â­ â­ â­ â â­ â­ â­ â­\n",
      "â­ â­ â­ â­ â â â â­\n",
      "â â â â­ â­ â â­ â\n",
      "â â â â â â â­ â\n",
      "Your turn to play!\n",
      " â â â â­ â â â­ â\n",
      "â â â â â â â â\n",
      "â­ â­ â­ â â­ â â­ â­\n",
      "â­ â­ â­ â­ â­ â­ â­ â­\n",
      "â­ â­ â­ â â­ â­ â­ â­\n",
      "â­ â­ â­ â­ â â â â­\n",
      "â â â â­ â­ â â­ â\n",
      "â â â â â â â­ â\n",
      "Invalid move, try again with format 'a1b1'.\n",
      "Black's turn to play!\n",
      " â â â â­ â â â­ â\n",
      "â â â â â â â â\n",
      "â­ â­ â­ â â­ â â­ â­\n",
      "â­ â­ â­ â­ â­ â­ â â­\n",
      "â­ â­ â­ â â­ â­ â­ â­\n",
      "â­ â­ â­ â­ â â­ â â­\n",
      "â â â â­ â­ â â­ â\n",
      "â â â â â â â­ â\n",
      "Your turn to play!\n",
      " â â­ â â­ â â â­ â\n",
      "â â â â â â â â\n",
      "â­ â­ â â â­ â â­ â­\n",
      "â­ â­ â­ â­ â­ â­ â â­\n",
      "â­ â­ â­ â â­ â­ â­ â­\n",
      "â­ â­ â­ â­ â â­ â â­\n",
      "â â â â­ â­ â â­ â\n",
      "â â â â â â â­ â\n"
     ]
    }
   ],
   "source": [
    "CHESS_GAME(WHITE_PLAYER_POLICY, BLACK_PLAYER_POLICY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
