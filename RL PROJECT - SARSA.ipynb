{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning Final Project \n",
    "\n",
    "Welcome to your Reinforcement Learning project focused on developing an RL agent capable of playing chess at a strategic level. Chess has long been considered a benchmark for measuring AI capabilities, and this project aims to leverage the power of RL to create an intelligent agent that can make optimal decisions in complex chess positions. By combining the principles of reinforcement learning with the rich strategic domain of chess, you will explore new approaches to create the most effective chess player.\n",
    "\n",
    "## Project Objectives:\n",
    "\n",
    "* Train an RL agent to play chess: The primary objective of this project is to develop an RL agent that can play chess at a high level of proficiency. The agent should be capable of evaluating chess positions and making strategic decisions.\n",
    "\n",
    "* Optimize decision-making using RL algorithms: Explore different RL algorithms, as seen in class, to train the agent. Compare and analise their effectiveness in learning and decision-making capabilities in the context of chess.\n",
    "\n",
    "* Use a challenging chess environment: Use a comprehensive environment for the agent to interact with, representing the rules and dynamics of chess. This environment will provide a realistic and challenging setting for the agent's training and evaluation.\n",
    "\n",
    "* Evaluate and benchmark performance: Assess the performance of the RL agent against different benchmarks from existing chess engines. You will compare your agent's performance to established chess engines to measure progress and identify areas for improvement.\n",
    "\n",
    "\n",
    "### Extra Objectives:\n",
    "\n",
    "* Investigate transfer learning and generalization: Explore techniques for transfer learning to leverage knowledge acquired in related domains or from pre-training on large chess datasets. Investigate the agent's ability to generalize its knowledge.\n",
    "\n",
    "* Enhance interpretability and analysis: Develop methods to analise the agent's decision-making process and provide insights into its strategic thinking. Investigate techniques to visualize the agent's evaluation of chess positions and understand its reasoning behind specific moves."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Play Chess! \n",
    "\n",
    "As you know [Chess](https://en.wikipedia.org/wiki/Chess) is a board game for two players, called White and Black, each controlling an army of chess pieces in their color, with the objective to checkmate the opponent's king.\n",
    "\n",
    "Chess is an abstract strategy game that involves no hidden information and no use of dice or cards. It is played on a chessboard with 64 squares arranged in an eight-by-eight grid. At the start, each player controls sixteen pieces: one king, one queen, two rooks, two bishops, two knights, and eight pawns. White moves first, followed by Black. Checkmating the opponent's king involves putting the king under immediate attack (in \"check\") whereby there is no way for it to escape.\n",
    "\n",
    "\n",
    "![](Images/CHESS_MOVES.PNG)\n",
    "\n",
    "* The king moves one square in any direction. There is also a special move called castling that involves moving the king and a rook. The king is the most valuable piece â€” attacks on the king must be immediately countered, and if this is impossible, the game is immediately lost.\n",
    "* A rook can move any number of squares along a rank or file, but cannot leap over other pieces. Along with the king, a rook is involved during the king's castling move.\n",
    "* A bishop can move any number of squares diagonally, but cannot leap over other pieces.\n",
    "* A queen combines the power of a rook and bishop and can move any number of squares along a rank, file, or diagonal, but cannot leap over other pieces.\n",
    "* A knight moves to any of the closest squares that are not on the same rank, file, or diagonal. (Thus the move forms an \"L\"-shape: two squares vertically and one square horizontally, or two squares horizontally and one square vertically.) The knight is the only piece that can leap over other pieces.\n",
    "* A pawn can move forward to the unoccupied square immediately in front of it on the same file, or on its first move it can advance two squares along the same file, provided both squares are unoccupied (black dots in the diagram). A pawn can capture an opponent's piece on a square diagonally in front of it by moving to that square (black crosses). It cannot capture a piece while advancing along the same file. A pawn has two special moves: the en passant capture and promotion."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The [Environment](https://github.com/iamlucaswolf/gym-chess)\n",
    "\n",
    "The environment gym-chess provides OpenAI Gym environments for the game of Chess. It comes with an implementation of the board and move encoding used in AlphaZero. \n",
    "\n",
    "Please install it using the command: \n",
    "\n",
    "`pip install gym-chess`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import gym\n",
    "import gym_chess\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Two player's game\n",
    "\n",
    "As you know chess is played by two players, as such the gym-chess environment gives you access to both players actions in a sequential matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WHITE_PLAYER_POLICY(env, state):\n",
    "    legal_actions = env.legal_actions\n",
    "    action = np.random.choice(legal_actions)\n",
    "\n",
    "    return action\n",
    "\n",
    "\n",
    "def BLACK_PLAYER_POLICY(env, state):\n",
    "    legal_actions = env.legal_actions\n",
    "    action = np.random.choice(legal_actions)\n",
    "\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\n",
    "    'ChessAlphaZero-v0'\n",
    ")  # We will use Alpha Zero's numenclature for the actions encodings\n",
    "\n",
    "state = env.reset()\n",
    "done = False\n",
    "counter = 0  # Since each step represents a play in a chess game we are going to store the number of steps associated to the episode/game\n",
    "\n",
    "while not done:\n",
    "    if (\n",
    "        counter % 2 == 0\n",
    "    ):  # If the step number is pair, this means that it is the WHITE player's turn\n",
    "        action = WHITE_PLAYER_POLICY(env, state)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "\n",
    "    else:  # If the step number is not pair, aka odd, this means that it is the BLACK player's turn\n",
    "        action = BLACK_PLAYER_POLICY(env, state)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "\n",
    "    counter += 1\n",
    "\n",
    "print(reward)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The agent receives a reward of +1 when the white player makes a winning move, and a reward of -1 when the black player makes a winning move. \n",
    "\n",
    "All other rewards are zero."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluationg your agent with [Stockfish](https://github.com/zhelyabuzhsky/stockfish)\n",
    "\n",
    "In order to have a good enough idea that our agent is actually playing well we need a benchmarkable opponent.\n",
    "\n",
    "As such we need to install stockfish a free and open-source chess engine. Stockfish has consistently ranked first or near the top of most chess-engine rating lists and, as of April 2023, is the strongest CPU chess engine in the world.\n",
    "\n",
    "`pip install stockfish`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stockfish import Stockfish"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StockFish has a python api as seen above, nevertheless the engine still needs to be downloaded [here](https://stockfishchess.org/download/) and used in the path.\n",
    "\n",
    "NOTE: You were given an engine already in moodle, nevertheless different computer systems (Windows, Mac, Ubuntu) might require other Stockfish engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stockfish_path = \"stockfish_15.1_win_x64_avx2/stockfish-windows-2022-x86-64-avx2\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions bellow generate episodes/games for a WHITE or BLACK Pieces Scenario respectively. We store the outcome of the episode (win/draw/loss) and the number of steps taken.\n",
    "\n",
    "#### Notice how the AGENT_POLICY function is used it recieves as inputs the env and the current state.\n",
    "`action = AGENT_POLICY(env, state)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_WHITE_scenario(Stockfish_path, AGENT_POLICY):\n",
    "    env = gym.make(\n",
    "        \"ChessAlphaZero-v0\"\n",
    "    )  # We will use Alpha Zero's numenclature for the actions encodings\n",
    "    stockfish = Stockfish(Stockfish_path)\n",
    "    stockfish.set_elo_rating(\n",
    "        100\n",
    "    )  # Default \"skill\" level is 1350, higher will increase the skill of stockfish \"player\". See more at https://en.wikipedia.org/wiki/Elo_rating_system\n",
    "\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    counter = 0  # Since each step represents a play in a chess game we are going to store the number of steps associated to the episode/game\n",
    "\n",
    "    while not done:\n",
    "        if (\n",
    "            counter % 2 == 0\n",
    "        ):  # If the step number is pair, this means that it is the WHITE player's turn\n",
    "            action = AGENT_POLICY(env, state)\n",
    "            decoded_action = str(env.decode(action))\n",
    "            stockfish.make_moves_from_current_position([decoded_action])\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "\n",
    "        else:  # If the step number is not pair, aka odd, this means that it is the BLACK player's turn\n",
    "            decoded_action = stockfish.get_best_move()\n",
    "            action = env.encode(chess.Move.from_uci(decoded_action))\n",
    "            stockfish.make_moves_from_current_position([decoded_action])\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "\n",
    "        counter += 1\n",
    "        state = next_state\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    return reward, np.ceil(counter / 2)\n",
    "\n",
    "\n",
    "def generate_BLACK_scenario(Stockfish_path, AGENT_POLICY):\n",
    "    env = gym.make(\n",
    "        \"ChessAlphaZero-v0\"\n",
    "    )  # We will use Alpha Zero's numenclature for the actions encodings\n",
    "    stockfish = Stockfish(Stockfish_path)\n",
    "    stockfish.set_elo_rating(\n",
    "        100\n",
    "    )  # Default \"skill\" level is 1350, higher will increase the skill of stockfish \"player\". See more at https://en.wikipedia.org/wiki/Elo_rating_system\n",
    "\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    counter = 0  # Since each step represents a play in a chess game we are going to store the number of steps associated to the episode/game\n",
    "\n",
    "    while not done:\n",
    "        if (\n",
    "            counter % 2 == 1\n",
    "        ):  # If the step number is not pair, aka odd, this means that it is the BLACK player's turn\n",
    "            action = AGENT_POLICY(env, state)\n",
    "            decoded_action = str(env.decode(action))\n",
    "            stockfish.make_moves_from_current_position([decoded_action])\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "\n",
    "        else:  # If the step number is pair, this means that it is the WHITE player's turn\n",
    "            decoded_action = stockfish.get_best_move()\n",
    "            action = env.encode(chess.Move.from_uci(decoded_action))\n",
    "            stockfish.make_moves_from_current_position([decoded_action])\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        state = next_state\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    return reward, np.ceil(counter / 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the function bellow a visualization is produced from the bechmarks made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AGENT_EVALUATION(Stockfish_path, AGENT_POLICY, n_evaluations=100):\n",
    "    results_list = []\n",
    "\n",
    "    for evaluation_number in tqdm(range(n_evaluations)):\n",
    "        generate_episode = generate_WHITE_scenario\n",
    "\n",
    "        reward, n_steps = generate_episode(Stockfish_path, AGENT_POLICY)\n",
    "\n",
    "        if reward == 1:\n",
    "            result = \"VICTORY\"\n",
    "        elif reward == 0:\n",
    "            result = \"DRAW\"\n",
    "        else:\n",
    "            result = \"LOSS\"\n",
    "\n",
    "        results_list.append([\"WHITE\", result, n_steps])\n",
    "\n",
    "        generate_episode = generate_BLACK_scenario\n",
    "\n",
    "        reward, n_steps = generate_episode(Stockfish_path, AGENT_POLICY)\n",
    "\n",
    "        if reward == -1:\n",
    "            result = \"VICTORY\"\n",
    "        elif reward == 0:\n",
    "            result = \"DRAW\"\n",
    "        else:\n",
    "            result = \"LOSS\"\n",
    "\n",
    "        results_list.append([\"BLACK\", result, n_steps])\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        results_list, columns=[\"AGENT COLOR\", \"OUTCOME\", \"N STEPS\"]\n",
    "    ).astype(\"int\", errors=\"ignore\")\n",
    "\n",
    "    plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "    results_group = (\n",
    "        df.groupby([\"AGENT COLOR\", \"OUTCOME\"])\n",
    "        .count()\n",
    "        .rename(columns={\"N STEPS\": \"GAMES\"})\n",
    "    )\n",
    "\n",
    "    n_games = results_group.sum()[0]\n",
    "\n",
    "    results_group = (2 * 100 * results_group / (n_games)).astype(\"int\")\n",
    "\n",
    "    viz_df = (\n",
    "        results_group.reset_index()\n",
    "        .pivot_table(index=\"AGENT COLOR\", columns=\"OUTCOME\", values=\"GAMES\")\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    viz_df.plot(kind=\"barh\", stacked=True)\n",
    "\n",
    "    plt.xlabel(\"Percentage\")\n",
    "    plt.title(f\"EVALUATION RESULTS FOR {n_games} GAMES\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929e98831f964c00981450f7f84ce321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = AGENT_EVALUATION(Stockfish_path, WHITE_PLAYER_POLICY, n_evaluations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGENT COLOR</th>\n",
       "      <th>OUTCOME</th>\n",
       "      <th>N STEPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHITE</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLACK</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHITE</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BLACK</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WHITE</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  AGENT COLOR OUTCOME  N STEPS\n",
       "0       WHITE    LOSS       14\n",
       "1       BLACK    LOSS       19\n",
       "2       WHITE    LOSS       10\n",
       "3       BLACK    LOSS       24\n",
       "4       WHITE    LOSS       22"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ready to Play Chess?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in SARSA is to initialize  the Q-values. However the chess is very complex, so we will be using a QNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from IPython.display import clear_output, display\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "# Set the seed for NumPy\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set the seed for TensorFlow\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "#set seed for random\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "#this neural network will aproximate the q-values for our SARSA\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, state , output_size):\n",
    "        self.output_size = output_size\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.x_layer = nn.Linear(119, 150)\n",
    "        self.h_layer = nn.Linear(150, 120)\n",
    "        self.y_layer = nn.Linear(120, output_size)\n",
    "        #print(output_size)\n",
    "        \n",
    "\n",
    "    def forward(self, state):\n",
    "        xh = F.relu(self.x_layer(state))\n",
    "        hh = F.relu(self.h_layer(xh))\n",
    "        state_action_values = self.y_layer(hh)\n",
    "        return state_action_values.view(-1, self.output_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of agent class to make policy and update network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    def best_move(self, state):\\n        state_tensor = torch.from_numpy(state).float()\\n        \\n        return np.argmax(self.qnet(state_tensor).data.numpy())'"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this class will be our agent\n",
    "\n",
    "class SARSAAgent(object):\n",
    "    def __init__(self, state, action_dim, env):\n",
    "        #initialize variables for the sarsa agent\n",
    "        self.qnet = QNetwork(state, action_dim)\n",
    "        self.qnet_optim = torch.optim.Adam(self.qnet.parameters(), lr=0.001)\n",
    "        self.gamma = 0.9\n",
    "        self.MSELoss_function = nn.MSELoss()\n",
    "        self.replay_buffer = ReplayBuffer()\n",
    "        self.env=env\n",
    "        pass\n",
    "    \n",
    "    # this is our SARSA policy, e-greed\n",
    "    def SARSA_POLICY(self, env, state, epsilon):\n",
    "\n",
    "        if np.random.uniform(0, 1) < epsilon:\n",
    "                legal_actions = env.legal_actions\n",
    "                return np.random.choice(legal_actions)  # choose random action\n",
    "        else:\n",
    "                state_tensor = torch.from_numpy(state).float() #transfor state into tensor so we are able to  input it\n",
    "                network_output = self.qnet(state_tensor) #predict the qualues for this state\n",
    "                reshaped_output = network_output[0] # choosing only the dimension that we want\n",
    "                #print(reshaped_output.shape)\n",
    "                legal_q_values= reshaped_output[env.legal_actions] #choose only the legal actions\n",
    "                return env.legal_actions[np.argmax(legal_q_values.detach().numpy())]  # choose greedy action\n",
    "        \n",
    "    def update_Sarsa_Network(self, state, next_state, action, next_action, reward, terminals, alpha=.85):\n",
    "        #obtaining the current Q-values for all the possible action in the the next_state\n",
    "        qsa = torch.gather(self.qnet(state), dim=1, index=action.long())\n",
    "        #next_state = torch.sum(input_tensor, dim=(1, 2, 3))\n",
    "        qsa_next_action = torch.gather(self.qnet(next_state), dim=1, index=next_action.long())\n",
    "        #not_terminals = 1 - terminals\n",
    "        qsa_next_target = qsa + alpha*(reward  + (self.gamma * qsa_next_action-qsa))\n",
    "        q_network_loss = self.MSELoss_function(qsa_next_action, qsa_next_target.detach()) \n",
    "        #initializes the gradients of the Q-network parameters to zero\n",
    "        self.qnet_optim.zero_grad()\n",
    "        q_network_loss.backward() #backpropagation\n",
    "        self.qnet_optim.step() #updates the Q-network parameters\n",
    "        \n",
    "    #The purpose of this code is to update the SARSA network using a specified number of iterations (update_rate). \n",
    "    #In each iteration, a minibatch of transitions is sampled from a replay buffer, and the network is updated using the update_Sarsa_Network method.  \n",
    "    def update_s(self, update_rate):\n",
    "        for i in range(update_rate):\n",
    "            states, next_states, actions, next_actions, rewards, terminals = self.replay_buffer.sample_minibatch_sarsa(64) #minibatch iniatilization\n",
    "            #variables preparation for updating the network\n",
    "            states = torch.Tensor(states)\n",
    "            next_states = torch.Tensor(next_states)\n",
    "            actions = torch.Tensor(actions)\n",
    "\n",
    "            #environment crition to be able to decode moves for the next_actions\n",
    "            second_env =  gym.make(\"ChessAlphaZero-v0\")\n",
    "            second_env.reset()\n",
    "            #print(next_actions)\n",
    "            next_actions = torch.Tensor([[self.env.encode(chess.Move.from_uci(move[0]))] if isinstance(move[0], str) else [move[0]] for move in next_actions])\n",
    "            rewards = torch.Tensor(rewards)\n",
    "            terminals = torch.Tensor(terminals)\n",
    "            second_env.close()\n",
    "            #print(states.shape, actions.shape)\n",
    "            #print(next_states.shape, next_actions.shape)\n",
    "            #call the network update\n",
    "            self.update_Sarsa_Network(states, next_states, actions, next_actions, rewards, terminals)\n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A replay buffer is used in reinforcement learning algorithms to store and sample experiences for training the agent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ReplayBuffer(object):\n",
    "    def __init__(self):\n",
    "        self.buffer = []\n",
    "        self.buffer_s = []\n",
    "    \n",
    "    #data storing\n",
    "    def add_to_buffer_sarsa(self, data):\n",
    "        #data must be of the form (state,next_state,action,n_action,reward,terminal)\n",
    "        self.buffer_s.append(data)\n",
    "\n",
    "    #define sample of minibach\n",
    "    def sample_minibatch_sarsa(self,minibatch_length):\n",
    "        states = []\n",
    "        next_states = []\n",
    "        actions = []\n",
    "        next_actions = []\n",
    "        rewards = []\n",
    "        terminals = []\n",
    "        for i in range(minibatch_length):\n",
    "            random_int = np.random.randint(0, len(self.buffer_s)-1) \n",
    "            transition = self.buffer_s[random_int]\n",
    "            states.append(transition[0])\n",
    "            next_states.append(transition[1])\n",
    "            actions.append(transition[2])\n",
    "            next_actions.append(transition[3])\n",
    "            rewards.append(transition[4])\n",
    "            terminals.append(transition[5])\n",
    "        return states, next_states, actions, next_actions, rewards, terminals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the functions to play the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_WHITE_SARSA(Stockfish_path, agent, epsilon):\n",
    "    #variables creation\n",
    "    env = gym.make(\"ChessAlphaZero-v0\")  # We will use Alpha Zero's numenclature for the actions encodinng\n",
    "    stockfish = Stockfish(Stockfish_path)\n",
    "    stockfish.set_elo_rating(100) \n",
    "    counter = 0 \n",
    "    done = False\n",
    "    final_reward = 0\n",
    "    \n",
    "    #initialize the state by resetting the environment\n",
    "    state = env.reset()\n",
    "\n",
    "    #for each step in the episode:\n",
    "    while not done:\n",
    "        #print('counter', counter)\n",
    "        if (counter % 2 == 0): #if pair then it is white's turn\n",
    "            action= agent.SARSA_POLICY(env, state, epsilon)\n",
    "            decoded_action = str(env.decode(action))\n",
    "            stockfish.make_moves_from_current_position([decoded_action]) \n",
    "                \n",
    "            #perform the selected action and store the next state information: \n",
    "            next_state, reward, done, info = env.step(action)\n",
    "\n",
    "            #if the next state is not the terminal one\n",
    "            if not done:\n",
    "                next_action= agent.SARSA_POLICY(env, next_state, epsilon) #get the next best action by sarsa\n",
    "                #print('next_Actionss', type(next_action))\n",
    "                #add the data to the buffer\n",
    "                agent.replay_buffer.add_to_buffer_sarsa((state, next_state, [action], [next_action], [reward],[done]))\n",
    "\n",
    "            #if player removed piece from opponent, increase reward\n",
    "            if next_state[:,:, :6].sum() < state[:,:, :6].sum(): \n",
    "                reward += 0.01\n",
    "            \n",
    "            #add the reward to the final reward\n",
    "            final_reward += reward\n",
    "            #print(done)\n",
    "\n",
    "        else:  \n",
    "            # If the step number is not pair, aka odd, this means that it is the BLACK player's turn\n",
    "            decoded_action = stockfish.get_best_move()\n",
    "            action = env.encode(chess.Move.from_uci(decoded_action))\n",
    "            stockfish.make_moves_from_current_position([decoded_action])\n",
    "\n",
    "            #perform the selected action and store the next state information: \n",
    "            next_state, reward, done, info = env.step(action)Âº\n",
    "\n",
    "            #if the next state is not the terminal one\n",
    "            if not done:\n",
    "                next_action = stockfish.get_best_move()\n",
    "                #print('next_Action st', type(next_action))\n",
    "                #update data for minibatch\n",
    "                agent.replay_buffer.add_to_buffer_sarsa((state, next_state, [action], [next_action], [reward],[done]))\n",
    "            #print(done)\n",
    "\n",
    "        #if the current state is the terminal state then break:\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "\n",
    "        counter += 1\n",
    "        state = next_state #update next action to current action\n",
    "\n",
    "    agent.update_s(32) #update network\n",
    "    \n",
    "    #update epsilon\n",
    "    if epsilon > 0.2:\n",
    "        epsilon *= 0.995\n",
    "    \n",
    "    if epsilon <= 0.2:\n",
    "        epsilon = 0.2\n",
    "\n",
    "\n",
    "    env.close()\n",
    "    print('Return:', final_reward, 'Steps:', counter, 'Epsilon:', epsilon)\n",
    "    \n",
    "\n",
    "    return final_reward, np.ceil(counter / 2), epsilon, state\n",
    "\n",
    "\n",
    "def generate_BLACK_SARSA(Stockfish_path, agent, epsilon):\n",
    "    #variables creation\n",
    "    env = gym.make(\"ChessAlphaZero-v0\")  # We will use Alpha Zero's numenclature for the actions encodinng\n",
    "    stockfish = Stockfish(Stockfish_path)\n",
    "    stockfish.set_elo_rating(100) \n",
    "    counter = 0 \n",
    "    done = False\n",
    "    final_reward = 0\n",
    "    \n",
    "    #initialize the state by resetting the environment\n",
    "    state = env.reset()\n",
    "\n",
    "    #for each step in the episode:\n",
    "    while not done:\n",
    "        if (counter % 2 == 1): #if not pair then it is black's turn\n",
    "            action= agent.SARSA_POLICY(env, state, epsilon)\n",
    "            decoded_action = str(env.decode(action))\n",
    "            stockfish.make_moves_from_current_position([decoded_action])\n",
    "                \n",
    "            #store the next state information: \n",
    "            next_state, reward, done, info = env.step(action)\n",
    "\n",
    "            #if the next state is not the terminal one\n",
    "            if not done:\n",
    "                next_action= agent.SARSA_POLICY(env, next_state, epsilon)\n",
    "                #print('next_Action', type(next_action))\n",
    "\n",
    "                #update data for minibatch\n",
    "                agent.replay_buffer.add_to_buffer_sarsa((state, next_state, [action], [next_action], [-reward],[done]))\n",
    "\n",
    "            #if player removed piece from opponent, increase reward\n",
    "            if next_state[:,:, 6:13].sum() < state[:,:, 6:13].sum(): \n",
    "                #print(counter, next_state[:,:, 6:13].sum(),state[:,:, 6:13].sum() )\n",
    "                final_reward -= 0.01\n",
    "                \n",
    "            #print(done)\n",
    "\n",
    "            final_reward += reward\n",
    "\n",
    "        else:  \n",
    "            # If the step number is not pair, aka odd, this means that it is the BLACK player's turn\n",
    "            decoded_action = stockfish.get_best_move()\n",
    "            action = env.encode(chess.Move.from_uci(decoded_action))\n",
    "            stockfish.make_moves_from_current_position([decoded_action])\n",
    "\n",
    "            #store the next state information: \n",
    "            next_state, reward, done, info = env.step(action)\n",
    "\n",
    "            #if the next state is not the terminal one\n",
    "            if not done:\n",
    "                next_action = stockfish.get_best_move()\n",
    "                #update data for minibatch\n",
    "                agent.replay_buffer.add_to_buffer_sarsa((state, next_state, [action], [next_action], [-reward],[done]))\n",
    "            #print('before', state[:,:, 6:13].sum(), state[:,:, :6].sum() )\n",
    "    \n",
    "            state = next_state #update next action to current action\n",
    "            #print('after', state[:,:, 6:13].sum(), state[:,:, :6].sum())\n",
    "\n",
    "        #if the current state is the terminal state then break:\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        counter += 1\n",
    "        state = next_state\n",
    "        \n",
    "        \n",
    "\n",
    "    agent.update_s(32) #update network\n",
    "    \n",
    "    #update epsilon\n",
    "    if epsilon > 0.2:\n",
    "        epsilon *= 0.995\n",
    "    \n",
    "    if epsilon <= 0.2:\n",
    "        epsilon = 0.2\n",
    "\n",
    "\n",
    "    env.close()\n",
    "    print('Return:', final_reward, 'Steps:', counter, 'Epsilon:', epsilon)\n",
    "\n",
    "    return final_reward, np.ceil(counter / 2), epsilon, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_pieces={0: \"pawn\", 1: \"horse\", 2: \"knight\", 3: \"rook\", 4: \"queen\", 5: \"king\"} #PARA TODOS\n",
    "black_pieces={6: \"pawn\", 7: \"horse\", 8: \"knight\", 9: \"rook\", 10: \"queen\", 11: \"king\"} #PARA TODOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AGENT_EVALUATION(Stockfish_path, n_evaluations=100, epsilon = 0.99):\n",
    "    results_list = []\n",
    "    env= gym.make(\"ChessAlphaZero-v0\")\n",
    "    state = env.reset()\n",
    "    \n",
    "    #creation of agentd for each of the colors\n",
    "    WHITE_agent = SARSAAgent(state.shape, env.action_space.n, env)\n",
    "    BLACK_agent = SARSAAgent(state.shape, env.action_space.n, env)\n",
    "    \n",
    "    #intiate episodes\n",
    "    for evaluation_number in tqdm(range(n_evaluations)):\n",
    "        \n",
    "        generate_episode = generate_WHITE_SARSA \n",
    "\n",
    "        #make game\n",
    "        reward, n_steps, epsilon, last_state = generate_episode(Stockfish_path, WHITE_agent, epsilon)\n",
    "        print('part 1')\n",
    "\n",
    "        #game classification\n",
    "        if reward == 1:\n",
    "            result = \"VICTORY\"\n",
    "        elif reward == 0:\n",
    "            result = \"DRAW\"\n",
    "        else:\n",
    "            result = \"LOSS\"\n",
    "        \n",
    "        #store last state boards\n",
    "        agent_pieces= last_state[:,:, 6:13].sum()\n",
    "        opponent_pieces= last_state[:,:, :6].sum()\n",
    "        remaining_pieces=[] #PARA TODOS\n",
    "\n",
    "        #count pieces\n",
    "        for piece in white_pieces: \n",
    "            remaining_pieces.append(last_state[:,:,piece].sum()) \n",
    "        results_list.append([\"WHITE\", result, n_steps, agent_pieces, opponent_pieces, evaluation_number, *remaining_pieces]) \n",
    "        \n",
    "\n",
    "        generate_episode = generate_BLACK_SARSA\n",
    "        #make game\n",
    "        reward, n_steps, epsilon, last_state = generate_episode(Stockfish_path, BLACK_agent, epsilon)\n",
    "        print('part 2')\n",
    "\n",
    "        #classify game \n",
    "        if reward == -1:\n",
    "            result = \"VICTORY\"\n",
    "        elif reward == 0:\n",
    "            result = \"DRAW\"\n",
    "        else:\n",
    "            result = \"LOSS\"\n",
    "\n",
    "        #store game\n",
    "        agent_pieces= last_state[:,:, :6].sum() \n",
    "        opponent_pieces= last_state[:,:, 6:13].sum() \n",
    "        remaining_pieces=[] \n",
    "        #count pieces\n",
    "        for piece in black_pieces: \n",
    "            remaining_pieces.append(last_state[:,:,piece].sum()) #PARA TODOS: podem ter de ajustar para [:, :,piece]\n",
    "        results_list.append([\"BLACK\", result, n_steps, agent_pieces, opponent_pieces, evaluation_number, *remaining_pieces]) #PARA TODOS\n",
    "        print('done')\n",
    "\n",
    "    #make dataframe\n",
    "    df = pd.DataFrame(\n",
    "        results_list, columns=[\"AGENT COLOR\", \"OUTCOME\", \"N STEPS\", \"AGENT PIECES\", \"OPPONENT PIECES\", \"EPISODE\",\"pawn\", \"horse\", \"knight\", \"rook\", \"queen\", \"king\"]  #PARA TODOS\n",
    "    ).astype(\"int\", errors=\"ignore\")\n",
    "    \n",
    "    plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "    results_group = (\n",
    "        df.groupby([\"AGENT COLOR\", \"OUTCOME\"])\n",
    "        .count()\n",
    "        .rename(columns={\"N STEPS\": \"GAMES\"})\n",
    "    )\n",
    "\n",
    "    n_games = results_group.sum()[0]\n",
    "\n",
    "    results_group = (2 * 100 * results_group / (n_games)).astype(\"int\")\n",
    "\n",
    "    viz_df = (\n",
    "        results_group.reset_index()\n",
    "        .pivot_table(index=\"AGENT COLOR\", columns=\"OUTCOME\", values=\"GAMES\")\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    viz_df.plot(kind=\"barh\", stacked=True)\n",
    "\n",
    "    plt.xlabel(\"Percentage\")\n",
    "    plt.title(f\"EVALUATION RESULTS FOR {n_games} GAMES\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return df, WHITE_agent, BLACK_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3db8a6cc8a432ab2af1c34862d62b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return: 0.01 Steps: 17 Epsilon: 0.98505\n",
      "part 1\n",
      "Return: -0.21000000000000005 Steps: 44 Epsilon: 0.98012475\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 47 Epsilon: 0.97522412625\n",
      "part 1\n",
      "Return: -0.05 Steps: 16 Epsilon: 0.97034800561875\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 61 Epsilon: 0.9654962655906563\n",
      "part 1\n",
      "Return: -0.13999999999999999 Steps: 38 Epsilon: 0.960668784262703\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 33 Epsilon: 0.9558654403413894\n",
      "part 1\n",
      "Return: -0.09999999999999999 Steps: 30 Epsilon: 0.9510861131396825\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 33 Epsilon: 0.9463306825739841\n",
      "part 1\n",
      "Return: -0.08 Steps: 24 Epsilon: 0.9415990291611142\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 11 Epsilon: 0.9368910340153086\n",
      "part 1\n",
      "Return: -0.3000000000000001 Steps: 64 Epsilon: 0.9322065788452321\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 13 Epsilon: 0.9275455459510059\n",
      "part 1\n",
      "Return: -0.09999999999999999 Steps: 42 Epsilon: 0.9229078182212509\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 27 Epsilon: 0.9182932791301447\n",
      "part 1\n",
      "Return: -0.060000000000000005 Steps: 22 Epsilon: 0.9137018127344939\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 25 Epsilon: 0.9091333036708215\n",
      "part 1\n",
      "Return: -0.16 Steps: 44 Epsilon: 0.9045876371524674\n",
      "part 2\n",
      "done\n",
      "Return: 0.04 Steps: 47 Epsilon: 0.900064698966705\n",
      "part 1\n",
      "Return: -0.20000000000000004 Steps: 52 Epsilon: 0.8955643754718715\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 65 Epsilon: 0.8910865535945122\n",
      "part 1\n",
      "Return: 0.0 Steps: 12 Epsilon: 0.8866311208265396\n",
      "part 2\n",
      "done\n",
      "Return: 0.01 Steps: 39 Epsilon: 0.8821979652224069\n",
      "part 1\n",
      "Return: -0.08 Steps: 22 Epsilon: 0.8777869753962949\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 19 Epsilon: 0.8733980405193135\n",
      "part 1\n",
      "Return: -0.10999999999999999 Steps: 32 Epsilon: 0.8690310503167169\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 27 Epsilon: 0.8646858950651333\n",
      "part 1\n",
      "Return: -0.16 Steps: 46 Epsilon: 0.8603624655898076\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 29 Epsilon: 0.8560606532618585\n",
      "part 1\n",
      "Return: -0.20000000000000004 Steps: 46 Epsilon: 0.8517803499955492\n",
      "part 2\n",
      "done\n",
      "Return: 0.01 Steps: 45 Epsilon: 0.8475214482455714\n",
      "part 1\n",
      "Return: -0.04 Steps: 20 Epsilon: 0.8432838410043435\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 15 Epsilon: 0.8390674217993218\n",
      "part 1\n",
      "Return: -0.03 Steps: 16 Epsilon: 0.8348720846903251\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 37 Epsilon: 0.8306977242668735\n",
      "part 1\n",
      "Return: -0.060000000000000005 Steps: 32 Epsilon: 0.8265442356455391\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 27 Epsilon: 0.8224115144673114\n",
      "part 1\n",
      "Return: -0.02 Steps: 14 Epsilon: 0.8182994568949749\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 31 Epsilon: 0.8142079596105\n",
      "part 1\n",
      "Return: -0.05 Steps: 22 Epsilon: 0.8101369198124475\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 33 Epsilon: 0.8060862352133853\n",
      "part 1\n",
      "Return: -0.02 Steps: 16 Epsilon: 0.8020558040373184\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 55 Epsilon: 0.7980455250171318\n",
      "part 1\n",
      "Return: -0.08 Steps: 32 Epsilon: 0.7940552973920462\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 47 Epsilon: 0.7900850209050859\n",
      "part 1\n",
      "Return: -0.10999999999999999 Steps: 34 Epsilon: 0.7861345958005604\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 53 Epsilon: 0.7822039228215576\n",
      "part 1\n",
      "Return: -0.22000000000000006 Steps: 54 Epsilon: 0.7782929032074498\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 29 Epsilon: 0.7744014386914125\n",
      "part 1\n",
      "Return: -0.2900000000000001 Steps: 62 Epsilon: 0.7705294314979555\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 13 Epsilon: 0.7666767843404657\n",
      "part 1\n",
      "Return: -0.10999999999999999 Steps: 26 Epsilon: 0.7628434004187634\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 31 Epsilon: 0.7590291834166696\n",
      "part 1\n",
      "Return: -0.09 Steps: 32 Epsilon: 0.7552340374995863\n",
      "part 2\n",
      "done\n",
      "Return: 0.01 Steps: 11 Epsilon: 0.7514578673120883\n",
      "part 1\n",
      "Return: -0.23000000000000007 Steps: 54 Epsilon: 0.7477005779755278\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 9 Epsilon: 0.7439620750856502\n",
      "part 1\n",
      "Return: -0.11999999999999998 Steps: 34 Epsilon: 0.7402422647102219\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 45 Epsilon: 0.7365410533866708\n",
      "part 1\n",
      "Return: -0.12999999999999998 Steps: 34 Epsilon: 0.7328583481197374\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 25 Epsilon: 0.7291940563791387\n",
      "part 1\n",
      "Return: -0.05 Steps: 28 Epsilon: 0.725548086097243\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 33 Epsilon: 0.7219203456667568\n",
      "part 1\n",
      "Return: -0.11999999999999998 Steps: 36 Epsilon: 0.718310743938423\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 21 Epsilon: 0.7147191902187309\n",
      "part 1\n",
      "Return: -0.09999999999999999 Steps: 32 Epsilon: 0.7111455942676372\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 31 Epsilon: 0.707589866296299\n",
      "part 1\n",
      "Return: -0.08 Steps: 28 Epsilon: 0.7040519169648175\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 45 Epsilon: 0.7005316573799935\n",
      "part 1\n",
      "Return: -0.26000000000000006 Steps: 62 Epsilon: 0.6970289990930935\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 27 Epsilon: 0.693543854097628\n",
      "part 1\n",
      "Return: -0.09999999999999999 Steps: 28 Epsilon: 0.6900761348271398\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 27 Epsilon: 0.6866257541530041\n",
      "part 1\n",
      "Return: -0.19000000000000003 Steps: 42 Epsilon: 0.683192625382239\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 51 Epsilon: 0.6797766622553278\n",
      "part 1\n",
      "Return: -0.07 Steps: 24 Epsilon: 0.6763777789440512\n",
      "part 2\n",
      "done\n",
      "Return: 0.03 Steps: 19 Epsilon: 0.6729958900493309\n",
      "part 1\n",
      "Return: -0.060000000000000005 Steps: 20 Epsilon: 0.6696309105990843\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 27 Epsilon: 0.6662827560460889\n",
      "part 1\n",
      "Return: -0.08 Steps: 24 Epsilon: 0.6629513422658584\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 45 Epsilon: 0.6596365855545291\n",
      "part 1\n",
      "Return: 0.0 Steps: 10 Epsilon: 0.6563384026267565\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 43 Epsilon: 0.6530567106136227\n",
      "part 1\n",
      "Return: -0.08 Steps: 24 Epsilon: 0.6497914270605546\n",
      "part 2\n",
      "done\n",
      "Return: 0.060000000000000005 Steps: 43 Epsilon: 0.6465424699252518\n",
      "part 1\n",
      "Return: -0.03 Steps: 34 Epsilon: 0.6433097575756255\n",
      "part 2\n",
      "done\n",
      "Return: 0.02 Steps: 11 Epsilon: 0.6400932087877473\n",
      "part 1\n",
      "Return: -0.09 Steps: 22 Epsilon: 0.6368927427438086\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 41 Epsilon: 0.6337082790300895\n",
      "part 1\n",
      "Return: -0.08 Steps: 28 Epsilon: 0.6305397376349391\n",
      "part 2\n",
      "done\n",
      "Return: 0.02 Steps: 29 Epsilon: 0.6273870389467644\n",
      "part 1\n",
      "Return: -0.07 Steps: 22 Epsilon: 0.6242501037520306\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 17 Epsilon: 0.6211288532332705\n",
      "part 1\n",
      "Return: -0.10999999999999999 Steps: 28 Epsilon: 0.6180232089671042\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 49 Epsilon: 0.6149330929222686\n",
      "part 1\n",
      "Return: -0.22000000000000006 Steps: 50 Epsilon: 0.6118584274576573\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 27 Epsilon: 0.608799135320369\n",
      "part 1\n",
      "Return: -0.09 Steps: 24 Epsilon: 0.6057551396437671\n",
      "part 2\n",
      "done\n",
      "Return: 0.04 Steps: 15 Epsilon: 0.6027263639455483\n",
      "part 1\n",
      "Return: -0.18000000000000002 Steps: 40 Epsilon: 0.5997127321258207\n",
      "part 2\n",
      "done\n",
      "Return: 0.04 Steps: 21 Epsilon: 0.5967141684651915\n",
      "part 1\n",
      "Return: -0.12999999999999998 Steps: 30 Epsilon: 0.5937305976228656\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 27 Epsilon: 0.5907619446347513\n",
      "part 1\n",
      "Return: -0.09999999999999999 Steps: 30 Epsilon: 0.5878081349115776\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 17 Epsilon: 0.5848690942370197\n",
      "part 1\n",
      "Return: -0.12999999999999998 Steps: 36 Epsilon: 0.5819447487658346\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 37 Epsilon: 0.5790350250220054\n",
      "part 1\n",
      "Return: -0.01 Steps: 8 Epsilon: 0.5761398498968954\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 35 Epsilon: 0.5732591506474108\n",
      "part 1\n",
      "Return: -0.07 Steps: 20 Epsilon: 0.5703928548941738\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 31 Epsilon: 0.5675408906197029\n",
      "part 1\n",
      "Return: -0.20000000000000004 Steps: 52 Epsilon: 0.5647031861666044\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 23 Epsilon: 0.5618796702357713\n",
      "part 1\n",
      "Return: 0.0 Steps: 10 Epsilon: 0.5590702718845925\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 21 Epsilon: 0.5562749205251695\n",
      "part 1\n",
      "Return: -0.11999999999999998 Steps: 30 Epsilon: 0.5534935459225436\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 15 Epsilon: 0.550726078192931\n",
      "part 1\n",
      "Return: -0.04 Steps: 14 Epsilon: 0.5479724478019663\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 59 Epsilon: 0.5452325855629565\n",
      "part 1\n",
      "Return: -0.21000000000000005 Steps: 56 Epsilon: 0.5425064226351417\n",
      "part 2\n",
      "done\n",
      "Return: 0.03 Steps: 25 Epsilon: 0.539793890521966\n",
      "part 1\n",
      "Return: -0.15 Steps: 34 Epsilon: 0.5370949210693562\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 33 Epsilon: 0.5344094464640095\n",
      "part 1\n",
      "Return: -0.17 Steps: 42 Epsilon: 0.5317373992316894\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 47 Epsilon: 0.5290787122355309\n",
      "part 1\n",
      "Return: -0.11999999999999998 Steps: 28 Epsilon: 0.5264333186743533\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 15 Epsilon: 0.5238011520809815\n",
      "part 1\n",
      "Return: -0.09 Steps: 26 Epsilon: 0.5211821463205767\n",
      "part 2\n",
      "done\n",
      "Return: 0.01 Steps: 33 Epsilon: 0.5185762355889738\n",
      "part 1\n",
      "Return: -0.12999999999999998 Steps: 30 Epsilon: 0.5159833544110289\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 43 Epsilon: 0.5134034376389738\n",
      "part 1\n",
      "Return: -0.05 Steps: 16 Epsilon: 0.5108364204507789\n",
      "part 2\n",
      "done\n",
      "Return: 0.01 Steps: 57 Epsilon: 0.508282238348525\n",
      "part 1\n",
      "Return: -0.10999999999999999 Steps: 38 Epsilon: 0.5057408271567824\n",
      "part 2\n",
      "done\n",
      "Return: 0.02 Steps: 19 Epsilon: 0.5032121230209985\n",
      "part 1\n",
      "Return: -0.060000000000000005 Steps: 28 Epsilon: 0.5006960624058935\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 37 Epsilon: 0.498192582093864\n",
      "part 1\n",
      "Return: -0.20000000000000004 Steps: 46 Epsilon: 0.4957016191833947\n",
      "part 2\n",
      "done\n",
      "Return: 0.01 Steps: 33 Epsilon: 0.49322311108747774\n",
      "part 1\n",
      "Return: -0.08 Steps: 20 Epsilon: 0.49075699553204033\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 33 Epsilon: 0.48830321055438014\n",
      "part 1\n",
      "Return: -0.10999999999999999 Steps: 28 Epsilon: 0.4858616945016082\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 33 Epsilon: 0.48343238602910016\n",
      "part 1\n",
      "Return: -0.08 Steps: 28 Epsilon: 0.48101522409895464\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 47 Epsilon: 0.47861014797845985\n",
      "part 1\n",
      "Return: -0.09999999999999999 Steps: 26 Epsilon: 0.47621709723856753\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 41 Epsilon: 0.4738360117523747\n",
      "part 1\n",
      "Return: -0.060000000000000005 Steps: 20 Epsilon: 0.47146683169361286\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 39 Epsilon: 0.4691094975351448\n",
      "part 1\n",
      "Return: -0.11999999999999998 Steps: 32 Epsilon: 0.46676395004746907\n",
      "part 2\n",
      "done\n",
      "Return: 0.01 Steps: 33 Epsilon: 0.46443013029723174\n",
      "part 1\n",
      "Return: -0.060000000000000005 Steps: 24 Epsilon: 0.46210797964574557\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 59 Epsilon: 0.45979743974751686\n",
      "part 1\n",
      "Return: -0.20000000000000004 Steps: 50 Epsilon: 0.45749845254877924\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 51 Epsilon: 0.45521096028603536\n",
      "part 1\n",
      "Return: -0.09999999999999999 Steps: 32 Epsilon: 0.4529349054846052\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 35 Epsilon: 0.45067023095718217\n",
      "part 1\n",
      "Return: -0.060000000000000005 Steps: 26 Epsilon: 0.44841687980239625\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 59 Epsilon: 0.4461747954033843\n",
      "part 1\n",
      "Return: -0.060000000000000005 Steps: 22 Epsilon: 0.44394392142636735\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 61 Epsilon: 0.4417242018192355\n",
      "part 1\n",
      "Return: -0.060000000000000005 Steps: 18 Epsilon: 0.4395155808101393\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 19 Epsilon: 0.43731800290608863\n",
      "part 1\n",
      "Return: -0.12999999999999998 Steps: 38 Epsilon: 0.4351314128915582\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 49 Epsilon: 0.43295575582710044\n",
      "part 1\n",
      "Return: -0.08 Steps: 26 Epsilon: 0.43079097704796493\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 49 Epsilon: 0.4286370221627251\n",
      "part 1\n",
      "Return: -0.12999999999999998 Steps: 30 Epsilon: 0.42649383705191146\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 45 Epsilon: 0.4243613678666519\n",
      "part 1\n",
      "Return: -0.22000000000000006 Steps: 50 Epsilon: 0.42223956102731863\n",
      "part 2\n",
      "done\n",
      "Return: 0.01 Steps: 33 Epsilon: 0.42012836322218206\n",
      "part 1\n",
      "Return: -0.10999999999999999 Steps: 48 Epsilon: 0.41802772140607114\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 25 Epsilon: 0.4159375827990408\n",
      "part 1\n",
      "Return: -0.21000000000000005 Steps: 50 Epsilon: 0.4138578948850456\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 31 Epsilon: 0.41178860541062035\n",
      "part 1\n",
      "Return: -0.01 Steps: 20 Epsilon: 0.40972966238356723\n",
      "part 2\n",
      "done\n",
      "Return: 0.05 Steps: 35 Epsilon: 0.4076810140716494\n",
      "part 1\n",
      "Return: -0.21000000000000005 Steps: 52 Epsilon: 0.4056426090012912\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 35 Epsilon: 0.40361439595628473\n",
      "part 1\n",
      "Return: -0.01 Steps: 20 Epsilon: 0.4015963239765033\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 35 Epsilon: 0.3995883423566208\n",
      "part 1\n",
      "Return: -0.05 Steps: 12 Epsilon: 0.3975904006448377\n",
      "part 2\n",
      "done\n",
      "Return: 0.01 Steps: 41 Epsilon: 0.3956024486416135\n",
      "part 1\n",
      "Return: -0.19000000000000003 Steps: 40 Epsilon: 0.3936244363984054\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 39 Epsilon: 0.39165631421641334\n",
      "part 1\n",
      "Return: -0.02 Steps: 6 Epsilon: 0.38969803264533126\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 15 Epsilon: 0.3877495424821046\n",
      "part 1\n",
      "Return: -0.08 Steps: 32 Epsilon: 0.38581079476969404\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 21 Epsilon: 0.3838817407958456\n",
      "part 1\n",
      "Return: -0.07 Steps: 38 Epsilon: 0.38196233209186636\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 29 Epsilon: 0.380052520431407\n",
      "part 1\n",
      "Return: -0.10999999999999999 Steps: 34 Epsilon: 0.37815225782925\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 37 Epsilon: 0.37626149654010377\n",
      "part 1\n",
      "Return: -0.060000000000000005 Steps: 36 Epsilon: 0.3743801890574032\n",
      "part 2\n",
      "done\n",
      "Return: 0.16 Steps: 49 Epsilon: 0.3725082881121162\n",
      "part 1\n",
      "Return: -0.11999999999999998 Steps: 34 Epsilon: 0.37064574667155564\n",
      "part 2\n",
      "done\n",
      "Return: 0.02 Steps: 43 Epsilon: 0.36879251793819784\n",
      "part 1\n",
      "Return: -0.24000000000000007 Steps: 54 Epsilon: 0.36694855534850684\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 29 Epsilon: 0.3651138125717643\n",
      "part 1\n",
      "Return: -0.11999999999999998 Steps: 28 Epsilon: 0.3632882435089055\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 13 Epsilon: 0.36147180229136094\n",
      "part 1\n",
      "Return: -0.08 Steps: 22 Epsilon: 0.35966444327990416\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 29 Epsilon: 0.3578661210635046\n",
      "part 1\n",
      "Return: -0.10999999999999999 Steps: 30 Epsilon: 0.3560767904581871\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 41 Epsilon: 0.35429640650589617\n",
      "part 1\n",
      "Return: -0.08 Steps: 26 Epsilon: 0.3525249244733667\n",
      "part 2\n",
      "done\n",
      "Return: 0.01 Steps: 37 Epsilon: 0.3507622998509999\n",
      "part 1\n",
      "Return: -0.23000000000000007 Steps: 52 Epsilon: 0.34900848835174486\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 31 Epsilon: 0.34726344590998615\n",
      "part 1\n",
      "Return: -0.18000000000000002 Steps: 46 Epsilon: 0.3455271286804362\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 41 Epsilon: 0.34379949303703405\n",
      "part 1\n",
      "Return: -0.09 Steps: 32 Epsilon: 0.3420804955718489\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 29 Epsilon: 0.34037009309398963\n",
      "part 1\n",
      "Return: -0.10999999999999999 Steps: 34 Epsilon: 0.3386682426285197\n",
      "part 2\n",
      "done\n",
      "Return: 0.05 Steps: 25 Epsilon: 0.3369749014153771\n",
      "part 1\n",
      "Return: -0.12999999999999998 Steps: 32 Epsilon: 0.33529002690830023\n",
      "part 2\n",
      "done\n",
      "Return: 0.01 Steps: 37 Epsilon: 0.33361357677375875\n",
      "part 1\n",
      "Return: -0.060000000000000005 Steps: 26 Epsilon: 0.33194550888988994\n",
      "part 2\n",
      "done\n",
      "Return: 0.01 Steps: 25 Epsilon: 0.3302857813454405\n",
      "part 1\n",
      "Return: -0.25000000000000006 Steps: 56 Epsilon: 0.3286343524387133\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 35 Epsilon: 0.3269911806765197\n",
      "part 1\n",
      "Return: -0.01 Steps: 16 Epsilon: 0.32535622477313714\n",
      "part 2\n",
      "done\n",
      "Return: 0.01 Steps: 59 Epsilon: 0.3237294436492715\n",
      "part 1\n",
      "Return: -0.04 Steps: 16 Epsilon: 0.32211079643102514\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 31 Epsilon: 0.32050024244887\n",
      "part 1\n",
      "Return: -0.18000000000000002 Steps: 44 Epsilon: 0.3188977412366256\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 25 Epsilon: 0.3173032525304425\n",
      "part 1\n",
      "Return: -0.04 Steps: 18 Epsilon: 0.3157167362677903\n",
      "part 2\n",
      "done\n",
      "Return: 0.01 Steps: 33 Epsilon: 0.31413815258645134\n",
      "part 1\n",
      "Return: -0.15 Steps: 34 Epsilon: 0.3125674618235191\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 33 Epsilon: 0.3110046245144015\n",
      "part 1\n",
      "Return: -0.17 Steps: 46 Epsilon: 0.3094496013918295\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 23 Epsilon: 0.3079023533848703\n",
      "part 1\n",
      "Return: -0.22000000000000006 Steps: 50 Epsilon: 0.30636284161794597\n",
      "part 2\n",
      "done\n",
      "Return: 0.03 Steps: 17 Epsilon: 0.30483102740985624\n",
      "part 1\n",
      "Return: -0.17 Steps: 38 Epsilon: 0.30330687227280695\n",
      "part 2\n",
      "done\n",
      "Return: 0.01 Steps: 35 Epsilon: 0.3017903379114429\n",
      "part 1\n",
      "Return: -0.09 Steps: 22 Epsilon: 0.30028138622188566\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 59 Epsilon: 0.2987799792907762\n",
      "part 1\n",
      "Return: -0.11999999999999998 Steps: 26 Epsilon: 0.29728607939432233\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 29 Epsilon: 0.29579964899735073\n",
      "part 1\n",
      "Return: 0.0 Steps: 26 Epsilon: 0.29432065075236397\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 23 Epsilon: 0.29284904749860213\n",
      "part 1\n",
      "Return: -0.01 Steps: 20 Epsilon: 0.29138480226110913\n",
      "part 2\n",
      "done\n",
      "Return: 0.01 Steps: 45 Epsilon: 0.2899278782498036\n",
      "part 1\n",
      "Return: -0.060000000000000005 Steps: 22 Epsilon: 0.28847823885855456\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 39 Epsilon: 0.28703584766426177\n",
      "part 1\n",
      "Return: -0.10999999999999999 Steps: 34 Epsilon: 0.28560066842594045\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 23 Epsilon: 0.2841726650838107\n",
      "part 1\n",
      "Return: -0.02 Steps: 22 Epsilon: 0.28275180175839165\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 15 Epsilon: 0.28133804274959967\n",
      "part 1\n",
      "Return: -0.09 Steps: 46 Epsilon: 0.27993135253585166\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 27 Epsilon: 0.2785316957731724\n",
      "part 1\n",
      "Return: -0.09999999999999999 Steps: 34 Epsilon: 0.2771390372943065\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 67 Epsilon: 0.275753342107835\n",
      "part 1\n",
      "Return: -0.2900000000000001 Steps: 66 Epsilon: 0.2743745753972958\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 33 Epsilon: 0.27300270252030934\n",
      "part 1\n",
      "Return: -0.060000000000000005 Steps: 18 Epsilon: 0.2716376890077078\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 23 Epsilon: 0.27027950056266925\n",
      "part 1\n",
      "Return: -0.16 Steps: 46 Epsilon: 0.2689281030598559\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 31 Epsilon: 0.26758346254455667\n",
      "part 1\n",
      "Return: -0.13999999999999999 Steps: 32 Epsilon: 0.2662455452318339\n",
      "part 2\n",
      "done\n",
      "Return: 0.01 Steps: 33 Epsilon: 0.26491431750567473\n",
      "part 1\n",
      "Return: -0.09999999999999999 Steps: 30 Epsilon: 0.2635897459181464\n",
      "part 2\n",
      "done\n",
      "Return: 0.060000000000000005 Steps: 19 Epsilon: 0.26227179718855564\n",
      "part 1\n",
      "Return: -0.23000000000000007 Steps: 60 Epsilon: 0.2609604382026129\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 39 Epsilon: 0.2596556360115998\n",
      "part 1\n",
      "Return: -0.17 Steps: 42 Epsilon: 0.2583573578315418\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 89 Epsilon: 0.2570655710423841\n",
      "part 1\n",
      "Return: -0.11999999999999998 Steps: 36 Epsilon: 0.2557802431871722\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 31 Epsilon: 0.2545013419712363\n",
      "part 1\n",
      "Return: -0.09 Steps: 24 Epsilon: 0.2532288352613801\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 25 Epsilon: 0.25196269108507324\n",
      "part 1\n",
      "Return: -0.04 Steps: 14 Epsilon: 0.2507028776296479\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 7 Epsilon: 0.24944936324149963\n",
      "part 1\n",
      "Return: -0.12999999999999998 Steps: 32 Epsilon: 0.24820211642529214\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 53 Epsilon: 0.24696110584316566\n",
      "part 1\n",
      "Return: -0.03 Steps: 10 Epsilon: 0.24572630031394985\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 27 Epsilon: 0.2444976688123801\n",
      "part 1\n",
      "Return: -0.05 Steps: 18 Epsilon: 0.2432751804683182\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 21 Epsilon: 0.24205880456597662\n",
      "part 1\n",
      "Return: -0.17 Steps: 38 Epsilon: 0.24084851054314674\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 23 Epsilon: 0.239644267990431\n",
      "part 1\n",
      "Return: -0.08 Steps: 22 Epsilon: 0.23844604665047886\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 39 Epsilon: 0.23725381641722645\n",
      "part 1\n",
      "Return: -0.03 Steps: 14 Epsilon: 0.23606754733514032\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 39 Epsilon: 0.23488720959846462\n",
      "part 1\n",
      "Return: -0.09999999999999999 Steps: 26 Epsilon: 0.2337127735504723\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 33 Epsilon: 0.23254420968271994\n",
      "part 1\n",
      "Return: -0.03 Steps: 18 Epsilon: 0.23138148863430633\n",
      "part 2\n",
      "done\n",
      "Return: 0.02 Steps: 31 Epsilon: 0.2302245811911348\n",
      "part 1\n",
      "Return: -0.3300000000000001 Steps: 70 Epsilon: 0.2290734582851791\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 37 Epsilon: 0.22792809099375322\n",
      "part 1\n",
      "Return: -0.12999999999999998 Steps: 30 Epsilon: 0.22678845053878446\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 17 Epsilon: 0.22565450828609054\n",
      "part 1\n",
      "Return: -0.20000000000000004 Steps: 46 Epsilon: 0.2245262357446601\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 31 Epsilon: 0.2234036045659368\n",
      "part 1\n",
      "Return: -0.09 Steps: 40 Epsilon: 0.22228658654310712\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 13 Epsilon: 0.22117515361039158\n",
      "part 1\n",
      "Return: -0.11999999999999998 Steps: 28 Epsilon: 0.22006927784233962\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 39 Epsilon: 0.21896893145312793\n",
      "part 1\n",
      "Return: -0.10999999999999999 Steps: 32 Epsilon: 0.2178740867958623\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 45 Epsilon: 0.21678471636188298\n",
      "part 1\n",
      "Return: -0.19000000000000003 Steps: 42 Epsilon: 0.21570079278007356\n",
      "part 2\n",
      "done\n",
      "Return: 0.02 Steps: 27 Epsilon: 0.2146222888161732\n",
      "part 1\n",
      "Return: -0.15 Steps: 36 Epsilon: 0.21354917737209234\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 19 Epsilon: 0.21248143148523188\n",
      "part 1\n",
      "Return: -0.17 Steps: 44 Epsilon: 0.2114190243278057\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 25 Epsilon: 0.21036192920616667\n",
      "part 1\n",
      "Return: -0.13999999999999999 Steps: 32 Epsilon: 0.20931011956013584\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 37 Epsilon: 0.20826356896233517\n",
      "part 1\n",
      "Return: -0.15 Steps: 40 Epsilon: 0.2072222511175235\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 41 Epsilon: 0.20618613986193587\n",
      "part 1\n",
      "Return: -0.10999999999999999 Steps: 28 Epsilon: 0.2051552091626262\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 25 Epsilon: 0.20412943311681306\n",
      "part 1\n",
      "Return: -0.060000000000000005 Steps: 24 Epsilon: 0.203108785951229\n",
      "part 2\n",
      "done\n",
      "Return: 0.01 Steps: 23 Epsilon: 0.20209324202147286\n",
      "part 1\n",
      "Return: -0.09999999999999999 Steps: 24 Epsilon: 0.2010827758113655\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 37 Epsilon: 0.20007736193230866\n",
      "part 1\n",
      "Return: -0.09999999999999999 Steps: 24 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.01 Steps: 33 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.2800000000000001 Steps: 66 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 27 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.13999999999999999 Steps: 38 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 39 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.13999999999999999 Steps: 42 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 21 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.05 Steps: 28 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 37 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.13999999999999999 Steps: 34 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 41 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.03 Steps: 10 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 25 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.13999999999999999 Steps: 32 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 15 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.05 Steps: 16 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 31 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.01 Steps: 16 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.01 Steps: 31 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.08 Steps: 20 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 55 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.060000000000000005 Steps: 20 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 45 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.11999999999999998 Steps: 30 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 29 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.05 Steps: 16 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 39 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.09999999999999999 Steps: 26 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 17 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.13999999999999999 Steps: 44 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 41 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.20000000000000004 Steps: 46 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 37 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.18000000000000002 Steps: 44 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 35 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.03 Steps: 16 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.01 Steps: 31 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.09 Steps: 46 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.04 Steps: 15 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.11999999999999998 Steps: 30 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.05 Steps: 29 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.19000000000000003 Steps: 42 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.01 Steps: 51 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.09 Steps: 22 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 37 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.02 Steps: 12 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 43 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.02 Steps: 22 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.01 Steps: 41 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.01 Steps: 58 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.01 Steps: 57 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.11999999999999998 Steps: 28 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 61 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.12999999999999998 Steps: 30 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 35 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.07 Steps: 26 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 47 Epsilon: 0.2\n",
      "part 1\n",
      "Return: 0.0 Steps: 26 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 5 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.07 Steps: 22 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 33 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.2700000000000001 Steps: 62 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 13 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.20000000000000004 Steps: 46 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.02 Steps: 35 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.07 Steps: 18 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 21 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.12999999999999998 Steps: 30 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 37 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.07 Steps: 20 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 33 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.060000000000000005 Steps: 18 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 15 Epsilon: 0.2\n",
      "part 1\n",
      "Return: 0.0 Steps: 30 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 41 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.13999999999999999 Steps: 32 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 15 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.08 Steps: 18 Epsilon: 0.2\n",
      "part 2\n",
      "done\n",
      "Return: 0.0 Steps: 39 Epsilon: 0.2\n",
      "part 1\n",
      "Return: -0.07 Steps: 16 Epsilon: 0.2\n",
      "part 2\n",
      "done\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#number of episodes\n",
    "num_episodes = 200 #1000\n",
    "df, WHITE_agent, BLACK_Agent= AGENT_EVALUATION(Stockfish_path, n_evaluations=num_episodes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGENT COLOR</th>\n",
       "      <th>OUTCOME</th>\n",
       "      <th>N STEPS</th>\n",
       "      <th>AGENT PIECES</th>\n",
       "      <th>OPPONENT PIECES</th>\n",
       "      <th>EPISODE</th>\n",
       "      <th>pawn</th>\n",
       "      <th>horse</th>\n",
       "      <th>knight</th>\n",
       "      <th>rook</th>\n",
       "      <th>queen</th>\n",
       "      <th>king</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHITE</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLACK</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHITE</td>\n",
       "      <td>DRAW</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BLACK</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WHITE</td>\n",
       "      <td>DRAW</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>BLACK</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>197</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>WHITE</td>\n",
       "      <td>DRAW</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>198</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>BLACK</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>198</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>WHITE</td>\n",
       "      <td>DRAW</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>199</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>BLACK</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>199</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AGENT COLOR OUTCOME  N STEPS  AGENT PIECES  OPPONENT PIECES  EPISODE  \\\n",
       "0         WHITE    LOSS        9            15               15        0   \n",
       "1         BLACK    LOSS       22            10               16        0   \n",
       "2         WHITE    DRAW       24             8               16        1   \n",
       "3         BLACK    LOSS        8            14               16        1   \n",
       "4         WHITE    DRAW       31             8               14        2   \n",
       "..          ...     ...      ...           ...              ...      ...   \n",
       "395       BLACK    LOSS       16            10               15      197   \n",
       "396       WHITE    DRAW        8            13               16      198   \n",
       "397       BLACK    LOSS        9            14               15      198   \n",
       "398       WHITE    DRAW       20            13               14      199   \n",
       "399       BLACK    LOSS        8            12               16      199   \n",
       "\n",
       "     pawn  horse  knight  rook  queen  king  \n",
       "0       8      2       1     2      1     1  \n",
       "1       8      2       2     2      1     1  \n",
       "2       8      2       2     2      1     1  \n",
       "3       8      2       2     2      1     1  \n",
       "4       5      2       2     2      2     1  \n",
       "..    ...    ...     ...   ...    ...   ...  \n",
       "395     6      2       3     2      1     1  \n",
       "396     8      2       2     2      1     1  \n",
       "397     7      2       2     2      1     1  \n",
       "398     7      1       2     2      1     1  \n",
       "399     8      2       2     2      1     1  \n",
       "\n",
       "[400 rows x 12 columns]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"deepsarsa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_w = 'whiteqn.pth'\n",
    "path_b = 'blackqn.pth'\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(WHITE_agent.qnet.state_dict(), path_w)\n",
    "torch.save(BLACK_Agent.qnet.state_dict(),path_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
